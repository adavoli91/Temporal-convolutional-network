{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7cbcdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch import nn, tensor, no_grad, optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d62bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_blocks(len_series: int, filter_size: int, base_dilation: int = 2) -> int:\n",
    "    '''\n",
    "    Function to determine the minimum number of residual blocks for full coverage of the input time series.\n",
    "    \n",
    "    Args:\n",
    "        len_series: Length of the time series.\n",
    "        filter_size: Filter size of the 1D convolutions of the TCN.\n",
    "        base_dilation: Base of the dilation; for the i-th block of the TCN, it is supposed to be `base_dilation`**i.\n",
    "        \n",
    "    Returns:\n",
    "        n_blocks: Minimum number of residual blocks for having full coverage of the input time series.\n",
    "    '''\n",
    "    if base_dilation == 2:\n",
    "        log = np.log2(1 + (len_series - 1)/(2*(filter_size - 1)))\n",
    "    else:\n",
    "        log = np.log(1 + (len_series - 1)/(2*(filter_size - 1)))\n",
    "        log /= np.log(base_dilation)\n",
    "    #\n",
    "    n_blocks = np.ceil(log)\n",
    "    return int(n_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7f0ed219",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_chan: int, dilation: int, dict_params: dict, last_block: bool,\n",
    "                 gated_activation: bool = False) -> None:\n",
    "        '''\n",
    "        Residual block of the TCN.\n",
    "\n",
    "        Args:\n",
    "            num_chan: Number of features of the input time series. For a hidden layer, this is the number of filters of the previous one.\n",
    "            dilation: Dilation factor.\n",
    "            dict_params: Dictionary containing information about the model architecture.\n",
    "            last_block: Whether it is the last residual block of the TCN.\n",
    "            gated_activation: Whether to use gated (i.e., tanh*sigmoid) activation function; if false, relu is used.\n",
    "\n",
    "        Returns: None.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        #\n",
    "        filter_size = dict_params['filter_size']\n",
    "        frac_dropout = dict_params['frac_dropout']\n",
    "        num_filters = dict_params['num_filters']\n",
    "        #\n",
    "        self.padding = (filter_size - 1)*dilation\n",
    "        self.last_block = last_block\n",
    "        self.gated_activation = gated_activation\n",
    "        # first convolution\n",
    "        self.conv_1 = nn.Conv1d(in_channels = num_chan, out_channels = num_filters, kernel_size = filter_size,\n",
    "                                dilation = dilation)\n",
    "        self.conv_1 = nn.utils.parametrizations.weight_norm(self.conv_1)\n",
    "        # second convolution\n",
    "        self.conv_2 = nn.Conv1d(in_channels = num_filters, out_channels = num_filters, kernel_size = filter_size,\n",
    "                                dilation = dilation)\n",
    "        self.conv_2 = nn.utils.parametrizations.weight_norm(self.conv_2)\n",
    "        # 1D convolution\n",
    "        self.conv_1x1 = nn.Conv1d(in_channels = num_chan, out_channels = num_filters, kernel_size = 1)\n",
    "        #\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(p = frac_dropout)\n",
    "        \n",
    "    def forward(self, x: tensor) -> tensor:\n",
    "        y = self.conv_1(nn.functional.pad(x, (self.padding, 0)))\n",
    "        if self.gated_activation == False:\n",
    "            y = self.relu(y)\n",
    "        else:\n",
    "            y = self.tanh(y)*self.sigmoid(y)\n",
    "        y = self.dropout(y)\n",
    "        #\n",
    "        y = self.conv_2(nn.functional.pad(y, (self.padding, 0)))\n",
    "        if self.last_block == False:\n",
    "            if self.gated_activation == False:\n",
    "                y = self.relu(y)\n",
    "            else:\n",
    "                y = self.tanh(y)*self.sigmoid(y)\n",
    "        y = self.dropout(y)\n",
    "        #\n",
    "        return self.conv_1x1(x) + y\n",
    "\n",
    "class TCN(nn.Module):\n",
    "    def __init__(self, len_series: int, num_feat: int, len_output: int, dict_params: dict, gated_activation: bool = False) -> None:\n",
    "        '''\n",
    "        TCN architecture.\n",
    "\n",
    "        Args:\n",
    "            len_series: Length of the input series.\n",
    "            num_feat: Number of features of the input series.\n",
    "            len_output: Length of the output series.\n",
    "            dict_params: Dictionary containing information about the model architecture.\n",
    "            gated_activation: Whether to use gated (i.e., tanh*sigmoid) activation function; if false, relu is used.\n",
    "\n",
    "        Returns: None.\n",
    "        '''\n",
    "        super().__init__()\n",
    "        #\n",
    "        dict_params = dict_params['model']\n",
    "        #\n",
    "        filter_size = dict_params['filter_size']\n",
    "        frac_dropout = dict_params['frac_dropout']\n",
    "        base_dilation = dict_params['base_dilation']\n",
    "        num_filters = dict_params['num_filters']\n",
    "        self.len_output = len_output\n",
    "        # get number of blocks\n",
    "        n_blocks = get_n_blocks(len_series = len_series, filter_size = filter_size, base_dilation = base_dilation)\n",
    "        # build TCN\n",
    "        list_blocks = []\n",
    "        for i in range(n_blocks):\n",
    "            if i == 0:\n",
    "                list_blocks.append(ResidualBlock(num_chan = num_feat, dilation = base_dilation**i, dict_params = dict_params,\n",
    "                                                 last_block = False, gated_activation = gated_activation))\n",
    "            elif 0 < i < n_blocks - 1:\n",
    "                list_blocks.append(ResidualBlock(num_chan = num_filters, dilation = base_dilation**i, dict_params = dict_params,\n",
    "                                                 last_block = False, gated_activation = gated_activation))\n",
    "            else:\n",
    "                list_blocks.append(ResidualBlock(num_chan = num_filters, dilation = base_dilation**i, dict_params = dict_params,\n",
    "                                                 last_block = True, gated_activation = gated_activation))\n",
    "        self.tcn = nn.ModuleList(list_blocks)\n",
    "        # final convolutional layer, used to fix dimensions\n",
    "        self.conv_final = nn.Conv1d(in_channels = num_filters, out_channels = 1, kernel_size = 1)\n",
    "        \n",
    "    def forward(self, x: tensor) -> tensor:\n",
    "        # TCN\n",
    "        y = self.tcn[0](x)\n",
    "        if len(self.tcn) > 0:\n",
    "            for i in range(1, len(self.tcn)):\n",
    "                y = self.tcn[i](y)\n",
    "        # final convolution\n",
    "        y = self.conv_final(y[:, :, -self.len_output:])\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "529cf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_params = {'data': {'len_series': 20, 'size_train': 0.8, 'size_valid': 0.3, 'horizon_forecast': 5},\n",
    "               'model': {'filter_size': 3, 'frac_dropout': 0.1, 'base_dilation': 2, 'num_filters': 30},\n",
    "               'training': {'batch_size': 128, 'n_epochs': 300, 'patience': 50, 'min_improve_valid_loss': 0.005}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "d47e4c2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>y</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>weekday_4</th>\n",
       "      <th>weekday_6</th>\n",
       "      <th>month_1</th>\n",
       "      <th>month_10</th>\n",
       "      <th>...</th>\n",
       "      <th>month_12</th>\n",
       "      <th>month_2</th>\n",
       "      <th>month_3</th>\n",
       "      <th>month_4</th>\n",
       "      <th>month_5</th>\n",
       "      <th>month_6</th>\n",
       "      <th>month_7</th>\n",
       "      <th>month_8</th>\n",
       "      <th>month_9</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-07</td>\n",
       "      <td>1623.7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-08</td>\n",
       "      <td>1637.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-10</td>\n",
       "      <td>1654.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-11</td>\n",
       "      <td>1650.3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-12</td>\n",
       "      <td>1628.6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date       y  weekday_0  weekday_1  weekday_2  weekday_3  weekday_4  \\\n",
       "0  2010-01-07  1623.7          0          0          0          1          0   \n",
       "1  2010-01-08  1637.8          0          0          0          0          1   \n",
       "2  2010-01-10  1654.9          0          0          0          0          0   \n",
       "3  2010-01-11  1650.3          1          0          0          0          0   \n",
       "4  2010-01-12  1628.6          0          1          0          0          0   \n",
       "\n",
       "   weekday_6  month_1  month_10  ...  month_12  month_2  month_3  month_4  \\\n",
       "0          0        1         0  ...         0        0        0        0   \n",
       "1          0        1         0  ...         0        0        0        0   \n",
       "2          1        1         0  ...         0        0        0        0   \n",
       "3          0        1         0  ...         0        0        0        0   \n",
       "4          0        1         0  ...         0        0        0        0   \n",
       "\n",
       "   month_5  month_6  month_7  month_8  month_9  label  \n",
       "0        0        0        0        0        0      3  \n",
       "1        0        0        0        0        0      2  \n",
       "2        0        0        0        0        0      3  \n",
       "3        0        0        0        0        0      3  \n",
       "4        0        0        0        0        0      2  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "e836dbd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>family</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>169.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>342.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      family      y\n",
       "0 2013-01-01  AUTOMOTIVE    0.0\n",
       "1 2013-01-02  AUTOMOTIVE  255.0\n",
       "2 2013-01-03  AUTOMOTIVE  161.0\n",
       "3 2013-01-04  AUTOMOTIVE  169.0\n",
       "4 2013-01-05  AUTOMOTIVE  342.0"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../store-sales-time-series-forecasting/train.csv', parse_dates = ['date'], index_col = 'id')\n",
    "df = df.groupby(['date', 'family']).agg({'sales': 'sum'}).reset_index()\n",
    "# add all dates\n",
    "df_temp = []\n",
    "for family in df['family'].unique():\n",
    "    df_temp.append(pd.DataFrame({'date': pd.date_range(df['date'].min(), df['date'].max())}).merge(df[df['family'] == family],\n",
    "                                                                                                   on = 'date', how = 'left'))\n",
    "    df_temp[-1]['family'] = family\n",
    "    df_temp[-1]['sales'] = df_temp[-1]['sales'].ffill()\n",
    "df = pd.concat(df_temp).reset_index(drop = True)\n",
    "del df_temp\n",
    "df = df.rename(columns = {'sales': 'y'})\n",
    "#\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "f06c61b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_splitting(df: pd.DataFrame, dict_params: dict) -> (pd.DataFrame, pd.DataFrame, pd.DataFrame):\n",
    "    '''\n",
    "    Function to split data in training, validation and test set.\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe containing time series. The column representing the main series should be called `y`.\n",
    "        dict_params: Dictionary containing information about the model architecture.\n",
    "\n",
    "    Returns:\n",
    "        df_train: Dataframe corresponding to training set.\n",
    "        df_valid: Dataframe corresponding to validation set.\n",
    "        df_test: Dataframe corresponding to test set.\n",
    "    '''\n",
    "    df_train = df.iloc[:int(df.shape[0]*dict_params['data']['size_train'])].copy().reset_index(drop = True)\n",
    "    df_test = df.iloc[int(df.shape[0]*dict_params['data']['size_train']):].reset_index(drop = True).copy().reset_index(drop = True)\n",
    "    df_valid = df_train.iloc[int(df_train.shape[0]*(1 - dict_params['data']['size_valid'])):].copy().reset_index(drop = True)\n",
    "    df_train = df_train.iloc[:int(df_train.shape[0]*(1 - dict_params['data']['size_valid']))].copy().reset_index(drop = True)\n",
    "    # rescale data\n",
    "    scaler = StandardScaler().fit(df_train[['y']])\n",
    "    df_train[['y']] = scaler.transform(df_train[['y']])\n",
    "    df_valid[['y']] = scaler.transform(df_valid[['y']])\n",
    "    df_test[['y']] = scaler.transform(df_test[['y']])\n",
    "    #\n",
    "    return df_train, df_valid, df_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "71cbe3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y(df: pd.DataFrame, df_future: pd.DataFrame, dict_params: dict, test_set: bool = False,\n",
    "            horizon_forecast: int = None) -> (tensor, tensor, np.array, np.array):\n",
    "    '''\n",
    "    Function obtain a tensor of regressors and one of target series.\n",
    "\n",
    "    Args:\n",
    "        df: Dataframe containing time series. The column representing the main series should be called `y`.\n",
    "        df_future: Same as `df`, but corresponding to its future (e.g., `df_valid` could be the \"future\" of `df_train`).\n",
    "        dict_params: Dictionary containing information about the model architecture.\n",
    "        test_set: Whether `df` is the dataframe corresponding to test set.\n",
    "        horizon_forecast: Length of the series to be predicted.\n",
    "\n",
    "    Returns:\n",
    "        x: Tensor representing regressors.\n",
    "        y: Tensor representing target time series.\n",
    "        date_x: Array containing the dates corresponding to the elements of `x`.\n",
    "        date_y: Array containing the dates corresponding to the elements of `y`.\n",
    "    '''\n",
    "    dict_params = dict_params['data']\n",
    "    #\n",
    "    len_series = dict_params['len_series']\n",
    "    if (horizon_forecast is None) or (horizon_forecast >= len_series):\n",
    "        horizon_forecast = len_series\n",
    "    #\n",
    "    df_present = df.copy()\n",
    "    if test_set == False:\n",
    "        df_future = pd.concat((df_present, df_future)).copy().shift(-len_series)\n",
    "        df_future = df_future.iloc[:df_present.shape[0]].reset_index(drop = True)\n",
    "    else:\n",
    "        df_future = df_present.copy().shift(-len_series).dropna()\n",
    "        df_present = df_present.iloc[:df_future.shape[0]]\n",
    "    #\n",
    "    x = np.array([df_present.loc[i: i + len_series - 1,\n",
    "                                 [col for col in df_present.columns if col != 'date']].values for i in range(df_present.shape[0] - len_series)])\n",
    "    y = np.array([df_future.loc[i: i + horizon_forecast - 1, ['y']].values for i in range(df_future.shape[0] - horizon_forecast)])\n",
    "    date_x = np.array([df_present.loc[i: i + len_series - 1, 'date'].values for i in range(df_present.shape[0] - len_series)])\n",
    "    date_y = np.array([df_future.loc[i: i + horizon_forecast - 1, 'date'].values for i in range(df_future.shape[0] - horizon_forecast)])\n",
    "    #\n",
    "    y = y[:x.shape[0]]\n",
    "    date_y = date_y[:date_x.shape[0]]\n",
    "    #\n",
    "    x = tensor(x.astype(np.float32))\n",
    "    y = tensor(y.astype(np.float32))\n",
    "    #\n",
    "    if len(x.shape) == 2:\n",
    "        x = x.reshape(x.shape[0], 1, -1)\n",
    "        y = y.reshape(y.shape[0], 1, -1)\n",
    "        date_x = date_x.reshape(x.shape[0], 1, -1)\n",
    "        date_y = date_y.reshape(y.shape[0], 1, -1)\n",
    "    if len(x.shape) == 3:\n",
    "        x = tensor(np.einsum('btc -> bct', x))\n",
    "        y = tensor(np.einsum('btc -> bct', y))\n",
    "        date_x = date_x.reshape(x.shape[0], 1, -1)\n",
    "        date_y = date_y.reshape(y.shape[0], 1, -1)\n",
    "    #\n",
    "    return x, y, date_x, date_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "37534548",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, x: tensor, y: tensor):\n",
    "        '''\n",
    "        Class to create a PyTorch dataset\n",
    "        \n",
    "        Args:\n",
    "            x: Tensor representing regressors.\n",
    "            y: Tensor representing target time series.\n",
    "            \n",
    "        Returns: None.\n",
    "        '''\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]\n",
    "        y = self.y[idx]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "8de575e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTCN():\n",
    "    def __init__(self, model: torch.nn.Module, dict_params: dict, dataloader_train: torch.utils.data.DataLoader, dataloader_valid: torch.utils.data.DataLoader) -> None:\n",
    "        '''\n",
    "        Class to train the TCN model.\n",
    "        \n",
    "        Args:\n",
    "            model: PyTorch model.\n",
    "            dict_params: Dictionary containing information about the model architecture.\n",
    "            dataloader_train: Dataloader containing training data.\n",
    "            dataloader_valid: Dataloader containing validation data.\n",
    "            \n",
    "        Returns: None.\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.dict_params = dict_params\n",
    "        self.dataloader_train = dataloader_train\n",
    "        self.dataloader_valid = dataloader_valid\n",
    "        #\n",
    "        self.loss_func = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(params = model.parameters(), lr = 1e-3)\n",
    "        self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer = self.optimizer, mode = 'min', factor = 0.5,\n",
    "                                                              patience = 10, threshold = 1e-4, threshold_mode = 'rel',\n",
    "                                                              verbose = False)\n",
    "\n",
    "    def _model_on_batch(self, batch: tuple, model: torch.nn.Module, optimizer: torch.optim, loss_func: torch.nn.modules.loss, perform_training: bool = True) -> float:\n",
    "        '''\n",
    "        Function to perform training on a single batch of data.\n",
    "        \n",
    "        Args:\n",
    "            batch: Batch of data to use for training/evaluation.\n",
    "            model: PyTorch model.\n",
    "            optimizer: Optimizer to use.\n",
    "            loss_func: Loss function to use.\n",
    "            perform_training: Whether to perform training (if not, evaluation is understood).\n",
    "            \n",
    "        Returns:\n",
    "            loss: Value of the loss function.\n",
    "        '''\n",
    "        if perform_training == True:\n",
    "            optimizer.zero_grad()\n",
    "        # get data from the batch\n",
    "        x, y_true = batch\n",
    "        x = x.to('cpu')\n",
    "        y_true = y_true.to('cpu')\n",
    "        # make predictions\n",
    "        y_hat = model(x).to('cpu')\n",
    "        # compute the loss function\n",
    "        loss = loss_func(y_true, y_hat)\n",
    "        if perform_training == True:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        #\n",
    "        return loss.item()\n",
    "\n",
    "    def _train(self) -> float:\n",
    "        '''\n",
    "        Function to train the TCN model on a single epoch.\n",
    "        \n",
    "        Args: None.\n",
    "            \n",
    "        Returns:\n",
    "            loss: Value of the training loss function per batch.\n",
    "        '''\n",
    "        model = self.model\n",
    "        optimizer = self.optimizer\n",
    "        loss_func = self.loss_func\n",
    "        loader = self.dataloader_train\n",
    "        #\n",
    "        model.train()\n",
    "        loss_epoch = 0\n",
    "        # iterate over batches\n",
    "        for batch in loader:\n",
    "            loss_epoch += self._model_on_batch(batch = batch, model = model, optimizer = optimizer, loss_func = loss_func,\n",
    "                                               perform_training = True)\n",
    "        #\n",
    "        return loss_epoch/len(loader)\n",
    "    \n",
    "    def _eval(self) -> float:\n",
    "        '''\n",
    "        Function to evaluate the TCN model on the validation set on a single epoch.\n",
    "        \n",
    "        Args: None.\n",
    "            \n",
    "        Returns:\n",
    "            loss: Value of the validation loss function per batch.\n",
    "        '''\n",
    "        model = self.model\n",
    "        loss_func = self.loss_func\n",
    "        loader = self.dataloader_valid\n",
    "        #\n",
    "        model.eval()\n",
    "        loss_epoch = 0\n",
    "        # iterate over batches\n",
    "        with no_grad():\n",
    "            for batch in loader:\n",
    "                loss_epoch += self._model_on_batch(batch = batch, model = model, optimizer = None, loss_func = loss_func,\n",
    "                                                   perform_training = False)\n",
    "        #\n",
    "        return loss_epoch/len(loader)\n",
    "    \n",
    "    def train_model(self) -> (torch.nn.Module, list, list):\n",
    "        '''\n",
    "        Function to train the TCN model.\n",
    "        \n",
    "        Args: None.\n",
    "            \n",
    "        Returns:\n",
    "            model: Trained TCN model.\n",
    "            list_loss_train: List of training loss function across the epochs.\n",
    "            list_loss_valid: List of validation loss function across the epochs.\n",
    "        '''\n",
    "        model = self.model\n",
    "        dict_params = self.dict_params\n",
    "        n_epochs = dict_params['training']['n_epochs']\n",
    "        patience = dict_params['training']['patience']\n",
    "        min_improve_valid_loss = dict_params['training']['min_improve_valid_loss']\n",
    "        #\n",
    "        list_loss_train, list_loss_valid = [], []\n",
    "        counter_patience = 0\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            loss_train = self._train()\n",
    "            loss_valid = self._eval()\n",
    "            # check validation loss improvement for patience\n",
    "            if (len(list_loss_valid) > 0) and (loss_valid >= np.nanmin(list_loss_valid)*(1 - min_improve_valid_loss)):\n",
    "                counter_patience += 1\n",
    "            # check validation loss w.r.t. best value\n",
    "            if (len(list_loss_valid) == 0) or (loss_valid < np.nanmin(list_loss_valid)):\n",
    "                torch.save(self.model.state_dict(), '../data/artifacts/weights.p')\n",
    "                counter_patience = 0\n",
    "            # scheduler step\n",
    "            self.scheduler.step(loss_valid)\n",
    "            #\n",
    "            print(f'Epoch {epoch}: training loss = {loss_train:.4f}, validation loss = {loss_valid:.4f}. ' +\n",
    "                  f'Learning rate = {self.optimizer.param_groups[0][\"lr\"]}. Patience = {counter_patience}')\n",
    "            #\n",
    "            list_loss_train.append(loss_train)\n",
    "            list_loss_valid.append(loss_valid)\n",
    "            # stop training with patience\n",
    "            if counter_patience >= patience:\n",
    "                print(f'Training stopped at epoch {epoch}; restoring weights from epoch {np.argmin(list_loss_valid) + 1}')\n",
    "                self.model.load_state_dict(torch.load('../data/artifacts/weights.p'))\n",
    "                break\n",
    "        #\n",
    "        return model, list_loss_train, list_loss_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13939731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_true_y_hat(model: torch.nn.Module, x: torch.tensor, y: torch.tensor, date_y: np.array,\n",
    "                     scaler: sklearn.preprocessing.StandardScaler) -> (np.array, np.array):\n",
    "    '''\n",
    "    Function to get the real time series and its prediction.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained TCN model.\n",
    "        x: Tensor representing regressors.\n",
    "        y: Tensor representing target time series.\n",
    "        date_y: Array containing the dates corresponding to the elements of `y`.\n",
    "        scaler: Scaled used to rescale data.\n",
    "        \n",
    "    Returns:\n",
    "        y_true: Array containing the true values.\n",
    "        y_hat: Array containing the predicted values.\n",
    "    '''\n",
    "    list_date = []\n",
    "    y_true = []\n",
    "    y_hat = []\n",
    "    preds = model(x)\n",
    "    for i in range(np.unique(date_y).shape[0]):\n",
    "        date = np.unique(date_y)[i]\n",
    "        list_date.append(date)\n",
    "        idx = np.where(date_y == date)\n",
    "        y_true.append(y.numpy()[idx].mean())\n",
    "        y_hat.append(preds.detach().numpy()[idx].mean())\n",
    "    y_true = np.array(y_true)\n",
    "    y_hat = np.array(y_hat)\n",
    "    # scale back\n",
    "    y_true = scaler.inverse_transform(y_true.reshape(-1, 1)).ravel()\n",
    "    y_hat = scaler.inverse_transform(y_hat.reshape(-1, 1)).ravel()\n",
    "    #\n",
    "    return y_true, y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "16c9e158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mape(y_true: np.array, y_hat: np.array) -> float:\n",
    "    '''\n",
    "    Function to compute the MAPE.\n",
    "    \n",
    "    Args:\n",
    "        y_true: Array containing the true values.\n",
    "        y_hat: Array containing the predicted values.\n",
    "        \n",
    "    Returns:\n",
    "        mape: MAPE computed from `y_true` and `y_hat`.\n",
    "    '''\n",
    "    mape = np.mean(abs(y_true[y_true > 0] - y_hat[y_true > 0])/y_true[y_true > 0])\n",
    "    return mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "9a4d118a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss = 0.7887, validation loss = 1.2967. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4731, validation loss = 0.8211. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4235, validation loss = 0.7362. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3863, validation loss = 0.7240. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.3640, validation loss = 0.7037. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.3614, validation loss = 0.7114. Learning rate = 0.001. Patience = 1\n",
      "Epoch 7: training loss = 0.3627, validation loss = 0.6925. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.3566, validation loss = 0.6766. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.3381, validation loss = 0.7363. Learning rate = 0.001. Patience = 1\n",
      "Epoch 10: training loss = 0.3401, validation loss = 0.6844. Learning rate = 0.001. Patience = 2\n",
      "Epoch 11: training loss = 0.3237, validation loss = 0.6723. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.3317, validation loss = 0.6923. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.3397, validation loss = 0.6647. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.3299, validation loss = 0.6700. Learning rate = 0.001. Patience = 1\n",
      "Epoch 15: training loss = 0.3248, validation loss = 0.6498. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.3187, validation loss = 0.6564. Learning rate = 0.001. Patience = 1\n",
      "Epoch 17: training loss = 0.3115, validation loss = 0.6899. Learning rate = 0.001. Patience = 2\n",
      "Epoch 18: training loss = 0.3090, validation loss = 0.6518. Learning rate = 0.001. Patience = 3\n",
      "Epoch 19: training loss = 0.3150, validation loss = 0.6217. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.3139, validation loss = 0.6679. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.3030, validation loss = 0.6366. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.3098, validation loss = 0.6345. Learning rate = 0.001. Patience = 3\n",
      "Epoch 23: training loss = 0.2989, validation loss = 0.6165. Learning rate = 0.001. Patience = 0\n",
      "Epoch 24: training loss = 0.3055, validation loss = 0.6488. Learning rate = 0.001. Patience = 1\n",
      "Epoch 25: training loss = 0.3031, validation loss = 0.6476. Learning rate = 0.001. Patience = 2\n",
      "Epoch 26: training loss = 0.2909, validation loss = 0.6308. Learning rate = 0.001. Patience = 3\n",
      "Epoch 27: training loss = 0.2950, validation loss = 0.6290. Learning rate = 0.001. Patience = 4\n",
      "Epoch 28: training loss = 0.2977, validation loss = 0.6485. Learning rate = 0.001. Patience = 5\n",
      "Epoch 29: training loss = 0.2936, validation loss = 0.6411. Learning rate = 0.001. Patience = 6\n",
      "Epoch 30: training loss = 0.2968, validation loss = 0.6277. Learning rate = 0.001. Patience = 7\n",
      "Epoch 31: training loss = 0.2819, validation loss = 0.6269. Learning rate = 0.001. Patience = 8\n",
      "Epoch 32: training loss = 0.2847, validation loss = 0.6264. Learning rate = 0.001. Patience = 9\n",
      "Epoch 33: training loss = 0.2784, validation loss = 0.6635. Learning rate = 0.001. Patience = 10\n",
      "Epoch 34: training loss = 0.2748, validation loss = 0.6319. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 35: training loss = 0.2677, validation loss = 0.6286. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 36: training loss = 0.2800, validation loss = 0.6353. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 37: training loss = 0.2757, validation loss = 0.6285. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 38: training loss = 0.2772, validation loss = 0.6314. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 39: training loss = 0.2695, validation loss = 0.6393. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 40: training loss = 0.2634, validation loss = 0.6364. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 41: training loss = 0.2806, validation loss = 0.6345. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 42: training loss = 0.2728, validation loss = 0.6379. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 43: training loss = 0.2703, validation loss = 0.6302. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 44: training loss = 0.2693, validation loss = 0.6481. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 45: training loss = 0.2761, validation loss = 0.6509. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 46: training loss = 0.2646, validation loss = 0.6335. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 47: training loss = 0.2654, validation loss = 0.6432. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 48: training loss = 0.2545, validation loss = 0.6418. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 49: training loss = 0.2622, validation loss = 0.6374. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 50: training loss = 0.2674, validation loss = 0.6494. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 51: training loss = 0.2536, validation loss = 0.6547. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 52: training loss = 0.2595, validation loss = 0.6526. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 53: training loss = 0.2574, validation loss = 0.6504. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 54: training loss = 0.2566, validation loss = 0.6608. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 55: training loss = 0.2554, validation loss = 0.6641. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 56: training loss = 0.2579, validation loss = 0.6544. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 57: training loss = 0.2607, validation loss = 0.6578. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 58: training loss = 0.2628, validation loss = 0.6569. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 59: training loss = 0.2555, validation loss = 0.6522. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 60: training loss = 0.2719, validation loss = 0.6784. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 61: training loss = 0.2499, validation loss = 0.6560. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 62: training loss = 0.2597, validation loss = 0.6553. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 63: training loss = 0.2526, validation loss = 0.6531. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 64: training loss = 0.2438, validation loss = 0.6542. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 65: training loss = 0.2510, validation loss = 0.6619. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 66: training loss = 0.2608, validation loss = 0.6601. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 67: training loss = 0.2746, validation loss = 0.6561. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 68: training loss = 0.2537, validation loss = 0.6598. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 69: training loss = 0.2533, validation loss = 0.6583. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 70: training loss = 0.2458, validation loss = 0.6549. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 71: training loss = 0.2573, validation loss = 0.6544. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 72: training loss = 0.2566, validation loss = 0.6549. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 73: training loss = 0.2480, validation loss = 0.6591. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 73; restoring weights from epoch 23\n",
      "Epoch 1: training loss = 1.6694, validation loss = 3.7295. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 1.4283, validation loss = 4.1552. Learning rate = 0.001. Patience = 1\n",
      "Epoch 3: training loss = 1.4348, validation loss = 4.9291. Learning rate = 0.001. Patience = 2\n",
      "Epoch 4: training loss = 1.3248, validation loss = 3.9431. Learning rate = 0.001. Patience = 3\n",
      "Epoch 5: training loss = 1.3169, validation loss = 3.9542. Learning rate = 0.001. Patience = 4\n",
      "Epoch 6: training loss = 1.3386, validation loss = 3.9267. Learning rate = 0.001. Patience = 5\n",
      "Epoch 7: training loss = 1.3441, validation loss = 3.9322. Learning rate = 0.001. Patience = 6\n",
      "Epoch 8: training loss = 1.3591, validation loss = 3.9633. Learning rate = 0.001. Patience = 7\n",
      "Epoch 9: training loss = 1.3260, validation loss = 4.0625. Learning rate = 0.001. Patience = 8\n",
      "Epoch 10: training loss = 1.2818, validation loss = 4.1253. Learning rate = 0.001. Patience = 9\n",
      "Epoch 11: training loss = 1.2826, validation loss = 4.4457. Learning rate = 0.001. Patience = 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: training loss = 2.0981, validation loss = 4.3449. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 13: training loss = 1.2506, validation loss = 4.9185. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 14: training loss = 1.2310, validation loss = 4.5799. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 15: training loss = 1.2450, validation loss = 4.6095. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 16: training loss = 2.0206, validation loss = 4.9123. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 17: training loss = 1.2217, validation loss = 5.8826. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 18: training loss = 1.2321, validation loss = 5.1921. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 19: training loss = 1.2546, validation loss = 5.1762. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 20: training loss = 1.1765, validation loss = 5.2705. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 21: training loss = 1.1720, validation loss = 5.6132. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 22: training loss = 1.1997, validation loss = 5.6392. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 23: training loss = 1.1469, validation loss = 5.6453. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 24: training loss = 1.1605, validation loss = 5.5706. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 25: training loss = 1.1640, validation loss = 5.6454. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 26: training loss = 1.1184, validation loss = 5.7027. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 27: training loss = 1.2127, validation loss = 5.8279. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 28: training loss = 1.1243, validation loss = 5.8970. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 29: training loss = 1.1494, validation loss = 6.0518. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 30: training loss = 1.1529, validation loss = 5.9230. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 31: training loss = 1.1176, validation loss = 6.1135. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 32: training loss = 1.1165, validation loss = 6.1112. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 33: training loss = 1.1314, validation loss = 6.1747. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 34: training loss = 1.1114, validation loss = 6.3772. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 35: training loss = 1.0828, validation loss = 6.4772. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 36: training loss = 1.0705, validation loss = 6.6271. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 37: training loss = 1.0842, validation loss = 6.4874. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 38: training loss = 1.0934, validation loss = 6.5687. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 39: training loss = 1.1386, validation loss = 6.5213. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 40: training loss = 1.1500, validation loss = 6.4765. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 41: training loss = 1.0878, validation loss = 6.6379. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 42: training loss = 1.7650, validation loss = 6.7712. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 43: training loss = 1.0724, validation loss = 7.4315. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 44: training loss = 1.0784, validation loss = 7.4481. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 45: training loss = 1.0526, validation loss = 7.1090. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 46: training loss = 1.6557, validation loss = 7.0930. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 47: training loss = 1.0675, validation loss = 7.3731. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 48: training loss = 1.1145, validation loss = 7.4383. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 49: training loss = 1.0831, validation loss = 7.4299. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 50: training loss = 1.1324, validation loss = 7.4218. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 51: training loss = 1.0920, validation loss = 7.4594. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 51; restoring weights from epoch 1\n",
      "Epoch 1: training loss = 0.8583, validation loss = 4.7469. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.6074, validation loss = 2.7327. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4691, validation loss = 1.6608. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.4259, validation loss = 1.9034. Learning rate = 0.001. Patience = 1\n",
      "Epoch 5: training loss = 0.4105, validation loss = 2.2748. Learning rate = 0.001. Patience = 2\n",
      "Epoch 6: training loss = 0.3951, validation loss = 1.8784. Learning rate = 0.001. Patience = 3\n",
      "Epoch 7: training loss = 0.3905, validation loss = 1.9001. Learning rate = 0.001. Patience = 4\n",
      "Epoch 8: training loss = 0.3956, validation loss = 1.6413. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.3873, validation loss = 1.9351. Learning rate = 0.001. Patience = 1\n",
      "Epoch 10: training loss = 0.3821, validation loss = 1.7035. Learning rate = 0.001. Patience = 2\n",
      "Epoch 11: training loss = 0.3889, validation loss = 2.1928. Learning rate = 0.001. Patience = 3\n",
      "Epoch 12: training loss = 0.3692, validation loss = 1.8436. Learning rate = 0.001. Patience = 4\n",
      "Epoch 13: training loss = 0.3713, validation loss = 2.0643. Learning rate = 0.001. Patience = 5\n",
      "Epoch 14: training loss = 0.3544, validation loss = 1.8650. Learning rate = 0.001. Patience = 6\n",
      "Epoch 15: training loss = 0.3455, validation loss = 2.2426. Learning rate = 0.001. Patience = 7\n",
      "Epoch 16: training loss = 0.3650, validation loss = 2.1372. Learning rate = 0.001. Patience = 8\n",
      "Epoch 17: training loss = 0.3597, validation loss = 2.5610. Learning rate = 0.001. Patience = 9\n",
      "Epoch 18: training loss = 0.3470, validation loss = 1.7755. Learning rate = 0.001. Patience = 10\n",
      "Epoch 19: training loss = 0.3520, validation loss = 2.5939. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 20: training loss = 0.3484, validation loss = 2.1019. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 21: training loss = 0.3727, validation loss = 2.2956. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 22: training loss = 0.3281, validation loss = 1.9982. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 23: training loss = 0.3478, validation loss = 2.2431. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 24: training loss = 0.3309, validation loss = 2.3784. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 25: training loss = 0.3359, validation loss = 2.2592. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 26: training loss = 0.3333, validation loss = 2.2003. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 27: training loss = 0.3354, validation loss = 2.2811. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 28: training loss = 0.3204, validation loss = 2.4502. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 29: training loss = 0.3402, validation loss = 2.3826. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 30: training loss = 0.3331, validation loss = 2.3708. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 31: training loss = 0.3428, validation loss = 2.4589. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 32: training loss = 0.3314, validation loss = 2.3582. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 33: training loss = 0.3275, validation loss = 2.5735. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 34: training loss = 0.3340, validation loss = 2.6040. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 35: training loss = 0.3185, validation loss = 2.4073. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 36: training loss = 0.3280, validation loss = 2.3676. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 37: training loss = 0.3169, validation loss = 2.4015. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 38: training loss = 0.3149, validation loss = 2.4276. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 39: training loss = 0.3157, validation loss = 2.3260. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 40: training loss = 0.3422, validation loss = 2.3212. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 41: training loss = 0.3118, validation loss = 2.5635. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 42: training loss = 0.3253, validation loss = 2.6758. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 43: training loss = 0.3079, validation loss = 2.5131. Learning rate = 0.000125. Patience = 35\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44: training loss = 0.3321, validation loss = 2.4544. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 45: training loss = 0.3246, validation loss = 2.3790. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 46: training loss = 0.3184, validation loss = 2.4105. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 47: training loss = 0.3094, validation loss = 2.4041. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 48: training loss = 0.3147, validation loss = 2.4735. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 49: training loss = 0.3149, validation loss = 2.4181. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 50: training loss = 0.3055, validation loss = 2.4266. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 51: training loss = 0.3196, validation loss = 2.5606. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 52: training loss = 0.3063, validation loss = 2.5111. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 53: training loss = 0.3114, validation loss = 2.4902. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 54: training loss = 0.3078, validation loss = 2.4920. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 55: training loss = 0.3267, validation loss = 2.4406. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 56: training loss = 0.3264, validation loss = 2.4883. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 57: training loss = 0.3127, validation loss = 2.4687. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 58: training loss = 0.3244, validation loss = 2.4769. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 58; restoring weights from epoch 8\n",
      "Epoch 1: training loss = 0.8236, validation loss = 0.9139. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4699, validation loss = 0.6526. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3277, validation loss = 0.5478. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3101, validation loss = 0.4861. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2716, validation loss = 0.4730. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2878, validation loss = 0.4218. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2753, validation loss = 0.4653. Learning rate = 0.001. Patience = 1\n",
      "Epoch 8: training loss = 0.2497, validation loss = 0.4178. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.2589, validation loss = 0.4139. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2440, validation loss = 0.4483. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2401, validation loss = 0.4028. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.2643, validation loss = 0.4477. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.2413, validation loss = 0.4245. Learning rate = 0.001. Patience = 2\n",
      "Epoch 14: training loss = 0.2597, validation loss = 0.4264. Learning rate = 0.001. Patience = 3\n",
      "Epoch 15: training loss = 0.2447, validation loss = 0.4444. Learning rate = 0.001. Patience = 4\n",
      "Epoch 16: training loss = 0.2455, validation loss = 0.4116. Learning rate = 0.001. Patience = 5\n",
      "Epoch 17: training loss = 0.2446, validation loss = 0.4225. Learning rate = 0.001. Patience = 6\n",
      "Epoch 18: training loss = 0.2506, validation loss = 0.4083. Learning rate = 0.001. Patience = 7\n",
      "Epoch 19: training loss = 0.2509, validation loss = 0.4393. Learning rate = 0.001. Patience = 8\n",
      "Epoch 20: training loss = 0.2442, validation loss = 0.4028. Learning rate = 0.001. Patience = 0\n",
      "Epoch 21: training loss = 0.2220, validation loss = 0.4039. Learning rate = 0.001. Patience = 1\n",
      "Epoch 22: training loss = 0.2295, validation loss = 0.4774. Learning rate = 0.001. Patience = 2\n",
      "Epoch 23: training loss = 0.2514, validation loss = 0.3927. Learning rate = 0.001. Patience = 0\n",
      "Epoch 24: training loss = 0.2214, validation loss = 0.5196. Learning rate = 0.001. Patience = 1\n",
      "Epoch 25: training loss = 0.2414, validation loss = 0.3926. Learning rate = 0.001. Patience = 0\n",
      "Epoch 26: training loss = 0.2206, validation loss = 0.4696. Learning rate = 0.001. Patience = 1\n",
      "Epoch 27: training loss = 0.2264, validation loss = 0.4004. Learning rate = 0.001. Patience = 2\n",
      "Epoch 28: training loss = 0.2321, validation loss = 0.4346. Learning rate = 0.001. Patience = 3\n",
      "Epoch 29: training loss = 0.2383, validation loss = 0.4314. Learning rate = 0.001. Patience = 4\n",
      "Epoch 30: training loss = 0.2317, validation loss = 0.4463. Learning rate = 0.001. Patience = 5\n",
      "Epoch 31: training loss = 0.2193, validation loss = 0.3761. Learning rate = 0.001. Patience = 0\n",
      "Epoch 32: training loss = 0.2512, validation loss = 0.4286. Learning rate = 0.001. Patience = 1\n",
      "Epoch 33: training loss = 0.2100, validation loss = 0.4410. Learning rate = 0.001. Patience = 2\n",
      "Epoch 34: training loss = 0.2060, validation loss = 0.4093. Learning rate = 0.001. Patience = 3\n",
      "Epoch 35: training loss = 0.2126, validation loss = 0.3845. Learning rate = 0.001. Patience = 4\n",
      "Epoch 36: training loss = 0.2360, validation loss = 0.4683. Learning rate = 0.001. Patience = 5\n",
      "Epoch 37: training loss = 0.2302, validation loss = 0.4093. Learning rate = 0.001. Patience = 6\n",
      "Epoch 38: training loss = 0.2029, validation loss = 0.4463. Learning rate = 0.001. Patience = 7\n",
      "Epoch 39: training loss = 0.2014, validation loss = 0.4454. Learning rate = 0.001. Patience = 8\n",
      "Epoch 40: training loss = 0.2210, validation loss = 0.3800. Learning rate = 0.001. Patience = 9\n",
      "Epoch 41: training loss = 0.1995, validation loss = 0.4787. Learning rate = 0.001. Patience = 10\n",
      "Epoch 42: training loss = 0.2347, validation loss = 0.4384. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 43: training loss = 0.1997, validation loss = 0.4629. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 44: training loss = 0.2190, validation loss = 0.4051. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 45: training loss = 0.2015, validation loss = 0.4464. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 46: training loss = 0.2070, validation loss = 0.4438. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 47: training loss = 0.1992, validation loss = 0.4471. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 48: training loss = 0.2010, validation loss = 0.4289. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 49: training loss = 0.2002, validation loss = 0.4413. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 50: training loss = 0.2084, validation loss = 0.4564. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 51: training loss = 0.2106, validation loss = 0.4288. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 52: training loss = 0.2093, validation loss = 0.4483. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 53: training loss = 0.1923, validation loss = 0.4358. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 54: training loss = 0.1979, validation loss = 0.4324. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 55: training loss = 0.2030, validation loss = 0.4322. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 56: training loss = 0.2086, validation loss = 0.4431. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 57: training loss = 0.1923, validation loss = 0.4329. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 58: training loss = 0.2032, validation loss = 0.4151. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 59: training loss = 0.2040, validation loss = 0.4168. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 60: training loss = 0.2004, validation loss = 0.4291. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 61: training loss = 0.1881, validation loss = 0.4233. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 62: training loss = 0.1975, validation loss = 0.4287. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 63: training loss = 0.2020, validation loss = 0.4453. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 64: training loss = 0.1939, validation loss = 0.4456. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 65: training loss = 0.1951, validation loss = 0.4262. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 66: training loss = 0.2027, validation loss = 0.4328. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 67: training loss = 0.1892, validation loss = 0.4167. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 68: training loss = 0.1903, validation loss = 0.4346. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 69: training loss = 0.1956, validation loss = 0.4325. Learning rate = 0.000125. Patience = 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70: training loss = 0.1934, validation loss = 0.4303. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 71: training loss = 0.1978, validation loss = 0.4320. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 72: training loss = 0.2000, validation loss = 0.4345. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 73: training loss = 0.1868, validation loss = 0.4285. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 74: training loss = 0.1999, validation loss = 0.4382. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 75: training loss = 0.1912, validation loss = 0.4523. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 76: training loss = 0.2046, validation loss = 0.4478. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 77: training loss = 0.1925, validation loss = 0.4349. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 78: training loss = 0.2043, validation loss = 0.4317. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 79: training loss = 0.2197, validation loss = 0.4368. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 80: training loss = 0.1845, validation loss = 0.4255. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 81: training loss = 0.1958, validation loss = 0.4280. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 81; restoring weights from epoch 31\n",
      "Epoch 1: training loss = 0.0178, validation loss = 0.0001. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.0037, validation loss = 0.0010. Learning rate = 0.001. Patience = 1\n",
      "Epoch 3: training loss = 0.0013, validation loss = 0.0010. Learning rate = 0.001. Patience = 2\n",
      "Epoch 4: training loss = 0.0007, validation loss = 0.0005. Learning rate = 0.001. Patience = 3\n",
      "Epoch 5: training loss = 0.0005, validation loss = 0.0001. Learning rate = 0.001. Patience = 4\n",
      "Epoch 6: training loss = 0.0004, validation loss = 0.0000. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.0003, validation loss = 0.0000. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.0002, validation loss = 0.0000. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.0002, validation loss = 0.0000. Learning rate = 0.001. Patience = 2\n",
      "Epoch 10: training loss = 0.0002, validation loss = 0.0000. Learning rate = 0.001. Patience = 0\n",
      "Epoch 11: training loss = 0.0002, validation loss = 0.0000. Learning rate = 0.001. Patience = 1\n",
      "Epoch 12: training loss = 0.0002, validation loss = 0.0000. Learning rate = 0.001. Patience = 2\n",
      "Epoch 13: training loss = 0.0002, validation loss = 0.0000. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.0002, validation loss = 0.0000. Learning rate = 0.001. Patience = 1\n",
      "Epoch 15: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 2\n",
      "Epoch 16: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 3\n",
      "Epoch 17: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 4\n",
      "Epoch 18: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 5\n",
      "Epoch 19: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 3\n",
      "Epoch 23: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 4\n",
      "Epoch 24: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 5\n",
      "Epoch 25: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 6\n",
      "Epoch 26: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 0\n",
      "Epoch 27: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 1\n",
      "Epoch 28: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 2\n",
      "Epoch 29: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 3\n",
      "Epoch 30: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 4\n",
      "Epoch 31: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 5\n",
      "Epoch 32: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 6\n",
      "Epoch 33: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 7\n",
      "Epoch 34: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 8\n",
      "Epoch 35: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 9\n",
      "Epoch 36: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.001. Patience = 10\n",
      "Epoch 37: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 38: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 39: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 40: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 41: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 42: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 43: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 44: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 45: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 46: training loss = 0.0001, validation loss = 0.0000. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 47: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 48: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 49: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 50: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 51: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 52: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 53: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 54: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 55: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 56: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 57: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 58: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 59: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 60: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 61: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 62: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 63: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 8\n",
      "Epoch 64: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 9\n",
      "Epoch 65: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.0005. Patience = 10\n",
      "Epoch 66: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 11\n",
      "Epoch 67: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 12\n",
      "Epoch 68: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 13\n",
      "Epoch 69: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 14\n",
      "Epoch 70: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 15\n",
      "Epoch 71: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 16\n",
      "Epoch 72: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 18\n",
      "Epoch 74: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 19\n",
      "Epoch 75: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 20\n",
      "Epoch 76: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.00025. Patience = 21\n",
      "Epoch 77: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 22\n",
      "Epoch 78: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 23\n",
      "Epoch 79: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 24\n",
      "Epoch 80: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 25\n",
      "Epoch 81: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 26\n",
      "Epoch 82: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 27\n",
      "Epoch 83: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 28\n",
      "Epoch 84: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 29\n",
      "Epoch 85: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 30\n",
      "Epoch 86: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 31\n",
      "Epoch 87: training loss = 0.0000, validation loss = 0.0000. Learning rate = 0.000125. Patience = 32\n",
      "Epoch 88: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 33\n",
      "Epoch 89: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 34\n",
      "Epoch 90: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 35\n",
      "Epoch 91: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 36\n",
      "Epoch 92: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 37\n",
      "Epoch 93: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 38\n",
      "Epoch 94: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 39\n",
      "Epoch 95: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 40\n",
      "Epoch 96: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 41\n",
      "Epoch 97: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 42\n",
      "Epoch 98: training loss = 0.0000, validation loss = 0.0000. Learning rate = 6.25e-05. Patience = 43\n",
      "Epoch 99: training loss = 0.0000, validation loss = 0.0000. Learning rate = 3.125e-05. Patience = 44\n",
      "Epoch 100: training loss = 0.0000, validation loss = 0.0000. Learning rate = 3.125e-05. Patience = 45\n",
      "Epoch 101: training loss = 0.0000, validation loss = 0.0000. Learning rate = 3.125e-05. Patience = 46\n",
      "Epoch 102: training loss = 0.0000, validation loss = 0.0000. Learning rate = 3.125e-05. Patience = 47\n",
      "Epoch 103: training loss = 0.0000, validation loss = 0.0000. Learning rate = 3.125e-05. Patience = 48\n",
      "Epoch 104: training loss = 0.0000, validation loss = 0.0000. Learning rate = 3.125e-05. Patience = 49\n",
      "Epoch 105: training loss = 0.0000, validation loss = 0.0000. Learning rate = 3.125e-05. Patience = 50\n",
      "Training stopped at epoch 105; restoring weights from epoch 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alled\\anaconda3\\envs\\trading\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\alled\\anaconda3\\envs\\trading\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\alled\\anaconda3\\envs\\trading\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\alled\\anaconda3\\envs\\trading\\lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss = 0.8555, validation loss = 1.0442. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4521, validation loss = 0.6214. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3083, validation loss = 0.5129. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.2619, validation loss = 0.3946. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2366, validation loss = 0.3659. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2352, validation loss = 0.3499. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2203, validation loss = 0.3469. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.2247, validation loss = 0.3374. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.2399, validation loss = 0.3097. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2153, validation loss = 0.3194. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2185, validation loss = 0.3094. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.2050, validation loss = 0.2991. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.2281, validation loss = 0.3043. Learning rate = 0.001. Patience = 1\n",
      "Epoch 14: training loss = 0.1942, validation loss = 0.3013. Learning rate = 0.001. Patience = 2\n",
      "Epoch 15: training loss = 0.1999, validation loss = 0.2814. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.1978, validation loss = 0.2933. Learning rate = 0.001. Patience = 1\n",
      "Epoch 17: training loss = 0.1944, validation loss = 0.2939. Learning rate = 0.001. Patience = 2\n",
      "Epoch 18: training loss = 0.1896, validation loss = 0.2997. Learning rate = 0.001. Patience = 3\n",
      "Epoch 19: training loss = 0.1888, validation loss = 0.2722. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.2095, validation loss = 0.2873. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.1905, validation loss = 0.2659. Learning rate = 0.001. Patience = 0\n",
      "Epoch 22: training loss = 0.1895, validation loss = 0.3064. Learning rate = 0.001. Patience = 1\n",
      "Epoch 23: training loss = 0.1865, validation loss = 0.2660. Learning rate = 0.001. Patience = 2\n",
      "Epoch 24: training loss = 0.1937, validation loss = 0.2807. Learning rate = 0.001. Patience = 3\n",
      "Epoch 25: training loss = 0.1804, validation loss = 0.2660. Learning rate = 0.001. Patience = 4\n",
      "Epoch 26: training loss = 0.1860, validation loss = 0.2676. Learning rate = 0.001. Patience = 5\n",
      "Epoch 27: training loss = 0.1929, validation loss = 0.2734. Learning rate = 0.001. Patience = 6\n",
      "Epoch 28: training loss = 0.1971, validation loss = 0.2729. Learning rate = 0.001. Patience = 7\n",
      "Epoch 29: training loss = 0.1746, validation loss = 0.2823. Learning rate = 0.001. Patience = 8\n",
      "Epoch 30: training loss = 0.1732, validation loss = 0.2751. Learning rate = 0.001. Patience = 9\n",
      "Epoch 31: training loss = 0.1775, validation loss = 0.2670. Learning rate = 0.001. Patience = 10\n",
      "Epoch 32: training loss = 0.1764, validation loss = 0.2763. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 33: training loss = 0.1756, validation loss = 0.2835. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 34: training loss = 0.1850, validation loss = 0.2669. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 35: training loss = 0.1856, validation loss = 0.2729. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 36: training loss = 0.1688, validation loss = 0.2804. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 37: training loss = 0.1763, validation loss = 0.2675. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 38: training loss = 0.1881, validation loss = 0.2986. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 39: training loss = 0.1708, validation loss = 0.2665. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 40: training loss = 0.1765, validation loss = 0.2796. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 41: training loss = 0.1735, validation loss = 0.2603. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 42: training loss = 0.1857, validation loss = 0.2852. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 43: training loss = 0.1740, validation loss = 0.2937. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 44: training loss = 0.1670, validation loss = 0.2769. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 45: training loss = 0.1734, validation loss = 0.2651. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 46: training loss = 0.1657, validation loss = 0.2900. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 47: training loss = 0.1685, validation loss = 0.2700. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 48: training loss = 0.1747, validation loss = 0.2807. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 49: training loss = 0.1774, validation loss = 0.2802. Learning rate = 0.0005. Patience = 8\n",
      "Epoch 50: training loss = 0.1667, validation loss = 0.2711. Learning rate = 0.0005. Patience = 9\n",
      "Epoch 51: training loss = 0.1651, validation loss = 0.2816. Learning rate = 0.0005. Patience = 10\n",
      "Epoch 52: training loss = 0.1662, validation loss = 0.2660. Learning rate = 0.00025. Patience = 11\n",
      "Epoch 53: training loss = 0.1742, validation loss = 0.2761. Learning rate = 0.00025. Patience = 12\n",
      "Epoch 54: training loss = 0.1746, validation loss = 0.2824. Learning rate = 0.00025. Patience = 13\n",
      "Epoch 55: training loss = 0.1600, validation loss = 0.2744. Learning rate = 0.00025. Patience = 14\n",
      "Epoch 56: training loss = 0.1613, validation loss = 0.2719. Learning rate = 0.00025. Patience = 15\n",
      "Epoch 57: training loss = 0.1671, validation loss = 0.2834. Learning rate = 0.00025. Patience = 16\n",
      "Epoch 58: training loss = 0.1662, validation loss = 0.2701. Learning rate = 0.00025. Patience = 17\n",
      "Epoch 59: training loss = 0.1835, validation loss = 0.2764. Learning rate = 0.00025. Patience = 18\n",
      "Epoch 60: training loss = 0.1646, validation loss = 0.2684. Learning rate = 0.00025. Patience = 19\n",
      "Epoch 61: training loss = 0.1630, validation loss = 0.2781. Learning rate = 0.00025. Patience = 20\n",
      "Epoch 62: training loss = 0.1611, validation loss = 0.2743. Learning rate = 0.00025. Patience = 21\n",
      "Epoch 63: training loss = 0.1607, validation loss = 0.2756. Learning rate = 0.000125. Patience = 22\n",
      "Epoch 64: training loss = 0.1657, validation loss = 0.2785. Learning rate = 0.000125. Patience = 23\n",
      "Epoch 65: training loss = 0.1643, validation loss = 0.2717. Learning rate = 0.000125. Patience = 24\n",
      "Epoch 66: training loss = 0.1621, validation loss = 0.2810. Learning rate = 0.000125. Patience = 25\n",
      "Epoch 67: training loss = 0.1633, validation loss = 0.2721. Learning rate = 0.000125. Patience = 26\n",
      "Epoch 68: training loss = 0.1605, validation loss = 0.2715. Learning rate = 0.000125. Patience = 27\n",
      "Epoch 69: training loss = 0.1681, validation loss = 0.2843. Learning rate = 0.000125. Patience = 28\n",
      "Epoch 70: training loss = 0.1568, validation loss = 0.2823. Learning rate = 0.000125. Patience = 29\n",
      "Epoch 71: training loss = 0.1646, validation loss = 0.2701. Learning rate = 0.000125. Patience = 30\n",
      "Epoch 72: training loss = 0.1752, validation loss = 0.2702. Learning rate = 0.000125. Patience = 31\n",
      "Epoch 73: training loss = 0.1588, validation loss = 0.2739. Learning rate = 0.000125. Patience = 32\n",
      "Epoch 74: training loss = 0.1641, validation loss = 0.2766. Learning rate = 6.25e-05. Patience = 33\n",
      "Epoch 75: training loss = 0.1609, validation loss = 0.2729. Learning rate = 6.25e-05. Patience = 34\n",
      "Epoch 76: training loss = 0.1571, validation loss = 0.2751. Learning rate = 6.25e-05. Patience = 35\n",
      "Epoch 77: training loss = 0.1569, validation loss = 0.2771. Learning rate = 6.25e-05. Patience = 36\n",
      "Epoch 78: training loss = 0.1569, validation loss = 0.2810. Learning rate = 6.25e-05. Patience = 37\n",
      "Epoch 79: training loss = 0.1770, validation loss = 0.2786. Learning rate = 6.25e-05. Patience = 38\n",
      "Epoch 80: training loss = 0.1615, validation loss = 0.2692. Learning rate = 6.25e-05. Patience = 39\n",
      "Epoch 81: training loss = 0.1745, validation loss = 0.2747. Learning rate = 6.25e-05. Patience = 40\n",
      "Epoch 82: training loss = 0.1766, validation loss = 0.2759. Learning rate = 6.25e-05. Patience = 41\n",
      "Epoch 83: training loss = 0.1585, validation loss = 0.2752. Learning rate = 6.25e-05. Patience = 42\n",
      "Epoch 84: training loss = 0.1645, validation loss = 0.2781. Learning rate = 6.25e-05. Patience = 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85: training loss = 0.1624, validation loss = 0.2784. Learning rate = 3.125e-05. Patience = 44\n",
      "Epoch 86: training loss = 0.1654, validation loss = 0.2757. Learning rate = 3.125e-05. Patience = 45\n",
      "Epoch 87: training loss = 0.1686, validation loss = 0.2736. Learning rate = 3.125e-05. Patience = 46\n",
      "Epoch 88: training loss = 0.1596, validation loss = 0.2754. Learning rate = 3.125e-05. Patience = 47\n",
      "Epoch 89: training loss = 0.1651, validation loss = 0.2770. Learning rate = 3.125e-05. Patience = 48\n",
      "Epoch 90: training loss = 0.1653, validation loss = 0.2796. Learning rate = 3.125e-05. Patience = 49\n",
      "Epoch 91: training loss = 0.1578, validation loss = 0.2745. Learning rate = 3.125e-05. Patience = 50\n",
      "Training stopped at epoch 91; restoring weights from epoch 41\n",
      "Epoch 1: training loss = 0.6273, validation loss = 0.6060. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4560, validation loss = 0.6149. Learning rate = 0.001. Patience = 1\n",
      "Epoch 3: training loss = 0.3607, validation loss = 0.4096. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3460, validation loss = 0.2882. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.3511, validation loss = 0.3091. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.3276, validation loss = 0.2469. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.3166, validation loss = 0.2638. Learning rate = 0.001. Patience = 1\n",
      "Epoch 8: training loss = 0.3295, validation loss = 0.2406. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.3080, validation loss = 0.2440. Learning rate = 0.001. Patience = 1\n",
      "Epoch 10: training loss = 0.2884, validation loss = 0.2481. Learning rate = 0.001. Patience = 2\n",
      "Epoch 11: training loss = 0.2884, validation loss = 0.2273. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.3030, validation loss = 0.2089. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.3032, validation loss = 0.2580. Learning rate = 0.001. Patience = 1\n",
      "Epoch 14: training loss = 0.2894, validation loss = 0.2137. Learning rate = 0.001. Patience = 2\n",
      "Epoch 15: training loss = 0.3259, validation loss = 0.2474. Learning rate = 0.001. Patience = 3\n",
      "Epoch 16: training loss = 0.3288, validation loss = 0.2089. Learning rate = 0.001. Patience = 4\n",
      "Epoch 17: training loss = 0.3098, validation loss = 0.2164. Learning rate = 0.001. Patience = 5\n",
      "Epoch 18: training loss = 0.2890, validation loss = 0.2068. Learning rate = 0.001. Patience = 0\n",
      "Epoch 19: training loss = 0.2706, validation loss = 0.1890. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.2781, validation loss = 0.2793. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.3103, validation loss = 0.1975. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.2771, validation loss = 0.2283. Learning rate = 0.001. Patience = 3\n",
      "Epoch 23: training loss = 0.2893, validation loss = 0.2134. Learning rate = 0.001. Patience = 4\n",
      "Epoch 24: training loss = 0.2602, validation loss = 0.2161. Learning rate = 0.001. Patience = 5\n",
      "Epoch 25: training loss = 0.2513, validation loss = 0.2020. Learning rate = 0.001. Patience = 6\n",
      "Epoch 26: training loss = 0.2788, validation loss = 0.2200. Learning rate = 0.001. Patience = 7\n",
      "Epoch 27: training loss = 0.2484, validation loss = 0.2000. Learning rate = 0.001. Patience = 8\n",
      "Epoch 28: training loss = 0.2866, validation loss = 0.3106. Learning rate = 0.001. Patience = 9\n",
      "Epoch 29: training loss = 0.2654, validation loss = 0.2110. Learning rate = 0.001. Patience = 10\n",
      "Epoch 30: training loss = 0.2543, validation loss = 0.2520. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 31: training loss = 0.2750, validation loss = 0.2109. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 32: training loss = 0.2547, validation loss = 0.2388. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 33: training loss = 0.2730, validation loss = 0.2114. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 34: training loss = 0.2695, validation loss = 0.2173. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 35: training loss = 0.2700, validation loss = 0.2172. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 36: training loss = 0.2690, validation loss = 0.2187. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 37: training loss = 0.2670, validation loss = 0.2234. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 38: training loss = 0.2659, validation loss = 0.2350. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 39: training loss = 0.2531, validation loss = 0.2235. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 40: training loss = 0.2727, validation loss = 0.2206. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 41: training loss = 0.2532, validation loss = 0.2383. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 42: training loss = 0.2578, validation loss = 0.2309. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 43: training loss = 0.2652, validation loss = 0.2277. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 44: training loss = 0.2379, validation loss = 0.2426. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 45: training loss = 0.2541, validation loss = 0.2253. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 46: training loss = 0.2520, validation loss = 0.2276. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 47: training loss = 0.2592, validation loss = 0.2453. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 48: training loss = 0.2335, validation loss = 0.2271. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 49: training loss = 0.2436, validation loss = 0.2335. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 50: training loss = 0.2683, validation loss = 0.2298. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 51: training loss = 0.2462, validation loss = 0.2332. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 52: training loss = 0.2346, validation loss = 0.2395. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 53: training loss = 0.2878, validation loss = 0.2337. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 54: training loss = 0.2444, validation loss = 0.2342. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 55: training loss = 0.2509, validation loss = 0.2314. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 56: training loss = 0.2546, validation loss = 0.2334. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 57: training loss = 0.2528, validation loss = 0.2471. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 58: training loss = 0.2372, validation loss = 0.2425. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 59: training loss = 0.2590, validation loss = 0.2332. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 60: training loss = 0.2804, validation loss = 0.2443. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 61: training loss = 0.2555, validation loss = 0.2482. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 62: training loss = 0.2619, validation loss = 0.2398. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 63: training loss = 0.2475, validation loss = 0.2336. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 64: training loss = 0.2653, validation loss = 0.2343. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 65: training loss = 0.2443, validation loss = 0.2371. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 66: training loss = 0.2721, validation loss = 0.2431. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 67: training loss = 0.2479, validation loss = 0.2395. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 68: training loss = 0.2560, validation loss = 0.2375. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 69: training loss = 0.2422, validation loss = 0.2377. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 69; restoring weights from epoch 19\n",
      "Epoch 1: training loss = 0.8618, validation loss = 1.0204. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.5801, validation loss = 0.6517. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4955, validation loss = 0.6406. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.4570, validation loss = 0.5977. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.4340, validation loss = 0.5660. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.4377, validation loss = 0.5698. Learning rate = 0.001. Patience = 1\n",
      "Epoch 7: training loss = 0.3999, validation loss = 0.5633. Learning rate = 0.001. Patience = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: training loss = 0.4006, validation loss = 0.5465. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.3646, validation loss = 0.5557. Learning rate = 0.001. Patience = 1\n",
      "Epoch 10: training loss = 0.3770, validation loss = 0.5167. Learning rate = 0.001. Patience = 0\n",
      "Epoch 11: training loss = 0.3835, validation loss = 0.5025. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.3407, validation loss = 0.5961. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.3430, validation loss = 0.5022. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.3333, validation loss = 0.4964. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.3567, validation loss = 0.5075. Learning rate = 0.001. Patience = 1\n",
      "Epoch 16: training loss = 0.3165, validation loss = 0.4967. Learning rate = 0.001. Patience = 2\n",
      "Epoch 17: training loss = 0.3052, validation loss = 0.5215. Learning rate = 0.001. Patience = 3\n",
      "Epoch 18: training loss = 0.3101, validation loss = 0.5059. Learning rate = 0.001. Patience = 4\n",
      "Epoch 19: training loss = 0.3104, validation loss = 0.5068. Learning rate = 0.001. Patience = 5\n",
      "Epoch 20: training loss = 0.3124, validation loss = 0.5033. Learning rate = 0.001. Patience = 6\n",
      "Epoch 21: training loss = 0.2983, validation loss = 0.4924. Learning rate = 0.001. Patience = 0\n",
      "Epoch 22: training loss = 0.3031, validation loss = 0.5373. Learning rate = 0.001. Patience = 1\n",
      "Epoch 23: training loss = 0.3016, validation loss = 0.4897. Learning rate = 0.001. Patience = 0\n",
      "Epoch 24: training loss = 0.2925, validation loss = 0.4989. Learning rate = 0.001. Patience = 1\n",
      "Epoch 25: training loss = 0.2903, validation loss = 0.4880. Learning rate = 0.001. Patience = 0\n",
      "Epoch 26: training loss = 0.2985, validation loss = 0.4985. Learning rate = 0.001. Patience = 1\n",
      "Epoch 27: training loss = 0.2824, validation loss = 0.4995. Learning rate = 0.001. Patience = 2\n",
      "Epoch 28: training loss = 0.2869, validation loss = 0.4742. Learning rate = 0.001. Patience = 0\n",
      "Epoch 29: training loss = 0.2856, validation loss = 0.5034. Learning rate = 0.001. Patience = 1\n",
      "Epoch 30: training loss = 0.2752, validation loss = 0.4957. Learning rate = 0.001. Patience = 2\n",
      "Epoch 31: training loss = 0.2723, validation loss = 0.4994. Learning rate = 0.001. Patience = 3\n",
      "Epoch 32: training loss = 0.2924, validation loss = 0.5413. Learning rate = 0.001. Patience = 4\n",
      "Epoch 33: training loss = 0.2718, validation loss = 0.5028. Learning rate = 0.001. Patience = 5\n",
      "Epoch 34: training loss = 0.2640, validation loss = 0.5239. Learning rate = 0.001. Patience = 6\n",
      "Epoch 35: training loss = 0.2671, validation loss = 0.4828. Learning rate = 0.001. Patience = 7\n",
      "Epoch 36: training loss = 0.2718, validation loss = 0.5017. Learning rate = 0.001. Patience = 8\n",
      "Epoch 37: training loss = 0.2649, validation loss = 0.4903. Learning rate = 0.001. Patience = 9\n",
      "Epoch 38: training loss = 0.2549, validation loss = 0.4839. Learning rate = 0.001. Patience = 10\n",
      "Epoch 39: training loss = 0.2560, validation loss = 0.4874. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 40: training loss = 0.2475, validation loss = 0.5276. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 41: training loss = 0.2574, validation loss = 0.4943. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 42: training loss = 0.2416, validation loss = 0.5014. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 43: training loss = 0.2383, validation loss = 0.4881. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 44: training loss = 0.2410, validation loss = 0.4969. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 45: training loss = 0.2600, validation loss = 0.4980. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 46: training loss = 0.2410, validation loss = 0.4892. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 47: training loss = 0.2389, validation loss = 0.5059. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 48: training loss = 0.2563, validation loss = 0.4942. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 49: training loss = 0.2411, validation loss = 0.4986. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 50: training loss = 0.2465, validation loss = 0.5128. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 51: training loss = 0.2558, validation loss = 0.4908. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 52: training loss = 0.2325, validation loss = 0.4995. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 53: training loss = 0.2564, validation loss = 0.4939. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 54: training loss = 0.2371, validation loss = 0.5082. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 55: training loss = 0.2316, validation loss = 0.4994. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 56: training loss = 0.2434, validation loss = 0.4934. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 57: training loss = 0.2279, validation loss = 0.5110. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 58: training loss = 0.2327, validation loss = 0.4961. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 59: training loss = 0.2361, validation loss = 0.5101. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 60: training loss = 0.2413, validation loss = 0.4981. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 61: training loss = 0.2313, validation loss = 0.5110. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 62: training loss = 0.2340, validation loss = 0.5114. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 63: training loss = 0.2327, validation loss = 0.5040. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 64: training loss = 0.2269, validation loss = 0.5024. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 65: training loss = 0.2396, validation loss = 0.5030. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 66: training loss = 0.2298, validation loss = 0.5070. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 67: training loss = 0.2322, validation loss = 0.4979. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 68: training loss = 0.2232, validation loss = 0.4997. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 69: training loss = 0.2381, validation loss = 0.5040. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 70: training loss = 0.2251, validation loss = 0.5151. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 71: training loss = 0.2272, validation loss = 0.5009. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 72: training loss = 0.2339, validation loss = 0.5021. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 73: training loss = 0.2344, validation loss = 0.5019. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 74: training loss = 0.2416, validation loss = 0.5033. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 75: training loss = 0.2387, validation loss = 0.5035. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 76: training loss = 0.2284, validation loss = 0.5014. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 77: training loss = 0.2292, validation loss = 0.5007. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 78: training loss = 0.2162, validation loss = 0.5037. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 78; restoring weights from epoch 28\n",
      "Epoch 1: training loss = 0.7752, validation loss = 0.8934. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.3572, validation loss = 0.4364. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.2324, validation loss = 0.4310. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.1952, validation loss = 0.2702. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.1898, validation loss = 0.3371. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.1843, validation loss = 0.3387. Learning rate = 0.001. Patience = 2\n",
      "Epoch 7: training loss = 0.1792, validation loss = 0.3125. Learning rate = 0.001. Patience = 3\n",
      "Epoch 8: training loss = 0.1628, validation loss = 0.3462. Learning rate = 0.001. Patience = 4\n",
      "Epoch 9: training loss = 0.1654, validation loss = 0.3168. Learning rate = 0.001. Patience = 5\n",
      "Epoch 10: training loss = 0.1572, validation loss = 0.3539. Learning rate = 0.001. Patience = 6\n",
      "Epoch 11: training loss = 0.1646, validation loss = 0.3201. Learning rate = 0.001. Patience = 7\n",
      "Epoch 12: training loss = 0.1602, validation loss = 0.3518. Learning rate = 0.001. Patience = 8\n",
      "Epoch 13: training loss = 0.1623, validation loss = 0.3447. Learning rate = 0.001. Patience = 9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: training loss = 0.1565, validation loss = 0.3372. Learning rate = 0.001. Patience = 10\n",
      "Epoch 15: training loss = 0.1553, validation loss = 0.3491. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 16: training loss = 0.1499, validation loss = 0.3314. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 17: training loss = 0.1518, validation loss = 0.3525. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 18: training loss = 0.1457, validation loss = 0.3387. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 19: training loss = 0.1490, validation loss = 0.3345. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 20: training loss = 0.1543, validation loss = 0.3475. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 21: training loss = 0.1536, validation loss = 0.3212. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 22: training loss = 0.1521, validation loss = 0.3381. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 23: training loss = 0.1442, validation loss = 0.3297. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 24: training loss = 0.1471, validation loss = 0.3280. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 25: training loss = 0.1461, validation loss = 0.3374. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 26: training loss = 0.1486, validation loss = 0.3304. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 27: training loss = 0.1481, validation loss = 0.3506. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 28: training loss = 0.1520, validation loss = 0.3493. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 29: training loss = 0.1428, validation loss = 0.3333. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 30: training loss = 0.1442, validation loss = 0.3457. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 31: training loss = 0.1443, validation loss = 0.3290. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 32: training loss = 0.1494, validation loss = 0.3473. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 33: training loss = 0.1383, validation loss = 0.3398. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 34: training loss = 0.1505, validation loss = 0.3287. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 35: training loss = 0.1382, validation loss = 0.3391. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 36: training loss = 0.1471, validation loss = 0.3392. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 37: training loss = 0.1450, validation loss = 0.3449. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 38: training loss = 0.1426, validation loss = 0.3425. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 39: training loss = 0.1555, validation loss = 0.3333. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 40: training loss = 0.1496, validation loss = 0.3300. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 41: training loss = 0.1376, validation loss = 0.3350. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 42: training loss = 0.1435, validation loss = 0.3327. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 43: training loss = 0.1456, validation loss = 0.3300. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 44: training loss = 0.1379, validation loss = 0.3343. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 45: training loss = 0.1407, validation loss = 0.3504. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 46: training loss = 0.1487, validation loss = 0.3323. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 47: training loss = 0.1421, validation loss = 0.3207. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 48: training loss = 0.1452, validation loss = 0.3290. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 49: training loss = 0.1377, validation loss = 0.3373. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 50: training loss = 0.1457, validation loss = 0.3422. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 51: training loss = 0.1380, validation loss = 0.3327. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 52: training loss = 0.1407, validation loss = 0.3320. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 53: training loss = 0.1405, validation loss = 0.3345. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 54: training loss = 0.1421, validation loss = 0.3378. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 54; restoring weights from epoch 4\n",
      "Epoch 1: training loss = 0.8657, validation loss = 0.8234. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.5047, validation loss = 0.5126. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3507, validation loss = 0.4515. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3203, validation loss = 0.4133. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2979, validation loss = 0.3928. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2664, validation loss = 0.3735. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2908, validation loss = 0.3765. Learning rate = 0.001. Patience = 1\n",
      "Epoch 8: training loss = 0.2634, validation loss = 0.3733. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.2671, validation loss = 0.3645. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2594, validation loss = 0.3748. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2643, validation loss = 0.3650. Learning rate = 0.001. Patience = 2\n",
      "Epoch 12: training loss = 0.2578, validation loss = 0.3821. Learning rate = 0.001. Patience = 3\n",
      "Epoch 13: training loss = 0.2567, validation loss = 0.3587. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.2443, validation loss = 0.3651. Learning rate = 0.001. Patience = 1\n",
      "Epoch 15: training loss = 0.2515, validation loss = 0.3628. Learning rate = 0.001. Patience = 2\n",
      "Epoch 16: training loss = 0.2522, validation loss = 0.3647. Learning rate = 0.001. Patience = 3\n",
      "Epoch 17: training loss = 0.2418, validation loss = 0.3627. Learning rate = 0.001. Patience = 4\n",
      "Epoch 18: training loss = 0.2350, validation loss = 0.3529. Learning rate = 0.001. Patience = 0\n",
      "Epoch 19: training loss = 0.2310, validation loss = 0.3658. Learning rate = 0.001. Patience = 1\n",
      "Epoch 20: training loss = 0.2307, validation loss = 0.3548. Learning rate = 0.001. Patience = 2\n",
      "Epoch 21: training loss = 0.2275, validation loss = 0.3563. Learning rate = 0.001. Patience = 3\n",
      "Epoch 22: training loss = 0.2452, validation loss = 0.3681. Learning rate = 0.001. Patience = 4\n",
      "Epoch 23: training loss = 0.2481, validation loss = 0.3578. Learning rate = 0.001. Patience = 5\n",
      "Epoch 24: training loss = 0.2236, validation loss = 0.3560. Learning rate = 0.001. Patience = 6\n",
      "Epoch 25: training loss = 0.2187, validation loss = 0.3494. Learning rate = 0.001. Patience = 0\n",
      "Epoch 26: training loss = 0.2342, validation loss = 0.3516. Learning rate = 0.001. Patience = 1\n",
      "Epoch 27: training loss = 0.2214, validation loss = 0.3586. Learning rate = 0.001. Patience = 2\n",
      "Epoch 28: training loss = 0.2091, validation loss = 0.3626. Learning rate = 0.001. Patience = 3\n",
      "Epoch 29: training loss = 0.2149, validation loss = 0.3518. Learning rate = 0.001. Patience = 4\n",
      "Epoch 30: training loss = 0.2104, validation loss = 0.3665. Learning rate = 0.001. Patience = 5\n",
      "Epoch 31: training loss = 0.2082, validation loss = 0.3600. Learning rate = 0.001. Patience = 6\n",
      "Epoch 32: training loss = 0.1997, validation loss = 0.3639. Learning rate = 0.001. Patience = 7\n",
      "Epoch 33: training loss = 0.2177, validation loss = 0.3540. Learning rate = 0.001. Patience = 8\n",
      "Epoch 34: training loss = 0.2157, validation loss = 0.3597. Learning rate = 0.001. Patience = 9\n",
      "Epoch 35: training loss = 0.2084, validation loss = 0.3564. Learning rate = 0.001. Patience = 10\n",
      "Epoch 36: training loss = 0.1996, validation loss = 0.3517. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 37: training loss = 0.2141, validation loss = 0.3533. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 38: training loss = 0.2030, validation loss = 0.3541. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 39: training loss = 0.1891, validation loss = 0.3498. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 40: training loss = 0.1889, validation loss = 0.3515. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 41: training loss = 0.1901, validation loss = 0.3510. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 42: training loss = 0.1932, validation loss = 0.3508. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 43: training loss = 0.1900, validation loss = 0.3529. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 44: training loss = 0.1926, validation loss = 0.3507. Learning rate = 0.0005. Patience = 19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45: training loss = 0.1867, validation loss = 0.3488. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 46: training loss = 0.1911, validation loss = 0.3495. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 47: training loss = 0.1908, validation loss = 0.3583. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 48: training loss = 0.1831, validation loss = 0.3536. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 49: training loss = 0.1891, validation loss = 0.3541. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 50: training loss = 0.1890, validation loss = 0.3513. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 51: training loss = 0.1940, validation loss = 0.3646. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 52: training loss = 0.1823, validation loss = 0.3596. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 53: training loss = 0.1792, validation loss = 0.3664. Learning rate = 0.0005. Patience = 8\n",
      "Epoch 54: training loss = 0.1823, validation loss = 0.3603. Learning rate = 0.0005. Patience = 9\n",
      "Epoch 55: training loss = 0.1774, validation loss = 0.3584. Learning rate = 0.0005. Patience = 10\n",
      "Epoch 56: training loss = 0.1866, validation loss = 0.3653. Learning rate = 0.00025. Patience = 11\n",
      "Epoch 57: training loss = 0.1752, validation loss = 0.3602. Learning rate = 0.00025. Patience = 12\n",
      "Epoch 58: training loss = 0.1836, validation loss = 0.3627. Learning rate = 0.00025. Patience = 13\n",
      "Epoch 59: training loss = 0.1775, validation loss = 0.3630. Learning rate = 0.00025. Patience = 14\n",
      "Epoch 60: training loss = 0.1801, validation loss = 0.3621. Learning rate = 0.00025. Patience = 15\n",
      "Epoch 61: training loss = 0.1877, validation loss = 0.3640. Learning rate = 0.00025. Patience = 16\n",
      "Epoch 62: training loss = 0.1716, validation loss = 0.3612. Learning rate = 0.00025. Patience = 17\n",
      "Epoch 63: training loss = 0.1910, validation loss = 0.3643. Learning rate = 0.00025. Patience = 18\n",
      "Epoch 64: training loss = 0.1733, validation loss = 0.3595. Learning rate = 0.00025. Patience = 19\n",
      "Epoch 65: training loss = 0.1820, validation loss = 0.3633. Learning rate = 0.00025. Patience = 20\n",
      "Epoch 66: training loss = 0.1759, validation loss = 0.3650. Learning rate = 0.00025. Patience = 21\n",
      "Epoch 67: training loss = 0.1734, validation loss = 0.3649. Learning rate = 0.000125. Patience = 22\n",
      "Epoch 68: training loss = 0.1700, validation loss = 0.3641. Learning rate = 0.000125. Patience = 23\n",
      "Epoch 69: training loss = 0.1745, validation loss = 0.3637. Learning rate = 0.000125. Patience = 24\n",
      "Epoch 70: training loss = 0.1764, validation loss = 0.3646. Learning rate = 0.000125. Patience = 25\n",
      "Epoch 71: training loss = 0.1787, validation loss = 0.3641. Learning rate = 0.000125. Patience = 26\n",
      "Epoch 72: training loss = 0.1745, validation loss = 0.3671. Learning rate = 0.000125. Patience = 27\n",
      "Epoch 73: training loss = 0.1708, validation loss = 0.3630. Learning rate = 0.000125. Patience = 28\n",
      "Epoch 74: training loss = 0.1780, validation loss = 0.3634. Learning rate = 0.000125. Patience = 29\n",
      "Epoch 75: training loss = 0.1788, validation loss = 0.3633. Learning rate = 0.000125. Patience = 30\n",
      "Epoch 76: training loss = 0.1694, validation loss = 0.3611. Learning rate = 0.000125. Patience = 31\n",
      "Epoch 77: training loss = 0.1837, validation loss = 0.3617. Learning rate = 0.000125. Patience = 32\n",
      "Epoch 78: training loss = 0.1698, validation loss = 0.3681. Learning rate = 6.25e-05. Patience = 33\n",
      "Epoch 79: training loss = 0.1696, validation loss = 0.3625. Learning rate = 6.25e-05. Patience = 34\n",
      "Epoch 80: training loss = 0.1753, validation loss = 0.3606. Learning rate = 6.25e-05. Patience = 35\n",
      "Epoch 81: training loss = 0.1760, validation loss = 0.3625. Learning rate = 6.25e-05. Patience = 36\n",
      "Epoch 82: training loss = 0.1747, validation loss = 0.3630. Learning rate = 6.25e-05. Patience = 37\n",
      "Epoch 83: training loss = 0.1823, validation loss = 0.3624. Learning rate = 6.25e-05. Patience = 38\n",
      "Epoch 84: training loss = 0.1704, validation loss = 0.3638. Learning rate = 6.25e-05. Patience = 39\n",
      "Epoch 85: training loss = 0.1742, validation loss = 0.3630. Learning rate = 6.25e-05. Patience = 40\n",
      "Epoch 86: training loss = 0.1918, validation loss = 0.3607. Learning rate = 6.25e-05. Patience = 41\n",
      "Epoch 87: training loss = 0.1805, validation loss = 0.3622. Learning rate = 6.25e-05. Patience = 42\n",
      "Epoch 88: training loss = 0.1784, validation loss = 0.3647. Learning rate = 6.25e-05. Patience = 43\n",
      "Epoch 89: training loss = 0.1703, validation loss = 0.3640. Learning rate = 3.125e-05. Patience = 44\n",
      "Epoch 90: training loss = 0.1745, validation loss = 0.3645. Learning rate = 3.125e-05. Patience = 45\n",
      "Epoch 91: training loss = 0.1703, validation loss = 0.3646. Learning rate = 3.125e-05. Patience = 46\n",
      "Epoch 92: training loss = 0.1735, validation loss = 0.3645. Learning rate = 3.125e-05. Patience = 47\n",
      "Epoch 93: training loss = 0.1658, validation loss = 0.3644. Learning rate = 3.125e-05. Patience = 48\n",
      "Epoch 94: training loss = 0.1705, validation loss = 0.3649. Learning rate = 3.125e-05. Patience = 49\n",
      "Epoch 95: training loss = 0.1710, validation loss = 0.3648. Learning rate = 3.125e-05. Patience = 50\n",
      "Training stopped at epoch 95; restoring weights from epoch 45\n",
      "Epoch 1: training loss = 0.7919, validation loss = 0.5629. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4089, validation loss = 0.3272. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3097, validation loss = 0.2730. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.2810, validation loss = 0.2698. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2721, validation loss = 0.2639. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2452, validation loss = 0.2599. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2646, validation loss = 0.2560. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.2499, validation loss = 0.2771. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.2403, validation loss = 0.2547. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2503, validation loss = 0.2549. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2353, validation loss = 0.2523. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.2233, validation loss = 0.2567. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.2365, validation loss = 0.2717. Learning rate = 0.001. Patience = 2\n",
      "Epoch 14: training loss = 0.2276, validation loss = 0.2529. Learning rate = 0.001. Patience = 3\n",
      "Epoch 15: training loss = 0.2295, validation loss = 0.2445. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.2312, validation loss = 0.2524. Learning rate = 0.001. Patience = 1\n",
      "Epoch 17: training loss = 0.2291, validation loss = 0.2588. Learning rate = 0.001. Patience = 2\n",
      "Epoch 18: training loss = 0.2200, validation loss = 0.2707. Learning rate = 0.001. Patience = 3\n",
      "Epoch 19: training loss = 0.2225, validation loss = 0.2603. Learning rate = 0.001. Patience = 4\n",
      "Epoch 20: training loss = 0.2222, validation loss = 0.2552. Learning rate = 0.001. Patience = 5\n",
      "Epoch 21: training loss = 0.2203, validation loss = 0.2653. Learning rate = 0.001. Patience = 6\n",
      "Epoch 22: training loss = 0.2128, validation loss = 0.2612. Learning rate = 0.001. Patience = 7\n",
      "Epoch 23: training loss = 0.2212, validation loss = 0.2495. Learning rate = 0.001. Patience = 8\n",
      "Epoch 24: training loss = 0.2124, validation loss = 0.2608. Learning rate = 0.001. Patience = 9\n",
      "Epoch 25: training loss = 0.2091, validation loss = 0.2643. Learning rate = 0.001. Patience = 10\n",
      "Epoch 26: training loss = 0.2105, validation loss = 0.2604. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 27: training loss = 0.2116, validation loss = 0.2617. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 28: training loss = 0.2079, validation loss = 0.2588. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 29: training loss = 0.1993, validation loss = 0.2642. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 30: training loss = 0.2077, validation loss = 0.2560. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 31: training loss = 0.2010, validation loss = 0.2628. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 32: training loss = 0.2012, validation loss = 0.2630. Learning rate = 0.0005. Patience = 17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: training loss = 0.1999, validation loss = 0.2602. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 34: training loss = 0.2002, validation loss = 0.2627. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 35: training loss = 0.1971, validation loss = 0.2656. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 36: training loss = 0.2063, validation loss = 0.2584. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 37: training loss = 0.2004, validation loss = 0.2570. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 38: training loss = 0.1979, validation loss = 0.2559. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 39: training loss = 0.2001, validation loss = 0.2633. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 40: training loss = 0.2007, validation loss = 0.2623. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 41: training loss = 0.1987, validation loss = 0.2597. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 42: training loss = 0.1905, validation loss = 0.2625. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 43: training loss = 0.1938, validation loss = 0.2606. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 44: training loss = 0.2051, validation loss = 0.2643. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 45: training loss = 0.1922, validation loss = 0.2599. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 46: training loss = 0.2047, validation loss = 0.2613. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 47: training loss = 0.1906, validation loss = 0.2643. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 48: training loss = 0.1958, validation loss = 0.2642. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 49: training loss = 0.2017, validation loss = 0.2613. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 50: training loss = 0.1975, validation loss = 0.2597. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 51: training loss = 0.1962, validation loss = 0.2582. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 52: training loss = 0.2004, validation loss = 0.2607. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 53: training loss = 0.1932, validation loss = 0.2668. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 54: training loss = 0.1872, validation loss = 0.2633. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 55: training loss = 0.1868, validation loss = 0.2603. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 56: training loss = 0.1985, validation loss = 0.2640. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 57: training loss = 0.1883, validation loss = 0.2704. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 58: training loss = 0.2076, validation loss = 0.2692. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 59: training loss = 0.1949, validation loss = 0.2621. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 60: training loss = 0.1858, validation loss = 0.2627. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 61: training loss = 0.2032, validation loss = 0.2631. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 62: training loss = 0.1919, validation loss = 0.2635. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 63: training loss = 0.1924, validation loss = 0.2636. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 64: training loss = 0.1940, validation loss = 0.2635. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 65: training loss = 0.1914, validation loss = 0.2638. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 65; restoring weights from epoch 15\n",
      "Epoch 1: training loss = 0.8689, validation loss = 1.2649. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.7019, validation loss = 1.1096. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.5133, validation loss = 1.0379. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.5075, validation loss = 0.9724. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.4480, validation loss = 0.9611. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.4254, validation loss = 0.8845. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.4513, validation loss = 0.8393. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.3849, validation loss = 0.9459. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.3480, validation loss = 0.7164. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.3073, validation loss = 0.7779. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2851, validation loss = 0.6666. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.2520, validation loss = 0.6685. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.2238, validation loss = 0.6904. Learning rate = 0.001. Patience = 2\n",
      "Epoch 14: training loss = 0.2051, validation loss = 0.7555. Learning rate = 0.001. Patience = 3\n",
      "Epoch 15: training loss = 0.1719, validation loss = 0.7801. Learning rate = 0.001. Patience = 4\n",
      "Epoch 16: training loss = 0.1689, validation loss = 0.6734. Learning rate = 0.001. Patience = 5\n",
      "Epoch 17: training loss = 0.1656, validation loss = 0.6867. Learning rate = 0.001. Patience = 6\n",
      "Epoch 18: training loss = 0.1457, validation loss = 0.8423. Learning rate = 0.001. Patience = 7\n",
      "Epoch 19: training loss = 0.1660, validation loss = 0.6852. Learning rate = 0.001. Patience = 8\n",
      "Epoch 20: training loss = 0.1484, validation loss = 0.5763. Learning rate = 0.001. Patience = 0\n",
      "Epoch 21: training loss = 0.1457, validation loss = 0.7557. Learning rate = 0.001. Patience = 1\n",
      "Epoch 22: training loss = 0.1228, validation loss = 0.5880. Learning rate = 0.001. Patience = 2\n",
      "Epoch 23: training loss = 0.1123, validation loss = 0.6649. Learning rate = 0.001. Patience = 3\n",
      "Epoch 24: training loss = 0.1138, validation loss = 0.6127. Learning rate = 0.001. Patience = 4\n",
      "Epoch 25: training loss = 0.1191, validation loss = 0.8065. Learning rate = 0.001. Patience = 5\n",
      "Epoch 26: training loss = 0.0988, validation loss = 0.5099. Learning rate = 0.001. Patience = 0\n",
      "Epoch 27: training loss = 0.1218, validation loss = 0.8030. Learning rate = 0.001. Patience = 1\n",
      "Epoch 28: training loss = 0.1059, validation loss = 0.6543. Learning rate = 0.001. Patience = 2\n",
      "Epoch 29: training loss = 0.1009, validation loss = 0.5965. Learning rate = 0.001. Patience = 3\n",
      "Epoch 30: training loss = 0.0947, validation loss = 0.8207. Learning rate = 0.001. Patience = 4\n",
      "Epoch 31: training loss = 0.0934, validation loss = 0.6536. Learning rate = 0.001. Patience = 5\n",
      "Epoch 32: training loss = 0.0841, validation loss = 0.7268. Learning rate = 0.001. Patience = 6\n",
      "Epoch 33: training loss = 0.0939, validation loss = 0.7289. Learning rate = 0.001. Patience = 7\n",
      "Epoch 34: training loss = 0.0806, validation loss = 0.7744. Learning rate = 0.001. Patience = 8\n",
      "Epoch 35: training loss = 0.0993, validation loss = 0.6947. Learning rate = 0.001. Patience = 9\n",
      "Epoch 36: training loss = 0.0923, validation loss = 0.7244. Learning rate = 0.001. Patience = 10\n",
      "Epoch 37: training loss = 0.0929, validation loss = 0.7375. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 38: training loss = 0.0744, validation loss = 0.6821. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 39: training loss = 0.0798, validation loss = 0.7334. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 40: training loss = 0.0728, validation loss = 0.7559. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 41: training loss = 0.0691, validation loss = 0.7138. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 42: training loss = 0.0683, validation loss = 0.7073. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 43: training loss = 0.0756, validation loss = 0.7385. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 44: training loss = 0.0760, validation loss = 0.7443. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 45: training loss = 0.0611, validation loss = 0.6660. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 46: training loss = 0.0610, validation loss = 0.7209. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 47: training loss = 0.0662, validation loss = 0.7448. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 48: training loss = 0.0759, validation loss = 0.7618. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 49: training loss = 0.0691, validation loss = 0.7345. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 50: training loss = 0.0712, validation loss = 0.7093. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 51: training loss = 0.0624, validation loss = 0.7722. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 52: training loss = 0.0666, validation loss = 0.7156. Learning rate = 0.00025. Patience = 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53: training loss = 0.0610, validation loss = 0.6806. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 54: training loss = 0.0783, validation loss = 0.6986. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 55: training loss = 0.0628, validation loss = 0.7330. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 56: training loss = 0.0692, validation loss = 0.7419. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 57: training loss = 0.0771, validation loss = 0.7280. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 58: training loss = 0.0584, validation loss = 0.7138. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 59: training loss = 0.0632, validation loss = 0.7664. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 60: training loss = 0.0630, validation loss = 0.7530. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 61: training loss = 0.0677, validation loss = 0.7454. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 62: training loss = 0.0637, validation loss = 0.7367. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 63: training loss = 0.0572, validation loss = 0.7315. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 64: training loss = 0.0683, validation loss = 0.7540. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 65: training loss = 0.0622, validation loss = 0.7129. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 66: training loss = 0.0627, validation loss = 0.7097. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 67: training loss = 0.0655, validation loss = 0.7161. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 68: training loss = 0.0613, validation loss = 0.7070. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 69: training loss = 0.0742, validation loss = 0.7172. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 70: training loss = 0.0660, validation loss = 0.7134. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 71: training loss = 0.0677, validation loss = 0.7338. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 72: training loss = 0.0559, validation loss = 0.7404. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 73: training loss = 0.0720, validation loss = 0.7378. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 74: training loss = 0.0576, validation loss = 0.7448. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 75: training loss = 0.0618, validation loss = 0.7532. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 76: training loss = 0.0576, validation loss = 0.7469. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 76; restoring weights from epoch 26\n",
      "Epoch 1: training loss = 0.8769, validation loss = 1.8247. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.5722, validation loss = 1.2246. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4603, validation loss = 1.0230. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.4165, validation loss = 1.0628. Learning rate = 0.001. Patience = 1\n",
      "Epoch 5: training loss = 0.4230, validation loss = 1.0989. Learning rate = 0.001. Patience = 2\n",
      "Epoch 6: training loss = 0.4007, validation loss = 1.0838. Learning rate = 0.001. Patience = 3\n",
      "Epoch 7: training loss = 0.3836, validation loss = 1.0555. Learning rate = 0.001. Patience = 4\n",
      "Epoch 8: training loss = 0.3701, validation loss = 1.0536. Learning rate = 0.001. Patience = 5\n",
      "Epoch 9: training loss = 0.3734, validation loss = 1.0670. Learning rate = 0.001. Patience = 6\n",
      "Epoch 10: training loss = 0.3698, validation loss = 1.0931. Learning rate = 0.001. Patience = 7\n",
      "Epoch 11: training loss = 0.3419, validation loss = 1.0618. Learning rate = 0.001. Patience = 8\n",
      "Epoch 12: training loss = 0.3550, validation loss = 1.0950. Learning rate = 0.001. Patience = 9\n",
      "Epoch 13: training loss = 0.3246, validation loss = 1.2400. Learning rate = 0.001. Patience = 10\n",
      "Epoch 14: training loss = 0.3156, validation loss = 1.1022. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 15: training loss = 0.3238, validation loss = 1.1209. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 16: training loss = 0.3083, validation loss = 1.1336. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 17: training loss = 0.3060, validation loss = 1.2157. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 18: training loss = 0.3063, validation loss = 1.2125. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 19: training loss = 0.2933, validation loss = 1.2755. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 20: training loss = 0.3017, validation loss = 1.1548. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 21: training loss = 0.2864, validation loss = 1.3415. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 22: training loss = 0.2872, validation loss = 1.2683. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 23: training loss = 0.2927, validation loss = 1.2700. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 24: training loss = 0.2768, validation loss = 1.3686. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 25: training loss = 0.2715, validation loss = 1.3508. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 26: training loss = 0.2684, validation loss = 1.3338. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 27: training loss = 0.2670, validation loss = 1.3151. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 28: training loss = 0.2593, validation loss = 1.3565. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 29: training loss = 0.2756, validation loss = 1.4778. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 30: training loss = 0.2708, validation loss = 1.3519. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 31: training loss = 0.2563, validation loss = 1.4149. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 32: training loss = 0.2614, validation loss = 1.5034. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 33: training loss = 0.2562, validation loss = 1.4234. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 34: training loss = 0.2672, validation loss = 1.3562. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 35: training loss = 0.2513, validation loss = 1.5641. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 36: training loss = 0.2561, validation loss = 1.5348. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 37: training loss = 0.2477, validation loss = 1.5291. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 38: training loss = 0.2524, validation loss = 1.5205. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 39: training loss = 0.2479, validation loss = 1.4956. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 40: training loss = 0.2517, validation loss = 1.5197. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 41: training loss = 0.2637, validation loss = 1.5252. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 42: training loss = 0.2430, validation loss = 1.4799. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 43: training loss = 0.2432, validation loss = 1.4994. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 44: training loss = 0.2446, validation loss = 1.5247. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 45: training loss = 0.2463, validation loss = 1.5203. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 46: training loss = 0.2458, validation loss = 1.5942. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 47: training loss = 0.2464, validation loss = 1.5832. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 48: training loss = 0.2428, validation loss = 1.5862. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 49: training loss = 0.2430, validation loss = 1.5775. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 50: training loss = 0.2393, validation loss = 1.5424. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 51: training loss = 0.2396, validation loss = 1.5470. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 52: training loss = 0.2547, validation loss = 1.5494. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 53: training loss = 0.2505, validation loss = 1.5675. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 53; restoring weights from epoch 3\n",
      "Epoch 1: training loss = 0.9470, validation loss = 0.9665. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.7030, validation loss = 0.8554. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.6153, validation loss = 0.8422. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.5533, validation loss = 0.8106. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.5245, validation loss = 0.7830. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.4716, validation loss = 0.7660. Learning rate = 0.001. Patience = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: training loss = 0.4399, validation loss = 0.7284. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.4976, validation loss = 0.7325. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.4142, validation loss = 0.7083. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.4005, validation loss = 0.7060. Learning rate = 0.001. Patience = 0\n",
      "Epoch 11: training loss = 0.3847, validation loss = 0.6869. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.3708, validation loss = 0.6946. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.3660, validation loss = 0.6780. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.3593, validation loss = 0.6830. Learning rate = 0.001. Patience = 1\n",
      "Epoch 15: training loss = 0.3892, validation loss = 0.6773. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.3564, validation loss = 0.6559. Learning rate = 0.001. Patience = 0\n",
      "Epoch 17: training loss = 0.3542, validation loss = 0.6496. Learning rate = 0.001. Patience = 0\n",
      "Epoch 18: training loss = 0.3288, validation loss = 0.6360. Learning rate = 0.001. Patience = 0\n",
      "Epoch 19: training loss = 0.3217, validation loss = 0.6243. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.3055, validation loss = 0.6186. Learning rate = 0.001. Patience = 0\n",
      "Epoch 21: training loss = 0.2883, validation loss = 0.6260. Learning rate = 0.001. Patience = 1\n",
      "Epoch 22: training loss = 0.3036, validation loss = 0.6066. Learning rate = 0.001. Patience = 0\n",
      "Epoch 23: training loss = 0.2993, validation loss = 0.6167. Learning rate = 0.001. Patience = 1\n",
      "Epoch 24: training loss = 0.3416, validation loss = 0.6350. Learning rate = 0.001. Patience = 2\n",
      "Epoch 25: training loss = 0.3032, validation loss = 0.6541. Learning rate = 0.001. Patience = 3\n",
      "Epoch 26: training loss = 0.3015, validation loss = 0.5866. Learning rate = 0.001. Patience = 0\n",
      "Epoch 27: training loss = 0.2865, validation loss = 0.5955. Learning rate = 0.001. Patience = 1\n",
      "Epoch 28: training loss = 0.2598, validation loss = 0.5939. Learning rate = 0.001. Patience = 2\n",
      "Epoch 29: training loss = 0.2608, validation loss = 0.5940. Learning rate = 0.001. Patience = 3\n",
      "Epoch 30: training loss = 0.2708, validation loss = 0.5962. Learning rate = 0.001. Patience = 4\n",
      "Epoch 31: training loss = 0.2648, validation loss = 0.5797. Learning rate = 0.001. Patience = 0\n",
      "Epoch 32: training loss = 0.2509, validation loss = 0.5841. Learning rate = 0.001. Patience = 1\n",
      "Epoch 33: training loss = 0.2656, validation loss = 0.5807. Learning rate = 0.001. Patience = 2\n",
      "Epoch 34: training loss = 0.2735, validation loss = 0.5931. Learning rate = 0.001. Patience = 3\n",
      "Epoch 35: training loss = 0.2930, validation loss = 0.5986. Learning rate = 0.001. Patience = 4\n",
      "Epoch 36: training loss = 0.2545, validation loss = 0.6021. Learning rate = 0.001. Patience = 5\n",
      "Epoch 37: training loss = 0.2782, validation loss = 0.5727. Learning rate = 0.001. Patience = 0\n",
      "Epoch 38: training loss = 0.2430, validation loss = 0.5690. Learning rate = 0.001. Patience = 0\n",
      "Epoch 39: training loss = 0.2475, validation loss = 0.5719. Learning rate = 0.001. Patience = 1\n",
      "Epoch 40: training loss = 0.2430, validation loss = 0.5706. Learning rate = 0.001. Patience = 2\n",
      "Epoch 41: training loss = 0.2339, validation loss = 0.5835. Learning rate = 0.001. Patience = 3\n",
      "Epoch 42: training loss = 0.2301, validation loss = 0.5722. Learning rate = 0.001. Patience = 4\n",
      "Epoch 43: training loss = 0.2465, validation loss = 0.5646. Learning rate = 0.001. Patience = 0\n",
      "Epoch 44: training loss = 0.2485, validation loss = 0.5836. Learning rate = 0.001. Patience = 1\n",
      "Epoch 45: training loss = 0.2307, validation loss = 0.5661. Learning rate = 0.001. Patience = 2\n",
      "Epoch 46: training loss = 0.2286, validation loss = 0.5691. Learning rate = 0.001. Patience = 3\n",
      "Epoch 47: training loss = 0.2312, validation loss = 0.5651. Learning rate = 0.001. Patience = 4\n",
      "Epoch 48: training loss = 0.2211, validation loss = 0.5699. Learning rate = 0.001. Patience = 5\n",
      "Epoch 49: training loss = 0.2257, validation loss = 0.5359. Learning rate = 0.001. Patience = 0\n",
      "Epoch 50: training loss = 0.2191, validation loss = 0.5521. Learning rate = 0.001. Patience = 1\n",
      "Epoch 51: training loss = 0.2101, validation loss = 0.5625. Learning rate = 0.001. Patience = 2\n",
      "Epoch 52: training loss = 0.2188, validation loss = 0.5397. Learning rate = 0.001. Patience = 3\n",
      "Epoch 53: training loss = 0.2093, validation loss = 0.5584. Learning rate = 0.001. Patience = 4\n",
      "Epoch 54: training loss = 0.2119, validation loss = 0.5716. Learning rate = 0.001. Patience = 5\n",
      "Epoch 55: training loss = 0.2512, validation loss = 0.5879. Learning rate = 0.001. Patience = 6\n",
      "Epoch 56: training loss = 0.1995, validation loss = 0.5473. Learning rate = 0.001. Patience = 7\n",
      "Epoch 57: training loss = 0.2163, validation loss = 0.5583. Learning rate = 0.001. Patience = 8\n",
      "Epoch 58: training loss = 0.2105, validation loss = 0.5460. Learning rate = 0.001. Patience = 9\n",
      "Epoch 59: training loss = 0.2096, validation loss = 0.5471. Learning rate = 0.001. Patience = 10\n",
      "Epoch 60: training loss = 0.2129, validation loss = 0.5787. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 61: training loss = 0.2472, validation loss = 0.5594. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 62: training loss = 0.2389, validation loss = 0.5584. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 63: training loss = 0.2013, validation loss = 0.5477. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 64: training loss = 0.2028, validation loss = 0.5394. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 65: training loss = 0.1957, validation loss = 0.5471. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 66: training loss = 0.2038, validation loss = 0.5556. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 67: training loss = 0.2042, validation loss = 0.5430. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 68: training loss = 0.2323, validation loss = 0.5486. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 69: training loss = 0.1988, validation loss = 0.5534. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 70: training loss = 0.1980, validation loss = 0.5638. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 71: training loss = 0.1972, validation loss = 0.5497. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 72: training loss = 0.2002, validation loss = 0.5430. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 73: training loss = 0.1887, validation loss = 0.5411. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 74: training loss = 0.1894, validation loss = 0.5485. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 75: training loss = 0.1961, validation loss = 0.5381. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 76: training loss = 0.2080, validation loss = 0.5416. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 77: training loss = 0.1909, validation loss = 0.5427. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 78: training loss = 0.1844, validation loss = 0.5324. Learning rate = 0.00025. Patience = 0\n",
      "Epoch 79: training loss = 0.2005, validation loss = 0.5400. Learning rate = 0.00025. Patience = 1\n",
      "Epoch 80: training loss = 0.1946, validation loss = 0.5547. Learning rate = 0.00025. Patience = 2\n",
      "Epoch 81: training loss = 0.2294, validation loss = 0.5372. Learning rate = 0.00025. Patience = 3\n",
      "Epoch 82: training loss = 0.1885, validation loss = 0.5418. Learning rate = 0.00025. Patience = 4\n",
      "Epoch 83: training loss = 0.1878, validation loss = 0.5562. Learning rate = 0.00025. Patience = 5\n",
      "Epoch 84: training loss = 0.1895, validation loss = 0.5411. Learning rate = 0.00025. Patience = 6\n",
      "Epoch 85: training loss = 0.1873, validation loss = 0.5374. Learning rate = 0.00025. Patience = 7\n",
      "Epoch 86: training loss = 0.1940, validation loss = 0.5476. Learning rate = 0.00025. Patience = 8\n",
      "Epoch 87: training loss = 0.1851, validation loss = 0.5410. Learning rate = 0.00025. Patience = 9\n",
      "Epoch 88: training loss = 0.1897, validation loss = 0.5354. Learning rate = 0.00025. Patience = 10\n",
      "Epoch 89: training loss = 0.1807, validation loss = 0.5402. Learning rate = 0.000125. Patience = 11\n",
      "Epoch 90: training loss = 0.1934, validation loss = 0.5380. Learning rate = 0.000125. Patience = 12\n",
      "Epoch 91: training loss = 0.1817, validation loss = 0.5418. Learning rate = 0.000125. Patience = 13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92: training loss = 0.1922, validation loss = 0.5378. Learning rate = 0.000125. Patience = 14\n",
      "Epoch 93: training loss = 0.2147, validation loss = 0.5359. Learning rate = 0.000125. Patience = 15\n",
      "Epoch 94: training loss = 0.1786, validation loss = 0.5327. Learning rate = 0.000125. Patience = 16\n",
      "Epoch 95: training loss = 0.1841, validation loss = 0.5365. Learning rate = 0.000125. Patience = 17\n",
      "Epoch 96: training loss = 0.1893, validation loss = 0.5414. Learning rate = 0.000125. Patience = 18\n",
      "Epoch 97: training loss = 0.1818, validation loss = 0.5418. Learning rate = 0.000125. Patience = 19\n",
      "Epoch 98: training loss = 0.1911, validation loss = 0.5397. Learning rate = 0.000125. Patience = 20\n",
      "Epoch 99: training loss = 0.1812, validation loss = 0.5414. Learning rate = 0.000125. Patience = 21\n",
      "Epoch 100: training loss = 0.1872, validation loss = 0.5379. Learning rate = 6.25e-05. Patience = 22\n",
      "Epoch 101: training loss = 0.1802, validation loss = 0.5379. Learning rate = 6.25e-05. Patience = 23\n",
      "Epoch 102: training loss = 0.1867, validation loss = 0.5395. Learning rate = 6.25e-05. Patience = 24\n",
      "Epoch 103: training loss = 0.1785, validation loss = 0.5422. Learning rate = 6.25e-05. Patience = 25\n",
      "Epoch 104: training loss = 0.2164, validation loss = 0.5399. Learning rate = 6.25e-05. Patience = 26\n",
      "Epoch 105: training loss = 0.1801, validation loss = 0.5391. Learning rate = 6.25e-05. Patience = 27\n",
      "Epoch 106: training loss = 0.1806, validation loss = 0.5392. Learning rate = 6.25e-05. Patience = 28\n",
      "Epoch 107: training loss = 0.1774, validation loss = 0.5421. Learning rate = 6.25e-05. Patience = 29\n",
      "Epoch 108: training loss = 0.1882, validation loss = 0.5444. Learning rate = 6.25e-05. Patience = 30\n",
      "Epoch 109: training loss = 0.1851, validation loss = 0.5462. Learning rate = 6.25e-05. Patience = 31\n",
      "Epoch 110: training loss = 0.1885, validation loss = 0.5432. Learning rate = 6.25e-05. Patience = 32\n",
      "Epoch 111: training loss = 0.2110, validation loss = 0.5432. Learning rate = 3.125e-05. Patience = 33\n",
      "Epoch 112: training loss = 0.1815, validation loss = 0.5433. Learning rate = 3.125e-05. Patience = 34\n",
      "Epoch 113: training loss = 0.1825, validation loss = 0.5423. Learning rate = 3.125e-05. Patience = 35\n",
      "Epoch 114: training loss = 0.1815, validation loss = 0.5411. Learning rate = 3.125e-05. Patience = 36\n",
      "Epoch 115: training loss = 0.2072, validation loss = 0.5403. Learning rate = 3.125e-05. Patience = 37\n",
      "Epoch 116: training loss = 0.2399, validation loss = 0.5410. Learning rate = 3.125e-05. Patience = 38\n",
      "Epoch 117: training loss = 0.1813, validation loss = 0.5414. Learning rate = 3.125e-05. Patience = 39\n",
      "Epoch 118: training loss = 0.2064, validation loss = 0.5416. Learning rate = 3.125e-05. Patience = 40\n",
      "Epoch 119: training loss = 0.1808, validation loss = 0.5414. Learning rate = 3.125e-05. Patience = 41\n",
      "Epoch 120: training loss = 0.1869, validation loss = 0.5399. Learning rate = 3.125e-05. Patience = 42\n",
      "Epoch 121: training loss = 0.1780, validation loss = 0.5406. Learning rate = 3.125e-05. Patience = 43\n",
      "Epoch 122: training loss = 0.1845, validation loss = 0.5403. Learning rate = 1.5625e-05. Patience = 44\n",
      "Epoch 123: training loss = 0.1863, validation loss = 0.5404. Learning rate = 1.5625e-05. Patience = 45\n",
      "Epoch 124: training loss = 0.1853, validation loss = 0.5394. Learning rate = 1.5625e-05. Patience = 46\n",
      "Epoch 125: training loss = 0.1792, validation loss = 0.5391. Learning rate = 1.5625e-05. Patience = 47\n",
      "Epoch 126: training loss = 0.1824, validation loss = 0.5392. Learning rate = 1.5625e-05. Patience = 48\n",
      "Epoch 127: training loss = 0.1783, validation loss = 0.5401. Learning rate = 1.5625e-05. Patience = 49\n",
      "Epoch 128: training loss = 0.1797, validation loss = 0.5408. Learning rate = 1.5625e-05. Patience = 50\n",
      "Training stopped at epoch 128; restoring weights from epoch 78\n",
      "Epoch 1: training loss = 0.8552, validation loss = 1.0381. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.7190, validation loss = 0.8942. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.6411, validation loss = 0.9213. Learning rate = 0.001. Patience = 1\n",
      "Epoch 4: training loss = 0.6149, validation loss = 0.9007. Learning rate = 0.001. Patience = 2\n",
      "Epoch 5: training loss = 0.6072, validation loss = 0.9145. Learning rate = 0.001. Patience = 3\n",
      "Epoch 6: training loss = 0.5763, validation loss = 0.9367. Learning rate = 0.001. Patience = 4\n",
      "Epoch 7: training loss = 0.5665, validation loss = 0.9479. Learning rate = 0.001. Patience = 5\n",
      "Epoch 8: training loss = 0.5739, validation loss = 0.9166. Learning rate = 0.001. Patience = 6\n",
      "Epoch 9: training loss = 0.5595, validation loss = 0.9278. Learning rate = 0.001. Patience = 7\n",
      "Epoch 10: training loss = 0.5686, validation loss = 0.9137. Learning rate = 0.001. Patience = 8\n",
      "Epoch 11: training loss = 0.5528, validation loss = 0.9338. Learning rate = 0.001. Patience = 9\n",
      "Epoch 12: training loss = 0.5489, validation loss = 0.9648. Learning rate = 0.001. Patience = 10\n",
      "Epoch 13: training loss = 0.5317, validation loss = 0.9258. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 14: training loss = 0.5446, validation loss = 0.9436. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 15: training loss = 0.5204, validation loss = 0.9403. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 16: training loss = 0.5240, validation loss = 0.9422. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 17: training loss = 0.5666, validation loss = 0.9106. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 18: training loss = 0.5290, validation loss = 0.9186. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 19: training loss = 0.5190, validation loss = 0.9254. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 20: training loss = 0.5270, validation loss = 0.9323. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 21: training loss = 0.5434, validation loss = 0.9187. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 22: training loss = 0.5340, validation loss = 0.9127. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 23: training loss = 0.5143, validation loss = 0.9317. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 24: training loss = 0.5257, validation loss = 0.9519. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 25: training loss = 0.5036, validation loss = 0.9347. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 26: training loss = 0.5152, validation loss = 0.9250. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 27: training loss = 0.4955, validation loss = 0.9301. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 28: training loss = 0.4997, validation loss = 0.9530. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 29: training loss = 0.5072, validation loss = 0.9456. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 30: training loss = 0.5309, validation loss = 0.9368. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 31: training loss = 0.5027, validation loss = 0.9204. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 32: training loss = 0.5006, validation loss = 0.9219. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 33: training loss = 0.5094, validation loss = 0.9342. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 34: training loss = 0.5052, validation loss = 0.9420. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 35: training loss = 0.5062, validation loss = 0.9405. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 36: training loss = 0.5051, validation loss = 0.9452. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 37: training loss = 0.4844, validation loss = 0.9321. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 38: training loss = 0.4895, validation loss = 0.9305. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 39: training loss = 0.5120, validation loss = 0.9325. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 40: training loss = 0.4925, validation loss = 0.9317. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 41: training loss = 0.4957, validation loss = 0.9348. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 42: training loss = 0.5084, validation loss = 0.9339. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 43: training loss = 0.4961, validation loss = 0.9346. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 44: training loss = 0.4977, validation loss = 0.9287. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 45: training loss = 0.4843, validation loss = 0.9264. Learning rate = 0.000125. Patience = 43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46: training loss = 0.4973, validation loss = 0.9278. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 47: training loss = 0.4920, validation loss = 0.9276. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 48: training loss = 0.4909, validation loss = 0.9301. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 49: training loss = 0.4816, validation loss = 0.9295. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 50: training loss = 0.5069, validation loss = 0.9324. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 51: training loss = 0.4918, validation loss = 0.9327. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 52: training loss = 0.5055, validation loss = 0.9322. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 52; restoring weights from epoch 2\n",
      "Epoch 1: training loss = 0.8541, validation loss = 0.3981. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.3533, validation loss = 0.3889. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3094, validation loss = 0.4119. Learning rate = 0.001. Patience = 1\n",
      "Epoch 4: training loss = 0.2793, validation loss = 0.3689. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2552, validation loss = 0.3627. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2395, validation loss = 0.3504. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2695, validation loss = 0.3373. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.2428, validation loss = 0.3320. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.2434, validation loss = 0.3231. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2466, validation loss = 0.3175. Learning rate = 0.001. Patience = 0\n",
      "Epoch 11: training loss = 0.2538, validation loss = 0.3182. Learning rate = 0.001. Patience = 1\n",
      "Epoch 12: training loss = 0.2370, validation loss = 0.3150. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.2378, validation loss = 0.3141. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.2339, validation loss = 0.3117. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.2317, validation loss = 0.3117. Learning rate = 0.001. Patience = 1\n",
      "Epoch 16: training loss = 0.2327, validation loss = 0.3130. Learning rate = 0.001. Patience = 2\n",
      "Epoch 17: training loss = 0.2368, validation loss = 0.3079. Learning rate = 0.001. Patience = 0\n",
      "Epoch 18: training loss = 0.2370, validation loss = 0.3080. Learning rate = 0.001. Patience = 1\n",
      "Epoch 19: training loss = 0.2485, validation loss = 0.3075. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.2152, validation loss = 0.3101. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.2348, validation loss = 0.3195. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.2130, validation loss = 0.3035. Learning rate = 0.001. Patience = 0\n",
      "Epoch 23: training loss = 0.2137, validation loss = 0.3147. Learning rate = 0.001. Patience = 1\n",
      "Epoch 24: training loss = 0.2169, validation loss = 0.3070. Learning rate = 0.001. Patience = 2\n",
      "Epoch 25: training loss = 0.2049, validation loss = 0.3322. Learning rate = 0.001. Patience = 3\n",
      "Epoch 26: training loss = 0.2194, validation loss = 0.3103. Learning rate = 0.001. Patience = 4\n",
      "Epoch 27: training loss = 0.2166, validation loss = 0.3266. Learning rate = 0.001. Patience = 5\n",
      "Epoch 28: training loss = 0.2176, validation loss = 0.3054. Learning rate = 0.001. Patience = 6\n",
      "Epoch 29: training loss = 0.2082, validation loss = 0.3045. Learning rate = 0.001. Patience = 7\n",
      "Epoch 30: training loss = 0.2060, validation loss = 0.3255. Learning rate = 0.001. Patience = 8\n",
      "Epoch 31: training loss = 0.2003, validation loss = 0.3064. Learning rate = 0.001. Patience = 9\n",
      "Epoch 32: training loss = 0.1968, validation loss = 0.3434. Learning rate = 0.001. Patience = 10\n",
      "Epoch 33: training loss = 0.2221, validation loss = 0.3128. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 34: training loss = 0.1984, validation loss = 0.3298. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 35: training loss = 0.2049, validation loss = 0.3302. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 36: training loss = 0.1892, validation loss = 0.3205. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 37: training loss = 0.2042, validation loss = 0.3259. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 38: training loss = 0.1846, validation loss = 0.3337. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 39: training loss = 0.1991, validation loss = 0.3285. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 40: training loss = 0.2153, validation loss = 0.3342. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 41: training loss = 0.2206, validation loss = 0.3216. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 42: training loss = 0.1872, validation loss = 0.3408. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 43: training loss = 0.1997, validation loss = 0.3278. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 44: training loss = 0.1929, validation loss = 0.3248. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 45: training loss = 0.2059, validation loss = 0.3189. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 46: training loss = 0.1942, validation loss = 0.3309. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 47: training loss = 0.2059, validation loss = 0.3265. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 48: training loss = 0.1935, validation loss = 0.3202. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 49: training loss = 0.1913, validation loss = 0.3249. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 50: training loss = 0.1868, validation loss = 0.3284. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 51: training loss = 0.1825, validation loss = 0.3277. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 52: training loss = 0.2118, validation loss = 0.3328. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 53: training loss = 0.1834, validation loss = 0.3336. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 54: training loss = 0.1953, validation loss = 0.3354. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 55: training loss = 0.1990, validation loss = 0.3293. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 56: training loss = 0.1844, validation loss = 0.3285. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 57: training loss = 0.1879, validation loss = 0.3310. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 58: training loss = 0.1886, validation loss = 0.3275. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 59: training loss = 0.1771, validation loss = 0.3262. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 60: training loss = 0.1785, validation loss = 0.3293. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 61: training loss = 0.1831, validation loss = 0.3273. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 62: training loss = 0.1995, validation loss = 0.3353. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 63: training loss = 0.1947, validation loss = 0.3325. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 64: training loss = 0.1863, validation loss = 0.3298. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 65: training loss = 0.1833, validation loss = 0.3281. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 66: training loss = 0.1957, validation loss = 0.3317. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 67: training loss = 0.1846, validation loss = 0.3360. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 68: training loss = 0.2018, validation loss = 0.3322. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 69: training loss = 0.1945, validation loss = 0.3257. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 70: training loss = 0.1822, validation loss = 0.3285. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 71: training loss = 0.2008, validation loss = 0.3309. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 72: training loss = 0.1828, validation loss = 0.3299. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 72; restoring weights from epoch 22\n",
      "Epoch 1: training loss = 0.6739, validation loss = 1.3465. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.3023, validation loss = 1.1305. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.2737, validation loss = 1.1412. Learning rate = 0.001. Patience = 1\n",
      "Epoch 4: training loss = 0.2607, validation loss = 0.9823. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2097, validation loss = 0.8509. Learning rate = 0.001. Patience = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: training loss = 0.1853, validation loss = 0.7685. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.1739, validation loss = 0.7442. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.1625, validation loss = 0.7418. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.1664, validation loss = 0.7422. Learning rate = 0.001. Patience = 1\n",
      "Epoch 10: training loss = 0.1592, validation loss = 0.7438. Learning rate = 0.001. Patience = 2\n",
      "Epoch 11: training loss = 0.1600, validation loss = 0.7462. Learning rate = 0.001. Patience = 3\n",
      "Epoch 12: training loss = 0.1609, validation loss = 0.7455. Learning rate = 0.001. Patience = 4\n",
      "Epoch 13: training loss = 0.1671, validation loss = 0.7471. Learning rate = 0.001. Patience = 5\n",
      "Epoch 14: training loss = 0.1563, validation loss = 0.7556. Learning rate = 0.001. Patience = 6\n",
      "Epoch 15: training loss = 0.1499, validation loss = 0.7745. Learning rate = 0.001. Patience = 7\n",
      "Epoch 16: training loss = 0.1460, validation loss = 0.7632. Learning rate = 0.001. Patience = 8\n",
      "Epoch 17: training loss = 0.1606, validation loss = 0.7626. Learning rate = 0.001. Patience = 9\n",
      "Epoch 18: training loss = 0.1611, validation loss = 0.7585. Learning rate = 0.001. Patience = 10\n",
      "Epoch 19: training loss = 0.1510, validation loss = 0.7597. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 20: training loss = 0.1592, validation loss = 0.7401. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 21: training loss = 0.1472, validation loss = 0.7315. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 22: training loss = 0.1537, validation loss = 0.7418. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 23: training loss = 0.1661, validation loss = 0.7362. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 24: training loss = 0.1474, validation loss = 0.7516. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 25: training loss = 0.1394, validation loss = 0.7592. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 26: training loss = 0.1456, validation loss = 0.7579. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 27: training loss = 0.1492, validation loss = 0.7562. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 28: training loss = 0.1629, validation loss = 0.7523. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 29: training loss = 0.1414, validation loss = 0.7491. Learning rate = 0.0005. Patience = 8\n",
      "Epoch 30: training loss = 0.1557, validation loss = 0.7538. Learning rate = 0.0005. Patience = 9\n",
      "Epoch 31: training loss = 0.1447, validation loss = 0.7393. Learning rate = 0.0005. Patience = 10\n",
      "Epoch 32: training loss = 0.1513, validation loss = 0.7779. Learning rate = 0.00025. Patience = 11\n",
      "Epoch 33: training loss = 0.1495, validation loss = 0.7655. Learning rate = 0.00025. Patience = 12\n",
      "Epoch 34: training loss = 0.1364, validation loss = 0.7553. Learning rate = 0.00025. Patience = 13\n",
      "Epoch 35: training loss = 0.1486, validation loss = 0.7711. Learning rate = 0.00025. Patience = 14\n",
      "Epoch 36: training loss = 0.1396, validation loss = 0.7756. Learning rate = 0.00025. Patience = 15\n",
      "Epoch 37: training loss = 0.1437, validation loss = 0.7570. Learning rate = 0.00025. Patience = 16\n",
      "Epoch 38: training loss = 0.1380, validation loss = 0.7955. Learning rate = 0.00025. Patience = 17\n",
      "Epoch 39: training loss = 0.1393, validation loss = 0.7632. Learning rate = 0.00025. Patience = 18\n",
      "Epoch 40: training loss = 0.1376, validation loss = 0.7428. Learning rate = 0.00025. Patience = 19\n",
      "Epoch 41: training loss = 0.1460, validation loss = 0.7602. Learning rate = 0.00025. Patience = 20\n",
      "Epoch 42: training loss = 0.1366, validation loss = 0.7743. Learning rate = 0.00025. Patience = 21\n",
      "Epoch 43: training loss = 0.1335, validation loss = 0.7591. Learning rate = 0.000125. Patience = 22\n",
      "Epoch 44: training loss = 0.1371, validation loss = 0.7641. Learning rate = 0.000125. Patience = 23\n",
      "Epoch 45: training loss = 0.1403, validation loss = 0.7721. Learning rate = 0.000125. Patience = 24\n",
      "Epoch 46: training loss = 0.1356, validation loss = 0.7674. Learning rate = 0.000125. Patience = 25\n",
      "Epoch 47: training loss = 0.1379, validation loss = 0.7676. Learning rate = 0.000125. Patience = 26\n",
      "Epoch 48: training loss = 0.1357, validation loss = 0.7640. Learning rate = 0.000125. Patience = 27\n",
      "Epoch 49: training loss = 0.1324, validation loss = 0.7693. Learning rate = 0.000125. Patience = 28\n",
      "Epoch 50: training loss = 0.1555, validation loss = 0.7771. Learning rate = 0.000125. Patience = 29\n",
      "Epoch 51: training loss = 0.1340, validation loss = 0.7654. Learning rate = 0.000125. Patience = 30\n",
      "Epoch 52: training loss = 0.1304, validation loss = 0.7666. Learning rate = 0.000125. Patience = 31\n",
      "Epoch 53: training loss = 0.1488, validation loss = 0.7739. Learning rate = 0.000125. Patience = 32\n",
      "Epoch 54: training loss = 0.1410, validation loss = 0.7797. Learning rate = 6.25e-05. Patience = 33\n",
      "Epoch 55: training loss = 0.1357, validation loss = 0.7834. Learning rate = 6.25e-05. Patience = 34\n",
      "Epoch 56: training loss = 0.1423, validation loss = 0.7792. Learning rate = 6.25e-05. Patience = 35\n",
      "Epoch 57: training loss = 0.1374, validation loss = 0.7735. Learning rate = 6.25e-05. Patience = 36\n",
      "Epoch 58: training loss = 0.1364, validation loss = 0.7754. Learning rate = 6.25e-05. Patience = 37\n",
      "Epoch 59: training loss = 0.1394, validation loss = 0.7765. Learning rate = 6.25e-05. Patience = 38\n",
      "Epoch 60: training loss = 0.1311, validation loss = 0.7796. Learning rate = 6.25e-05. Patience = 39\n",
      "Epoch 61: training loss = 0.1385, validation loss = 0.7816. Learning rate = 6.25e-05. Patience = 40\n",
      "Epoch 62: training loss = 0.1417, validation loss = 0.7824. Learning rate = 6.25e-05. Patience = 41\n",
      "Epoch 63: training loss = 0.1325, validation loss = 0.7770. Learning rate = 6.25e-05. Patience = 42\n",
      "Epoch 64: training loss = 0.1332, validation loss = 0.7761. Learning rate = 6.25e-05. Patience = 43\n",
      "Epoch 65: training loss = 0.1412, validation loss = 0.7827. Learning rate = 3.125e-05. Patience = 44\n",
      "Epoch 66: training loss = 0.1339, validation loss = 0.7842. Learning rate = 3.125e-05. Patience = 45\n",
      "Epoch 67: training loss = 0.1326, validation loss = 0.7825. Learning rate = 3.125e-05. Patience = 46\n",
      "Epoch 68: training loss = 0.1400, validation loss = 0.7822. Learning rate = 3.125e-05. Patience = 47\n",
      "Epoch 69: training loss = 0.1426, validation loss = 0.7850. Learning rate = 3.125e-05. Patience = 48\n",
      "Epoch 70: training loss = 0.1332, validation loss = 0.7826. Learning rate = 3.125e-05. Patience = 49\n",
      "Epoch 71: training loss = 0.1515, validation loss = 0.7827. Learning rate = 3.125e-05. Patience = 50\n",
      "Training stopped at epoch 71; restoring weights from epoch 21\n",
      "Epoch 1: training loss = 0.6363, validation loss = 0.3708. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.5277, validation loss = 0.3376. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4182, validation loss = 0.2750. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.4005, validation loss = 0.2662. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.3849, validation loss = 0.2768. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.3761, validation loss = 0.2643. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.3649, validation loss = 0.2657. Learning rate = 0.001. Patience = 1\n",
      "Epoch 8: training loss = 0.3664, validation loss = 0.2669. Learning rate = 0.001. Patience = 2\n",
      "Epoch 9: training loss = 0.3454, validation loss = 0.2550. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.3447, validation loss = 0.2570. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.3362, validation loss = 0.2569. Learning rate = 0.001. Patience = 2\n",
      "Epoch 12: training loss = 0.3413, validation loss = 0.2592. Learning rate = 0.001. Patience = 3\n",
      "Epoch 13: training loss = 0.3312, validation loss = 0.2562. Learning rate = 0.001. Patience = 4\n",
      "Epoch 14: training loss = 0.3478, validation loss = 0.2497. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.3298, validation loss = 0.2602. Learning rate = 0.001. Patience = 1\n",
      "Epoch 16: training loss = 0.3276, validation loss = 0.2626. Learning rate = 0.001. Patience = 2\n",
      "Epoch 17: training loss = 0.3178, validation loss = 0.2554. Learning rate = 0.001. Patience = 3\n",
      "Epoch 18: training loss = 0.3194, validation loss = 0.2528. Learning rate = 0.001. Patience = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: training loss = 0.3211, validation loss = 0.2589. Learning rate = 0.001. Patience = 5\n",
      "Epoch 20: training loss = 0.3194, validation loss = 0.2517. Learning rate = 0.001. Patience = 6\n",
      "Epoch 21: training loss = 0.3237, validation loss = 0.2460. Learning rate = 0.001. Patience = 0\n",
      "Epoch 22: training loss = 0.3110, validation loss = 0.2478. Learning rate = 0.001. Patience = 1\n",
      "Epoch 23: training loss = 0.3144, validation loss = 0.2496. Learning rate = 0.001. Patience = 2\n",
      "Epoch 24: training loss = 0.3128, validation loss = 0.2664. Learning rate = 0.001. Patience = 3\n",
      "Epoch 25: training loss = 0.3150, validation loss = 0.2484. Learning rate = 0.001. Patience = 4\n",
      "Epoch 26: training loss = 0.3033, validation loss = 0.2511. Learning rate = 0.001. Patience = 5\n",
      "Epoch 27: training loss = 0.3005, validation loss = 0.2520. Learning rate = 0.001. Patience = 6\n",
      "Epoch 28: training loss = 0.3004, validation loss = 0.2618. Learning rate = 0.001. Patience = 7\n",
      "Epoch 29: training loss = 0.3041, validation loss = 0.2543. Learning rate = 0.001. Patience = 8\n",
      "Epoch 30: training loss = 0.3023, validation loss = 0.2541. Learning rate = 0.001. Patience = 9\n",
      "Epoch 31: training loss = 0.3137, validation loss = 0.2382. Learning rate = 0.001. Patience = 0\n",
      "Epoch 32: training loss = 0.2932, validation loss = 0.2546. Learning rate = 0.001. Patience = 1\n",
      "Epoch 33: training loss = 0.2956, validation loss = 0.2793. Learning rate = 0.001. Patience = 2\n",
      "Epoch 34: training loss = 0.2954, validation loss = 0.2578. Learning rate = 0.001. Patience = 3\n",
      "Epoch 35: training loss = 0.2969, validation loss = 0.2775. Learning rate = 0.001. Patience = 4\n",
      "Epoch 36: training loss = 0.2925, validation loss = 0.2505. Learning rate = 0.001. Patience = 5\n",
      "Epoch 37: training loss = 0.2899, validation loss = 0.2472. Learning rate = 0.001. Patience = 6\n",
      "Epoch 38: training loss = 0.2941, validation loss = 0.2884. Learning rate = 0.001. Patience = 7\n",
      "Epoch 39: training loss = 0.2930, validation loss = 0.2564. Learning rate = 0.001. Patience = 8\n",
      "Epoch 40: training loss = 0.2807, validation loss = 0.2450. Learning rate = 0.001. Patience = 9\n",
      "Epoch 41: training loss = 0.2803, validation loss = 0.2513. Learning rate = 0.001. Patience = 10\n",
      "Epoch 42: training loss = 0.2764, validation loss = 0.2575. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 43: training loss = 0.2728, validation loss = 0.2485. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 44: training loss = 0.2772, validation loss = 0.2599. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 45: training loss = 0.2666, validation loss = 0.2575. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 46: training loss = 0.2631, validation loss = 0.2602. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 47: training loss = 0.2851, validation loss = 0.2606. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 48: training loss = 0.2704, validation loss = 0.2553. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 49: training loss = 0.2604, validation loss = 0.2627. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 50: training loss = 0.2633, validation loss = 0.2568. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 51: training loss = 0.2669, validation loss = 0.2576. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 52: training loss = 0.2562, validation loss = 0.2567. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 53: training loss = 0.2535, validation loss = 0.2620. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 54: training loss = 0.2574, validation loss = 0.2581. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 55: training loss = 0.2668, validation loss = 0.2614. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 56: training loss = 0.2668, validation loss = 0.2610. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 57: training loss = 0.2627, validation loss = 0.2597. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 58: training loss = 0.2624, validation loss = 0.2653. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 59: training loss = 0.2539, validation loss = 0.2645. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 60: training loss = 0.2592, validation loss = 0.2606. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 61: training loss = 0.2585, validation loss = 0.2623. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 62: training loss = 0.2498, validation loss = 0.2624. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 63: training loss = 0.2533, validation loss = 0.2631. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 64: training loss = 0.2465, validation loss = 0.2627. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 65: training loss = 0.2453, validation loss = 0.2596. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 66: training loss = 0.2485, validation loss = 0.2614. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 67: training loss = 0.2519, validation loss = 0.2618. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 68: training loss = 0.2532, validation loss = 0.2614. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 69: training loss = 0.2424, validation loss = 0.2595. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 70: training loss = 0.2537, validation loss = 0.2622. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 71: training loss = 0.2535, validation loss = 0.2678. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 72: training loss = 0.2436, validation loss = 0.2628. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 73: training loss = 0.2486, validation loss = 0.2595. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 74: training loss = 0.2428, validation loss = 0.2617. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 75: training loss = 0.2517, validation loss = 0.2659. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 76: training loss = 0.2415, validation loss = 0.2628. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 77: training loss = 0.2500, validation loss = 0.2627. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 78: training loss = 0.2410, validation loss = 0.2630. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 79: training loss = 0.2523, validation loss = 0.2617. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 80: training loss = 0.2399, validation loss = 0.2638. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 81: training loss = 0.2392, validation loss = 0.2626. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 81; restoring weights from epoch 31\n",
      "Epoch 1: training loss = 0.6350, validation loss = 0.4443. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4232, validation loss = 0.4235. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3573, validation loss = 0.5271. Learning rate = 0.001. Patience = 1\n",
      "Epoch 4: training loss = 0.3161, validation loss = 0.3612. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.3464, validation loss = 0.3245. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2992, validation loss = 0.3194. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2911, validation loss = 0.2665. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.3099, validation loss = 0.2882. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.3163, validation loss = 0.2668. Learning rate = 0.001. Patience = 2\n",
      "Epoch 10: training loss = 0.2852, validation loss = 0.2598. Learning rate = 0.001. Patience = 0\n",
      "Epoch 11: training loss = 0.2799, validation loss = 0.2604. Learning rate = 0.001. Patience = 1\n",
      "Epoch 12: training loss = 0.2687, validation loss = 0.2565. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.2676, validation loss = 0.2548. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.2820, validation loss = 0.2566. Learning rate = 0.001. Patience = 1\n",
      "Epoch 15: training loss = 0.2791, validation loss = 0.2427. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.2657, validation loss = 0.2534. Learning rate = 0.001. Patience = 1\n",
      "Epoch 17: training loss = 0.2700, validation loss = 0.2588. Learning rate = 0.001. Patience = 2\n",
      "Epoch 18: training loss = 0.3340, validation loss = 0.2311. Learning rate = 0.001. Patience = 0\n",
      "Epoch 19: training loss = 0.3211, validation loss = 0.2705. Learning rate = 0.001. Patience = 1\n",
      "Epoch 20: training loss = 0.2532, validation loss = 0.2358. Learning rate = 0.001. Patience = 2\n",
      "Epoch 21: training loss = 0.2764, validation loss = 0.2514. Learning rate = 0.001. Patience = 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: training loss = 0.2601, validation loss = 0.2308. Learning rate = 0.001. Patience = 0\n",
      "Epoch 23: training loss = 0.2748, validation loss = 0.2404. Learning rate = 0.001. Patience = 1\n",
      "Epoch 24: training loss = 0.2744, validation loss = 0.2738. Learning rate = 0.001. Patience = 2\n",
      "Epoch 25: training loss = 0.2590, validation loss = 0.2365. Learning rate = 0.001. Patience = 3\n",
      "Epoch 26: training loss = 0.2630, validation loss = 0.2378. Learning rate = 0.001. Patience = 4\n",
      "Epoch 27: training loss = 0.2659, validation loss = 0.2760. Learning rate = 0.001. Patience = 5\n",
      "Epoch 28: training loss = 0.2719, validation loss = 0.2288. Learning rate = 0.001. Patience = 0\n",
      "Epoch 29: training loss = 0.2828, validation loss = 0.2817. Learning rate = 0.001. Patience = 1\n",
      "Epoch 30: training loss = 0.2764, validation loss = 0.2538. Learning rate = 0.001. Patience = 2\n",
      "Epoch 31: training loss = 0.2521, validation loss = 0.2437. Learning rate = 0.001. Patience = 3\n",
      "Epoch 32: training loss = 0.2639, validation loss = 0.2655. Learning rate = 0.001. Patience = 4\n",
      "Epoch 33: training loss = 0.2955, validation loss = 0.2454. Learning rate = 0.001. Patience = 5\n",
      "Epoch 34: training loss = 0.2494, validation loss = 0.2770. Learning rate = 0.001. Patience = 6\n",
      "Epoch 35: training loss = 0.3253, validation loss = 0.2324. Learning rate = 0.001. Patience = 7\n",
      "Epoch 36: training loss = 0.2675, validation loss = 0.2743. Learning rate = 0.001. Patience = 8\n",
      "Epoch 37: training loss = 0.2582, validation loss = 0.2449. Learning rate = 0.001. Patience = 9\n",
      "Epoch 38: training loss = 0.2450, validation loss = 0.2573. Learning rate = 0.001. Patience = 10\n",
      "Epoch 39: training loss = 0.2510, validation loss = 0.2558. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 40: training loss = 0.2646, validation loss = 0.2410. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 41: training loss = 0.2660, validation loss = 0.2795. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 42: training loss = 0.2620, validation loss = 0.2654. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 43: training loss = 0.2725, validation loss = 0.2755. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 44: training loss = 0.2577, validation loss = 0.2594. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 45: training loss = 0.2578, validation loss = 0.2520. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 46: training loss = 0.2445, validation loss = 0.2756. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 47: training loss = 0.2455, validation loss = 0.2734. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 48: training loss = 0.2480, validation loss = 0.2471. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 49: training loss = 0.2836, validation loss = 0.2763. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 50: training loss = 0.2450, validation loss = 0.2728. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 51: training loss = 0.2563, validation loss = 0.2603. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 52: training loss = 0.2873, validation loss = 0.2759. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 53: training loss = 0.2592, validation loss = 0.2775. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 54: training loss = 0.2383, validation loss = 0.2751. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 55: training loss = 0.2423, validation loss = 0.2634. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 56: training loss = 0.2584, validation loss = 0.2608. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 57: training loss = 0.2415, validation loss = 0.2833. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 58: training loss = 0.2357, validation loss = 0.2782. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 59: training loss = 0.2639, validation loss = 0.2679. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 60: training loss = 0.2614, validation loss = 0.2687. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 61: training loss = 0.2576, validation loss = 0.2885. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 62: training loss = 0.2727, validation loss = 0.2840. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 63: training loss = 0.2400, validation loss = 0.2752. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 64: training loss = 0.2331, validation loss = 0.2631. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 65: training loss = 0.2566, validation loss = 0.2634. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 66: training loss = 0.2527, validation loss = 0.2764. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 67: training loss = 0.2800, validation loss = 0.2834. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 68: training loss = 0.2718, validation loss = 0.2906. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 69: training loss = 0.2580, validation loss = 0.2838. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 70: training loss = 0.2478, validation loss = 0.2827. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 71: training loss = 0.2352, validation loss = 0.2688. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 72: training loss = 0.2525, validation loss = 0.2717. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 73: training loss = 0.2628, validation loss = 0.2734. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 74: training loss = 0.2678, validation loss = 0.2696. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 75: training loss = 0.2590, validation loss = 0.2784. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 76: training loss = 0.2508, validation loss = 0.2833. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 77: training loss = 0.2454, validation loss = 0.2797. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 78: training loss = 0.2796, validation loss = 0.2760. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 78; restoring weights from epoch 28\n",
      "Epoch 1: training loss = 0.5691, validation loss = 0.6931. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4314, validation loss = 0.4268. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3519, validation loss = 0.3229. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3321, validation loss = 0.2152. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2957, validation loss = 0.2670. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.3173, validation loss = 0.1940. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2717, validation loss = 0.2051. Learning rate = 0.001. Patience = 1\n",
      "Epoch 8: training loss = 0.2774, validation loss = 0.2308. Learning rate = 0.001. Patience = 2\n",
      "Epoch 9: training loss = 0.2819, validation loss = 0.1850. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2582, validation loss = 0.2227. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2738, validation loss = 0.1823. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.2635, validation loss = 0.1799. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.2489, validation loss = 0.2047. Learning rate = 0.001. Patience = 1\n",
      "Epoch 14: training loss = 0.2680, validation loss = 0.1801. Learning rate = 0.001. Patience = 2\n",
      "Epoch 15: training loss = 0.2583, validation loss = 0.1962. Learning rate = 0.001. Patience = 3\n",
      "Epoch 16: training loss = 0.2618, validation loss = 0.1772. Learning rate = 0.001. Patience = 0\n",
      "Epoch 17: training loss = 0.2721, validation loss = 0.1931. Learning rate = 0.001. Patience = 1\n",
      "Epoch 18: training loss = 0.2510, validation loss = 0.1881. Learning rate = 0.001. Patience = 2\n",
      "Epoch 19: training loss = 0.2491, validation loss = 0.1768. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.2578, validation loss = 0.1789. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.2501, validation loss = 0.2063. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.2554, validation loss = 0.1985. Learning rate = 0.001. Patience = 3\n",
      "Epoch 23: training loss = 0.2679, validation loss = 0.2369. Learning rate = 0.001. Patience = 4\n",
      "Epoch 24: training loss = 0.2710, validation loss = 0.1878. Learning rate = 0.001. Patience = 5\n",
      "Epoch 25: training loss = 0.2336, validation loss = 0.1768. Learning rate = 0.001. Patience = 6\n",
      "Epoch 26: training loss = 0.2563, validation loss = 0.1729. Learning rate = 0.001. Patience = 0\n",
      "Epoch 27: training loss = 0.2433, validation loss = 0.1777. Learning rate = 0.001. Patience = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: training loss = 0.2339, validation loss = 0.1763. Learning rate = 0.001. Patience = 2\n",
      "Epoch 29: training loss = 0.2402, validation loss = 0.1740. Learning rate = 0.001. Patience = 3\n",
      "Epoch 30: training loss = 0.2327, validation loss = 0.1883. Learning rate = 0.001. Patience = 4\n",
      "Epoch 31: training loss = 0.2504, validation loss = 0.1786. Learning rate = 0.001. Patience = 5\n",
      "Epoch 32: training loss = 0.2397, validation loss = 0.1839. Learning rate = 0.001. Patience = 6\n",
      "Epoch 33: training loss = 0.2326, validation loss = 0.1761. Learning rate = 0.001. Patience = 7\n",
      "Epoch 34: training loss = 0.2516, validation loss = 0.1807. Learning rate = 0.001. Patience = 8\n",
      "Epoch 35: training loss = 0.2384, validation loss = 0.1856. Learning rate = 0.001. Patience = 9\n",
      "Epoch 36: training loss = 0.2468, validation loss = 0.1752. Learning rate = 0.001. Patience = 10\n",
      "Epoch 37: training loss = 0.2288, validation loss = 0.1813. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 38: training loss = 0.2337, validation loss = 0.1824. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 39: training loss = 0.2332, validation loss = 0.1875. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 40: training loss = 0.2264, validation loss = 0.1732. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 41: training loss = 0.2212, validation loss = 0.1768. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 42: training loss = 0.2233, validation loss = 0.1734. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 43: training loss = 0.2288, validation loss = 0.1788. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 44: training loss = 0.2205, validation loss = 0.1749. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 45: training loss = 0.2470, validation loss = 0.1767. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 46: training loss = 0.2239, validation loss = 0.1716. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 47: training loss = 0.2286, validation loss = 0.1676. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 48: training loss = 0.2304, validation loss = 0.1688. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 49: training loss = 0.2141, validation loss = 0.1685. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 50: training loss = 0.2302, validation loss = 0.1664. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 51: training loss = 0.2096, validation loss = 0.1700. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 52: training loss = 0.2277, validation loss = 0.1702. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 53: training loss = 0.2353, validation loss = 0.1734. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 54: training loss = 0.2166, validation loss = 0.1714. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 55: training loss = 0.2172, validation loss = 0.1696. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 56: training loss = 0.2268, validation loss = 0.1725. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 57: training loss = 0.2298, validation loss = 0.1801. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 58: training loss = 0.2239, validation loss = 0.1730. Learning rate = 0.0005. Patience = 8\n",
      "Epoch 59: training loss = 0.2203, validation loss = 0.1739. Learning rate = 0.0005. Patience = 9\n",
      "Epoch 60: training loss = 0.2087, validation loss = 0.1705. Learning rate = 0.0005. Patience = 10\n",
      "Epoch 61: training loss = 0.2088, validation loss = 0.1687. Learning rate = 0.00025. Patience = 11\n",
      "Epoch 62: training loss = 0.2070, validation loss = 0.1707. Learning rate = 0.00025. Patience = 12\n",
      "Epoch 63: training loss = 0.2254, validation loss = 0.1726. Learning rate = 0.00025. Patience = 13\n",
      "Epoch 64: training loss = 0.2095, validation loss = 0.1700. Learning rate = 0.00025. Patience = 14\n",
      "Epoch 65: training loss = 0.2081, validation loss = 0.1712. Learning rate = 0.00025. Patience = 15\n",
      "Epoch 66: training loss = 0.2276, validation loss = 0.1666. Learning rate = 0.00025. Patience = 16\n",
      "Epoch 67: training loss = 0.2243, validation loss = 0.1680. Learning rate = 0.00025. Patience = 17\n",
      "Epoch 68: training loss = 0.2113, validation loss = 0.1729. Learning rate = 0.00025. Patience = 18\n",
      "Epoch 69: training loss = 0.2013, validation loss = 0.1672. Learning rate = 0.00025. Patience = 19\n",
      "Epoch 70: training loss = 0.2245, validation loss = 0.1670. Learning rate = 0.00025. Patience = 20\n",
      "Epoch 71: training loss = 0.2027, validation loss = 0.1685. Learning rate = 0.00025. Patience = 21\n",
      "Epoch 72: training loss = 0.2178, validation loss = 0.1695. Learning rate = 0.000125. Patience = 22\n",
      "Epoch 73: training loss = 0.2300, validation loss = 0.1682. Learning rate = 0.000125. Patience = 23\n",
      "Epoch 74: training loss = 0.2161, validation loss = 0.1678. Learning rate = 0.000125. Patience = 24\n",
      "Epoch 75: training loss = 0.2152, validation loss = 0.1694. Learning rate = 0.000125. Patience = 25\n",
      "Epoch 76: training loss = 0.2328, validation loss = 0.1721. Learning rate = 0.000125. Patience = 26\n",
      "Epoch 77: training loss = 0.2170, validation loss = 0.1706. Learning rate = 0.000125. Patience = 27\n",
      "Epoch 78: training loss = 0.2068, validation loss = 0.1717. Learning rate = 0.000125. Patience = 28\n",
      "Epoch 79: training loss = 0.2000, validation loss = 0.1700. Learning rate = 0.000125. Patience = 29\n",
      "Epoch 80: training loss = 0.2206, validation loss = 0.1698. Learning rate = 0.000125. Patience = 30\n",
      "Epoch 81: training loss = 0.2172, validation loss = 0.1701. Learning rate = 0.000125. Patience = 31\n",
      "Epoch 82: training loss = 0.2364, validation loss = 0.1685. Learning rate = 0.000125. Patience = 32\n",
      "Epoch 83: training loss = 0.2219, validation loss = 0.1689. Learning rate = 6.25e-05. Patience = 33\n",
      "Epoch 84: training loss = 0.2181, validation loss = 0.1692. Learning rate = 6.25e-05. Patience = 34\n",
      "Epoch 85: training loss = 0.2253, validation loss = 0.1689. Learning rate = 6.25e-05. Patience = 35\n",
      "Epoch 86: training loss = 0.2130, validation loss = 0.1694. Learning rate = 6.25e-05. Patience = 36\n",
      "Epoch 87: training loss = 0.2134, validation loss = 0.1695. Learning rate = 6.25e-05. Patience = 37\n",
      "Epoch 88: training loss = 0.2366, validation loss = 0.1696. Learning rate = 6.25e-05. Patience = 38\n",
      "Epoch 89: training loss = 0.2167, validation loss = 0.1694. Learning rate = 6.25e-05. Patience = 39\n",
      "Epoch 90: training loss = 0.2135, validation loss = 0.1694. Learning rate = 6.25e-05. Patience = 40\n",
      "Epoch 91: training loss = 0.2167, validation loss = 0.1694. Learning rate = 6.25e-05. Patience = 41\n",
      "Epoch 92: training loss = 0.2224, validation loss = 0.1695. Learning rate = 6.25e-05. Patience = 42\n",
      "Epoch 93: training loss = 0.2021, validation loss = 0.1687. Learning rate = 6.25e-05. Patience = 43\n",
      "Epoch 94: training loss = 0.2088, validation loss = 0.1682. Learning rate = 3.125e-05. Patience = 44\n",
      "Epoch 95: training loss = 0.2018, validation loss = 0.1685. Learning rate = 3.125e-05. Patience = 45\n",
      "Epoch 96: training loss = 0.2366, validation loss = 0.1691. Learning rate = 3.125e-05. Patience = 46\n",
      "Epoch 97: training loss = 0.2049, validation loss = 0.1692. Learning rate = 3.125e-05. Patience = 47\n",
      "Epoch 98: training loss = 0.1995, validation loss = 0.1694. Learning rate = 3.125e-05. Patience = 48\n",
      "Epoch 99: training loss = 0.2067, validation loss = 0.1692. Learning rate = 3.125e-05. Patience = 49\n",
      "Epoch 100: training loss = 0.1974, validation loss = 0.1692. Learning rate = 3.125e-05. Patience = 50\n",
      "Training stopped at epoch 100; restoring weights from epoch 50\n",
      "Epoch 1: training loss = 0.7684, validation loss = 0.9521. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4914, validation loss = 0.7067. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4527, validation loss = 0.5394. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.4197, validation loss = 0.5968. Learning rate = 0.001. Patience = 1\n",
      "Epoch 5: training loss = 0.3972, validation loss = 0.5757. Learning rate = 0.001. Patience = 2\n",
      "Epoch 6: training loss = 0.3962, validation loss = 0.5531. Learning rate = 0.001. Patience = 3\n",
      "Epoch 7: training loss = 0.3829, validation loss = 0.5713. Learning rate = 0.001. Patience = 4\n",
      "Epoch 8: training loss = 0.3776, validation loss = 0.5221. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.3797, validation loss = 0.5219. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.3621, validation loss = 0.5225. Learning rate = 0.001. Patience = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: training loss = 0.3435, validation loss = 0.5305. Learning rate = 0.001. Patience = 2\n",
      "Epoch 12: training loss = 0.3552, validation loss = 0.5550. Learning rate = 0.001. Patience = 3\n",
      "Epoch 13: training loss = 0.3546, validation loss = 0.5054. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.3365, validation loss = 0.5030. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.3522, validation loss = 0.5292. Learning rate = 0.001. Patience = 1\n",
      "Epoch 16: training loss = 0.3327, validation loss = 0.5405. Learning rate = 0.001. Patience = 2\n",
      "Epoch 17: training loss = 0.3278, validation loss = 0.4668. Learning rate = 0.001. Patience = 0\n",
      "Epoch 18: training loss = 0.3370, validation loss = 0.4934. Learning rate = 0.001. Patience = 1\n",
      "Epoch 19: training loss = 0.3320, validation loss = 0.4647. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.3233, validation loss = 0.4824. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.3175, validation loss = 0.4675. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.3314, validation loss = 0.4505. Learning rate = 0.001. Patience = 0\n",
      "Epoch 23: training loss = 0.3106, validation loss = 0.4932. Learning rate = 0.001. Patience = 1\n",
      "Epoch 24: training loss = 0.3210, validation loss = 0.5120. Learning rate = 0.001. Patience = 2\n",
      "Epoch 25: training loss = 0.3311, validation loss = 0.4700. Learning rate = 0.001. Patience = 3\n",
      "Epoch 26: training loss = 0.3180, validation loss = 0.4408. Learning rate = 0.001. Patience = 0\n",
      "Epoch 27: training loss = 0.3020, validation loss = 0.5085. Learning rate = 0.001. Patience = 1\n",
      "Epoch 28: training loss = 0.3213, validation loss = 0.4890. Learning rate = 0.001. Patience = 2\n",
      "Epoch 29: training loss = 0.2991, validation loss = 0.5574. Learning rate = 0.001. Patience = 3\n",
      "Epoch 30: training loss = 0.3119, validation loss = 0.5146. Learning rate = 0.001. Patience = 4\n",
      "Epoch 31: training loss = 0.3197, validation loss = 0.4803. Learning rate = 0.001. Patience = 5\n",
      "Epoch 32: training loss = 0.3184, validation loss = 0.4373. Learning rate = 0.001. Patience = 0\n",
      "Epoch 33: training loss = 0.3056, validation loss = 0.5500. Learning rate = 0.001. Patience = 1\n",
      "Epoch 34: training loss = 0.3019, validation loss = 0.5473. Learning rate = 0.001. Patience = 2\n",
      "Epoch 35: training loss = 0.2911, validation loss = 0.4199. Learning rate = 0.001. Patience = 0\n",
      "Epoch 36: training loss = 0.3228, validation loss = 0.4285. Learning rate = 0.001. Patience = 1\n",
      "Epoch 37: training loss = 0.3061, validation loss = 0.5932. Learning rate = 0.001. Patience = 2\n",
      "Epoch 38: training loss = 0.3061, validation loss = 0.4812. Learning rate = 0.001. Patience = 3\n",
      "Epoch 39: training loss = 0.2911, validation loss = 0.5080. Learning rate = 0.001. Patience = 4\n",
      "Epoch 40: training loss = 0.3023, validation loss = 0.4315. Learning rate = 0.001. Patience = 5\n",
      "Epoch 41: training loss = 0.2829, validation loss = 0.5008. Learning rate = 0.001. Patience = 6\n",
      "Epoch 42: training loss = 0.2668, validation loss = 0.4961. Learning rate = 0.001. Patience = 7\n",
      "Epoch 43: training loss = 0.2784, validation loss = 0.4895. Learning rate = 0.001. Patience = 8\n",
      "Epoch 44: training loss = 0.2612, validation loss = 0.4908. Learning rate = 0.001. Patience = 9\n",
      "Epoch 45: training loss = 0.2604, validation loss = 0.5201. Learning rate = 0.001. Patience = 10\n",
      "Epoch 46: training loss = 0.2688, validation loss = 0.4927. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 47: training loss = 0.2825, validation loss = 0.4782. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 48: training loss = 0.2714, validation loss = 0.4651. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 49: training loss = 0.2614, validation loss = 0.5413. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 50: training loss = 0.2567, validation loss = 0.5134. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 51: training loss = 0.2802, validation loss = 0.4564. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 52: training loss = 0.2539, validation loss = 0.4868. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 53: training loss = 0.2513, validation loss = 0.5220. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 54: training loss = 0.2642, validation loss = 0.4806. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 55: training loss = 0.2571, validation loss = 0.5089. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 56: training loss = 0.2686, validation loss = 0.5014. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 57: training loss = 0.2651, validation loss = 0.4911. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 58: training loss = 0.2579, validation loss = 0.5070. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 59: training loss = 0.2520, validation loss = 0.4947. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 60: training loss = 0.2498, validation loss = 0.5111. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 61: training loss = 0.2574, validation loss = 0.4986. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 62: training loss = 0.2674, validation loss = 0.4790. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 63: training loss = 0.2489, validation loss = 0.4934. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 64: training loss = 0.2423, validation loss = 0.4945. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 65: training loss = 0.2418, validation loss = 0.5010. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 66: training loss = 0.2639, validation loss = 0.4964. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 67: training loss = 0.2362, validation loss = 0.4997. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 68: training loss = 0.2445, validation loss = 0.5276. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 69: training loss = 0.2337, validation loss = 0.4908. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 70: training loss = 0.2377, validation loss = 0.4888. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 71: training loss = 0.2417, validation loss = 0.4966. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 72: training loss = 0.2358, validation loss = 0.5010. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 73: training loss = 0.2371, validation loss = 0.5045. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 74: training loss = 0.2516, validation loss = 0.4763. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 75: training loss = 0.2471, validation loss = 0.4778. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 76: training loss = 0.2373, validation loss = 0.4895. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 77: training loss = 0.2545, validation loss = 0.5024. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 78: training loss = 0.2289, validation loss = 0.4931. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 79: training loss = 0.2358, validation loss = 0.5052. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 80: training loss = 0.2359, validation loss = 0.5072. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 81: training loss = 0.2364, validation loss = 0.5025. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 82: training loss = 0.2457, validation loss = 0.5018. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 83: training loss = 0.2369, validation loss = 0.5017. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 84: training loss = 0.2455, validation loss = 0.5109. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 85: training loss = 0.2467, validation loss = 0.5146. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 85; restoring weights from epoch 35\n",
      "Epoch 1: training loss = 0.8152, validation loss = 0.8186. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.6505, validation loss = 0.6240. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.5174, validation loss = 0.6599. Learning rate = 0.001. Patience = 1\n",
      "Epoch 4: training loss = 0.4990, validation loss = 0.6148. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.4876, validation loss = 0.5589. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.4830, validation loss = 0.5896. Learning rate = 0.001. Patience = 1\n",
      "Epoch 7: training loss = 0.4535, validation loss = 0.5486. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.4434, validation loss = 0.5617. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.4329, validation loss = 0.5427. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.4291, validation loss = 0.5708. Learning rate = 0.001. Patience = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: training loss = 0.4464, validation loss = 0.5558. Learning rate = 0.001. Patience = 2\n",
      "Epoch 12: training loss = 0.4237, validation loss = 0.5336. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.4114, validation loss = 0.5521. Learning rate = 0.001. Patience = 1\n",
      "Epoch 14: training loss = 0.4355, validation loss = 0.5527. Learning rate = 0.001. Patience = 2\n",
      "Epoch 15: training loss = 0.4221, validation loss = 0.5441. Learning rate = 0.001. Patience = 3\n",
      "Epoch 16: training loss = 0.4065, validation loss = 0.5500. Learning rate = 0.001. Patience = 4\n",
      "Epoch 17: training loss = 0.4091, validation loss = 0.5303. Learning rate = 0.001. Patience = 0\n",
      "Epoch 18: training loss = 0.3974, validation loss = 0.5356. Learning rate = 0.001. Patience = 1\n",
      "Epoch 19: training loss = 0.3946, validation loss = 0.5331. Learning rate = 0.001. Patience = 2\n",
      "Epoch 20: training loss = 0.3735, validation loss = 0.5316. Learning rate = 0.001. Patience = 3\n",
      "Epoch 21: training loss = 0.3891, validation loss = 0.5471. Learning rate = 0.001. Patience = 4\n",
      "Epoch 22: training loss = 0.3808, validation loss = 0.5314. Learning rate = 0.001. Patience = 5\n",
      "Epoch 23: training loss = 0.3603, validation loss = 0.5412. Learning rate = 0.001. Patience = 6\n",
      "Epoch 24: training loss = 0.3637, validation loss = 0.5611. Learning rate = 0.001. Patience = 7\n",
      "Epoch 25: training loss = 0.3650, validation loss = 0.5368. Learning rate = 0.001. Patience = 8\n",
      "Epoch 26: training loss = 0.3678, validation loss = 0.5299. Learning rate = 0.001. Patience = 0\n",
      "Epoch 27: training loss = 0.3478, validation loss = 0.5501. Learning rate = 0.001. Patience = 1\n",
      "Epoch 28: training loss = 0.3533, validation loss = 0.5696. Learning rate = 0.001. Patience = 2\n",
      "Epoch 29: training loss = 0.3440, validation loss = 0.5372. Learning rate = 0.001. Patience = 3\n",
      "Epoch 30: training loss = 0.3530, validation loss = 0.5627. Learning rate = 0.001. Patience = 4\n",
      "Epoch 31: training loss = 0.3552, validation loss = 0.5560. Learning rate = 0.001. Patience = 5\n",
      "Epoch 32: training loss = 0.3384, validation loss = 0.5468. Learning rate = 0.001. Patience = 6\n",
      "Epoch 33: training loss = 0.3365, validation loss = 0.5555. Learning rate = 0.001. Patience = 7\n",
      "Epoch 34: training loss = 0.3521, validation loss = 0.5587. Learning rate = 0.001. Patience = 8\n",
      "Epoch 35: training loss = 0.3362, validation loss = 0.5677. Learning rate = 0.001. Patience = 9\n",
      "Epoch 36: training loss = 0.3331, validation loss = 0.5751. Learning rate = 0.001. Patience = 10\n",
      "Epoch 37: training loss = 0.3354, validation loss = 0.5983. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 38: training loss = 0.3199, validation loss = 0.5762. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 39: training loss = 0.3240, validation loss = 0.5865. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 40: training loss = 0.3153, validation loss = 0.5847. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 41: training loss = 0.3011, validation loss = 0.5831. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 42: training loss = 0.3086, validation loss = 0.5844. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 43: training loss = 0.3069, validation loss = 0.6065. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 44: training loss = 0.3128, validation loss = 0.5948. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 45: training loss = 0.3250, validation loss = 0.5870. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 46: training loss = 0.3126, validation loss = 0.5950. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 47: training loss = 0.3013, validation loss = 0.6111. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 48: training loss = 0.3038, validation loss = 0.5953. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 49: training loss = 0.3041, validation loss = 0.6054. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 50: training loss = 0.3095, validation loss = 0.6049. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 51: training loss = 0.3133, validation loss = 0.5972. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 52: training loss = 0.2949, validation loss = 0.6043. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 53: training loss = 0.2975, validation loss = 0.6127. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 54: training loss = 0.2962, validation loss = 0.6070. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 55: training loss = 0.2930, validation loss = 0.6026. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 56: training loss = 0.2988, validation loss = 0.6011. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 57: training loss = 0.3030, validation loss = 0.6171. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 58: training loss = 0.2955, validation loss = 0.6053. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 59: training loss = 0.2873, validation loss = 0.6142. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 60: training loss = 0.3011, validation loss = 0.6135. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 61: training loss = 0.2911, validation loss = 0.6172. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 62: training loss = 0.2896, validation loss = 0.6233. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 63: training loss = 0.2943, validation loss = 0.6220. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 64: training loss = 0.2896, validation loss = 0.6211. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 65: training loss = 0.3028, validation loss = 0.6211. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 66: training loss = 0.3000, validation loss = 0.6257. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 67: training loss = 0.2862, validation loss = 0.6208. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 68: training loss = 0.2822, validation loss = 0.6256. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 69: training loss = 0.2852, validation loss = 0.6265. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 70: training loss = 0.2827, validation loss = 0.6253. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 71: training loss = 0.2868, validation loss = 0.6223. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 72: training loss = 0.3000, validation loss = 0.6193. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 73: training loss = 0.2911, validation loss = 0.6194. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 74: training loss = 0.2933, validation loss = 0.6220. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 75: training loss = 0.2780, validation loss = 0.6250. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 76: training loss = 0.2902, validation loss = 0.6278. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 76; restoring weights from epoch 26\n",
      "Epoch 1: training loss = 0.9120, validation loss = 0.7750. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.6168, validation loss = 0.4919. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4470, validation loss = 0.4615. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.4459, validation loss = 0.4592. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.4559, validation loss = 0.4510. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.4342, validation loss = 0.4434. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.4067, validation loss = 0.4347. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.4116, validation loss = 0.4427. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.3648, validation loss = 0.4312. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.3998, validation loss = 0.4218. Learning rate = 0.001. Patience = 0\n",
      "Epoch 11: training loss = 0.4063, validation loss = 0.4208. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.3337, validation loss = 0.4202. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.3483, validation loss = 0.4317. Learning rate = 0.001. Patience = 1\n",
      "Epoch 14: training loss = 0.3117, validation loss = 0.4084. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.3199, validation loss = 0.4195. Learning rate = 0.001. Patience = 1\n",
      "Epoch 16: training loss = 0.3096, validation loss = 0.4230. Learning rate = 0.001. Patience = 2\n",
      "Epoch 17: training loss = 0.3170, validation loss = 0.4120. Learning rate = 0.001. Patience = 3\n",
      "Epoch 18: training loss = 0.3176, validation loss = 0.4131. Learning rate = 0.001. Patience = 4\n",
      "Epoch 19: training loss = 0.2973, validation loss = 0.4081. Learning rate = 0.001. Patience = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: training loss = 0.2661, validation loss = 0.4168. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.2767, validation loss = 0.4127. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.2773, validation loss = 0.3921. Learning rate = 0.001. Patience = 0\n",
      "Epoch 23: training loss = 0.2590, validation loss = 0.4130. Learning rate = 0.001. Patience = 1\n",
      "Epoch 24: training loss = 0.2556, validation loss = 0.3979. Learning rate = 0.001. Patience = 2\n",
      "Epoch 25: training loss = 0.2538, validation loss = 0.3985. Learning rate = 0.001. Patience = 3\n",
      "Epoch 26: training loss = 0.2530, validation loss = 0.3859. Learning rate = 0.001. Patience = 0\n",
      "Epoch 27: training loss = 0.2658, validation loss = 0.4195. Learning rate = 0.001. Patience = 1\n",
      "Epoch 28: training loss = 0.2431, validation loss = 0.3782. Learning rate = 0.001. Patience = 0\n",
      "Epoch 29: training loss = 0.2478, validation loss = 0.3929. Learning rate = 0.001. Patience = 1\n",
      "Epoch 30: training loss = 0.2229, validation loss = 0.3831. Learning rate = 0.001. Patience = 2\n",
      "Epoch 31: training loss = 0.2451, validation loss = 0.3848. Learning rate = 0.001. Patience = 3\n",
      "Epoch 32: training loss = 0.2274, validation loss = 0.3752. Learning rate = 0.001. Patience = 0\n",
      "Epoch 33: training loss = 0.2286, validation loss = 0.3702. Learning rate = 0.001. Patience = 0\n",
      "Epoch 34: training loss = 0.2375, validation loss = 0.3967. Learning rate = 0.001. Patience = 1\n",
      "Epoch 35: training loss = 0.2253, validation loss = 0.3657. Learning rate = 0.001. Patience = 0\n",
      "Epoch 36: training loss = 0.2289, validation loss = 0.3579. Learning rate = 0.001. Patience = 0\n",
      "Epoch 37: training loss = 0.2033, validation loss = 0.3710. Learning rate = 0.001. Patience = 1\n",
      "Epoch 38: training loss = 0.2228, validation loss = 0.3468. Learning rate = 0.001. Patience = 0\n",
      "Epoch 39: training loss = 0.2147, validation loss = 0.3597. Learning rate = 0.001. Patience = 1\n",
      "Epoch 40: training loss = 0.2027, validation loss = 0.3585. Learning rate = 0.001. Patience = 2\n",
      "Epoch 41: training loss = 0.2095, validation loss = 0.3467. Learning rate = 0.001. Patience = 0\n",
      "Epoch 42: training loss = 0.2016, validation loss = 0.3552. Learning rate = 0.001. Patience = 1\n",
      "Epoch 43: training loss = 0.2118, validation loss = 0.3514. Learning rate = 0.001. Patience = 2\n",
      "Epoch 44: training loss = 0.2069, validation loss = 0.3486. Learning rate = 0.001. Patience = 3\n",
      "Epoch 45: training loss = 0.2056, validation loss = 0.3493. Learning rate = 0.001. Patience = 4\n",
      "Epoch 46: training loss = 0.1981, validation loss = 0.3484. Learning rate = 0.001. Patience = 5\n",
      "Epoch 47: training loss = 0.1940, validation loss = 0.3583. Learning rate = 0.001. Patience = 6\n",
      "Epoch 48: training loss = 0.1861, validation loss = 0.3383. Learning rate = 0.001. Patience = 0\n",
      "Epoch 49: training loss = 0.1818, validation loss = 0.3522. Learning rate = 0.001. Patience = 1\n",
      "Epoch 50: training loss = 0.1843, validation loss = 0.3699. Learning rate = 0.001. Patience = 2\n",
      "Epoch 51: training loss = 0.1812, validation loss = 0.3433. Learning rate = 0.001. Patience = 3\n",
      "Epoch 52: training loss = 0.1852, validation loss = 0.3495. Learning rate = 0.001. Patience = 4\n",
      "Epoch 53: training loss = 0.1854, validation loss = 0.3357. Learning rate = 0.001. Patience = 0\n",
      "Epoch 54: training loss = 0.1798, validation loss = 0.3514. Learning rate = 0.001. Patience = 1\n",
      "Epoch 55: training loss = 0.1696, validation loss = 0.3424. Learning rate = 0.001. Patience = 2\n",
      "Epoch 56: training loss = 0.1726, validation loss = 0.3382. Learning rate = 0.001. Patience = 3\n",
      "Epoch 57: training loss = 0.1916, validation loss = 0.3623. Learning rate = 0.001. Patience = 4\n",
      "Epoch 58: training loss = 0.1713, validation loss = 0.3353. Learning rate = 0.001. Patience = 0\n",
      "Epoch 59: training loss = 0.1745, validation loss = 0.3634. Learning rate = 0.001. Patience = 1\n",
      "Epoch 60: training loss = 0.1804, validation loss = 0.3418. Learning rate = 0.001. Patience = 2\n",
      "Epoch 61: training loss = 0.1662, validation loss = 0.3325. Learning rate = 0.001. Patience = 0\n",
      "Epoch 62: training loss = 0.1668, validation loss = 0.3454. Learning rate = 0.001. Patience = 1\n",
      "Epoch 63: training loss = 0.1769, validation loss = 0.3418. Learning rate = 0.001. Patience = 2\n",
      "Epoch 64: training loss = 0.1686, validation loss = 0.3421. Learning rate = 0.001. Patience = 3\n",
      "Epoch 65: training loss = 0.1668, validation loss = 0.3476. Learning rate = 0.001. Patience = 4\n",
      "Epoch 66: training loss = 0.1711, validation loss = 0.3396. Learning rate = 0.001. Patience = 5\n",
      "Epoch 67: training loss = 0.1659, validation loss = 0.3312. Learning rate = 0.001. Patience = 0\n",
      "Epoch 68: training loss = 0.1598, validation loss = 0.3653. Learning rate = 0.001. Patience = 1\n",
      "Epoch 69: training loss = 0.1665, validation loss = 0.3433. Learning rate = 0.001. Patience = 2\n",
      "Epoch 70: training loss = 0.1525, validation loss = 0.3427. Learning rate = 0.001. Patience = 3\n",
      "Epoch 71: training loss = 0.1651, validation loss = 0.3351. Learning rate = 0.001. Patience = 4\n",
      "Epoch 72: training loss = 0.1486, validation loss = 0.3322. Learning rate = 0.001. Patience = 5\n",
      "Epoch 73: training loss = 0.1557, validation loss = 0.3423. Learning rate = 0.001. Patience = 6\n",
      "Epoch 74: training loss = 0.1580, validation loss = 0.3368. Learning rate = 0.001. Patience = 7\n",
      "Epoch 75: training loss = 0.1586, validation loss = 0.3423. Learning rate = 0.001. Patience = 8\n",
      "Epoch 76: training loss = 0.1657, validation loss = 0.3444. Learning rate = 0.001. Patience = 9\n",
      "Epoch 77: training loss = 0.1516, validation loss = 0.3357. Learning rate = 0.001. Patience = 10\n",
      "Epoch 78: training loss = 0.1567, validation loss = 0.3648. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 79: training loss = 0.1492, validation loss = 0.3577. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 80: training loss = 0.1599, validation loss = 0.3600. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 81: training loss = 0.1602, validation loss = 0.3446. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 82: training loss = 0.1469, validation loss = 0.3539. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 83: training loss = 0.1732, validation loss = 0.3479. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 84: training loss = 0.1469, validation loss = 0.3507. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 85: training loss = 0.1449, validation loss = 0.3505. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 86: training loss = 0.1579, validation loss = 0.3427. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 87: training loss = 0.1493, validation loss = 0.3513. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 88: training loss = 0.1461, validation loss = 0.3486. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 89: training loss = 0.1500, validation loss = 0.3433. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 90: training loss = 0.1502, validation loss = 0.3479. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 91: training loss = 0.1659, validation loss = 0.3424. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 92: training loss = 0.1429, validation loss = 0.3453. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 93: training loss = 0.1558, validation loss = 0.3556. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 94: training loss = 0.1484, validation loss = 0.3493. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 95: training loss = 0.1481, validation loss = 0.3461. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 96: training loss = 0.1558, validation loss = 0.3546. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 97: training loss = 0.1392, validation loss = 0.3552. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 98: training loss = 0.1465, validation loss = 0.3579. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 99: training loss = 0.1583, validation loss = 0.3527. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 100: training loss = 0.1468, validation loss = 0.3499. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 101: training loss = 0.1563, validation loss = 0.3501. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 102: training loss = 0.1377, validation loss = 0.3525. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 103: training loss = 0.1391, validation loss = 0.3566. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 104: training loss = 0.1650, validation loss = 0.3545. Learning rate = 0.000125. Patience = 37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 105: training loss = 0.1404, validation loss = 0.3495. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 106: training loss = 0.1445, validation loss = 0.3516. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 107: training loss = 0.1392, validation loss = 0.3501. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 108: training loss = 0.1369, validation loss = 0.3527. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 109: training loss = 0.1644, validation loss = 0.3526. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 110: training loss = 0.1486, validation loss = 0.3557. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 111: training loss = 0.1544, validation loss = 0.3526. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 112: training loss = 0.1493, validation loss = 0.3514. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 113: training loss = 0.1456, validation loss = 0.3515. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 114: training loss = 0.1426, validation loss = 0.3527. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 115: training loss = 0.1481, validation loss = 0.3559. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 116: training loss = 0.1370, validation loss = 0.3556. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 117: training loss = 0.1371, validation loss = 0.3533. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 117; restoring weights from epoch 67\n",
      "Epoch 1: training loss = 0.6110, validation loss = 10.1501. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.5053, validation loss = 21.5844. Learning rate = 0.001. Patience = 1\n",
      "Epoch 3: training loss = 0.5363, validation loss = 20.8368. Learning rate = 0.001. Patience = 2\n",
      "Epoch 4: training loss = 0.5004, validation loss = 21.0308. Learning rate = 0.001. Patience = 3\n",
      "Epoch 5: training loss = 0.4921, validation loss = 34.0612. Learning rate = 0.001. Patience = 4\n",
      "Epoch 6: training loss = 0.4684, validation loss = 32.3489. Learning rate = 0.001. Patience = 5\n",
      "Epoch 7: training loss = 0.4707, validation loss = 41.3871. Learning rate = 0.001. Patience = 6\n",
      "Epoch 8: training loss = 0.4284, validation loss = 41.2534. Learning rate = 0.001. Patience = 7\n",
      "Epoch 9: training loss = 0.4208, validation loss = 42.9415. Learning rate = 0.001. Patience = 8\n",
      "Epoch 10: training loss = 0.4664, validation loss = 43.4617. Learning rate = 0.001. Patience = 9\n",
      "Epoch 11: training loss = 0.3943, validation loss = 46.9041. Learning rate = 0.001. Patience = 10\n",
      "Epoch 12: training loss = 0.4072, validation loss = 43.1609. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 13: training loss = 0.4270, validation loss = 44.5031. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 14: training loss = 0.3902, validation loss = 47.6686. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 15: training loss = 0.3972, validation loss = 47.3991. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 16: training loss = 0.4044, validation loss = 47.6564. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 17: training loss = 0.4024, validation loss = 44.5085. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 18: training loss = 0.3937, validation loss = 42.0879. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 19: training loss = 0.4213, validation loss = 42.3219. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 20: training loss = 0.3881, validation loss = 43.0374. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 21: training loss = 0.3808, validation loss = 40.4339. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 22: training loss = 0.3784, validation loss = 41.7176. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 23: training loss = 0.3819, validation loss = 43.2518. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 24: training loss = 0.3740, validation loss = 42.6764. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 25: training loss = 0.3691, validation loss = 41.6488. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 26: training loss = 0.3794, validation loss = 41.9700. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 27: training loss = 0.3684, validation loss = 44.2397. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 28: training loss = 0.3744, validation loss = 41.0855. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 29: training loss = 0.3805, validation loss = 40.0413. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 30: training loss = 0.3777, validation loss = 40.6334. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 31: training loss = 0.3751, validation loss = 39.9137. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 32: training loss = 0.4252, validation loss = 39.6607. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 33: training loss = 0.3737, validation loss = 42.4021. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 34: training loss = 0.3821, validation loss = 40.7875. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 35: training loss = 0.4097, validation loss = 38.4901. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 36: training loss = 0.3719, validation loss = 38.5703. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 37: training loss = 0.3843, validation loss = 39.6996. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 38: training loss = 0.3823, validation loss = 40.4556. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 39: training loss = 0.3957, validation loss = 41.3668. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 40: training loss = 0.3724, validation loss = 39.9565. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 41: training loss = 0.3846, validation loss = 40.2980. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 42: training loss = 0.3790, validation loss = 39.9831. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 43: training loss = 0.3709, validation loss = 38.7048. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 44: training loss = 0.3545, validation loss = 40.2944. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 45: training loss = 0.4008, validation loss = 39.0889. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 46: training loss = 0.3542, validation loss = 38.8920. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 47: training loss = 0.3938, validation loss = 39.4967. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 48: training loss = 0.3673, validation loss = 39.2940. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 49: training loss = 0.3746, validation loss = 39.1037. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 50: training loss = 0.3882, validation loss = 38.5913. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 51: training loss = 0.3845, validation loss = 37.9609. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 51; restoring weights from epoch 1\n",
      "Epoch 1: training loss = 0.7822, validation loss = 0.8348. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.5454, validation loss = 0.6397. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4954, validation loss = 0.5840. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.5054, validation loss = 0.6121. Learning rate = 0.001. Patience = 1\n",
      "Epoch 5: training loss = 0.4668, validation loss = 0.5686. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.4714, validation loss = 0.5835. Learning rate = 0.001. Patience = 1\n",
      "Epoch 7: training loss = 0.4267, validation loss = 0.5308. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.4164, validation loss = 0.5557. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.4337, validation loss = 0.5523. Learning rate = 0.001. Patience = 2\n",
      "Epoch 10: training loss = 0.4304, validation loss = 0.5374. Learning rate = 0.001. Patience = 3\n",
      "Epoch 11: training loss = 0.3988, validation loss = 0.5329. Learning rate = 0.001. Patience = 4\n",
      "Epoch 12: training loss = 0.3895, validation loss = 0.5308. Learning rate = 0.001. Patience = 5\n",
      "Epoch 13: training loss = 0.3826, validation loss = 0.5548. Learning rate = 0.001. Patience = 6\n",
      "Epoch 14: training loss = 0.3956, validation loss = 0.5236. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.3789, validation loss = 0.5102. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.3749, validation loss = 0.5300. Learning rate = 0.001. Patience = 1\n",
      "Epoch 17: training loss = 0.3697, validation loss = 0.5639. Learning rate = 0.001. Patience = 2\n",
      "Epoch 18: training loss = 0.3680, validation loss = 0.4998. Learning rate = 0.001. Patience = 0\n",
      "Epoch 19: training loss = 0.3785, validation loss = 0.5570. Learning rate = 0.001. Patience = 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: training loss = 0.3762, validation loss = 0.5226. Learning rate = 0.001. Patience = 2\n",
      "Epoch 21: training loss = 0.3601, validation loss = 0.5286. Learning rate = 0.001. Patience = 3\n",
      "Epoch 22: training loss = 0.3512, validation loss = 0.5582. Learning rate = 0.001. Patience = 4\n",
      "Epoch 23: training loss = 0.3611, validation loss = 0.5303. Learning rate = 0.001. Patience = 5\n",
      "Epoch 24: training loss = 0.3608, validation loss = 0.5078. Learning rate = 0.001. Patience = 6\n",
      "Epoch 25: training loss = 0.3434, validation loss = 0.5268. Learning rate = 0.001. Patience = 7\n",
      "Epoch 26: training loss = 0.3435, validation loss = 0.5276. Learning rate = 0.001. Patience = 8\n",
      "Epoch 27: training loss = 0.3442, validation loss = 0.5019. Learning rate = 0.001. Patience = 9\n",
      "Epoch 28: training loss = 0.3324, validation loss = 0.5406. Learning rate = 0.001. Patience = 10\n",
      "Epoch 29: training loss = 0.3487, validation loss = 0.5061. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 30: training loss = 0.3319, validation loss = 0.5193. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 31: training loss = 0.3275, validation loss = 0.5238. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 32: training loss = 0.3254, validation loss = 0.5211. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 33: training loss = 0.3622, validation loss = 0.5199. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 34: training loss = 0.3204, validation loss = 0.5136. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 35: training loss = 0.3145, validation loss = 0.5325. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 36: training loss = 0.3201, validation loss = 0.5160. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 37: training loss = 0.3190, validation loss = 0.5305. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 38: training loss = 0.3117, validation loss = 0.5213. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 39: training loss = 0.3312, validation loss = 0.5186. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 40: training loss = 0.3161, validation loss = 0.5211. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 41: training loss = 0.3066, validation loss = 0.5098. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 42: training loss = 0.3062, validation loss = 0.5235. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 43: training loss = 0.3120, validation loss = 0.5169. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 44: training loss = 0.3017, validation loss = 0.5161. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 45: training loss = 0.3223, validation loss = 0.5187. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 46: training loss = 0.3065, validation loss = 0.5305. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 47: training loss = 0.3190, validation loss = 0.5238. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 48: training loss = 0.3220, validation loss = 0.5220. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 49: training loss = 0.3015, validation loss = 0.5205. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 50: training loss = 0.2985, validation loss = 0.5244. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 51: training loss = 0.3241, validation loss = 0.5232. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 52: training loss = 0.2984, validation loss = 0.5232. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 53: training loss = 0.3060, validation loss = 0.5248. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 54: training loss = 0.3043, validation loss = 0.5231. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 55: training loss = 0.3008, validation loss = 0.5224. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 56: training loss = 0.2966, validation loss = 0.5195. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 57: training loss = 0.3118, validation loss = 0.5197. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 58: training loss = 0.3080, validation loss = 0.5198. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 59: training loss = 0.3018, validation loss = 0.5204. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 60: training loss = 0.3291, validation loss = 0.5228. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 61: training loss = 0.3065, validation loss = 0.5252. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 62: training loss = 0.2892, validation loss = 0.5249. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 63: training loss = 0.3132, validation loss = 0.5265. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 64: training loss = 0.3041, validation loss = 0.5263. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 65: training loss = 0.3030, validation loss = 0.5249. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 66: training loss = 0.2923, validation loss = 0.5233. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 67: training loss = 0.3171, validation loss = 0.5227. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 68: training loss = 0.3192, validation loss = 0.5224. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 68; restoring weights from epoch 18\n",
      "Epoch 1: training loss = 0.8322, validation loss = 1.1835. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.5346, validation loss = 0.8843. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4622, validation loss = 0.9584. Learning rate = 0.001. Patience = 1\n",
      "Epoch 4: training loss = 0.4192, validation loss = 0.8268. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.4100, validation loss = 0.8644. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.3831, validation loss = 0.7819. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.3817, validation loss = 0.8276. Learning rate = 0.001. Patience = 1\n",
      "Epoch 8: training loss = 0.3740, validation loss = 0.7917. Learning rate = 0.001. Patience = 2\n",
      "Epoch 9: training loss = 0.3703, validation loss = 0.7861. Learning rate = 0.001. Patience = 3\n",
      "Epoch 10: training loss = 0.3475, validation loss = 0.8094. Learning rate = 0.001. Patience = 4\n",
      "Epoch 11: training loss = 0.3571, validation loss = 0.7518. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.3439, validation loss = 0.8524. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.3333, validation loss = 0.8595. Learning rate = 0.001. Patience = 2\n",
      "Epoch 14: training loss = 0.3290, validation loss = 0.7797. Learning rate = 0.001. Patience = 3\n",
      "Epoch 15: training loss = 0.3232, validation loss = 0.7623. Learning rate = 0.001. Patience = 4\n",
      "Epoch 16: training loss = 0.3151, validation loss = 0.8155. Learning rate = 0.001. Patience = 5\n",
      "Epoch 17: training loss = 0.2993, validation loss = 0.8934. Learning rate = 0.001. Patience = 6\n",
      "Epoch 18: training loss = 0.3078, validation loss = 0.7852. Learning rate = 0.001. Patience = 7\n",
      "Epoch 19: training loss = 0.2936, validation loss = 0.7435. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.2828, validation loss = 0.8412. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.2947, validation loss = 0.8024. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.2924, validation loss = 0.7767. Learning rate = 0.001. Patience = 3\n",
      "Epoch 23: training loss = 0.2801, validation loss = 0.8025. Learning rate = 0.001. Patience = 4\n",
      "Epoch 24: training loss = 0.2865, validation loss = 0.8769. Learning rate = 0.001. Patience = 5\n",
      "Epoch 25: training loss = 0.2766, validation loss = 0.8310. Learning rate = 0.001. Patience = 6\n",
      "Epoch 26: training loss = 0.2716, validation loss = 0.8271. Learning rate = 0.001. Patience = 7\n",
      "Epoch 27: training loss = 0.2655, validation loss = 0.8666. Learning rate = 0.001. Patience = 8\n",
      "Epoch 28: training loss = 0.2653, validation loss = 0.8812. Learning rate = 0.001. Patience = 9\n",
      "Epoch 29: training loss = 0.2633, validation loss = 0.8962. Learning rate = 0.001. Patience = 10\n",
      "Epoch 30: training loss = 0.2562, validation loss = 0.8096. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 31: training loss = 0.2644, validation loss = 0.8622. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 32: training loss = 0.2645, validation loss = 0.7791. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 33: training loss = 0.2630, validation loss = 0.8579. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 34: training loss = 0.2537, validation loss = 0.8193. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 35: training loss = 0.2511, validation loss = 0.8479. Learning rate = 0.0005. Patience = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: training loss = 0.2497, validation loss = 0.8195. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 37: training loss = 0.2440, validation loss = 0.8344. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 38: training loss = 0.2487, validation loss = 0.7969. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 39: training loss = 0.2496, validation loss = 0.8537. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 40: training loss = 0.2452, validation loss = 0.8203. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 41: training loss = 0.2469, validation loss = 0.8625. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 42: training loss = 0.2453, validation loss = 0.8314. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 43: training loss = 0.2497, validation loss = 0.8377. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 44: training loss = 0.2352, validation loss = 0.8345. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 45: training loss = 0.2411, validation loss = 0.8287. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 46: training loss = 0.2462, validation loss = 0.8284. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 47: training loss = 0.2407, validation loss = 0.8288. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 48: training loss = 0.2373, validation loss = 0.8166. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 49: training loss = 0.2383, validation loss = 0.8445. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 50: training loss = 0.2444, validation loss = 0.8066. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 51: training loss = 0.2349, validation loss = 0.8462. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 52: training loss = 0.2313, validation loss = 0.8267. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 53: training loss = 0.2461, validation loss = 0.8118. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 54: training loss = 0.2306, validation loss = 0.8073. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 55: training loss = 0.2342, validation loss = 0.8303. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 56: training loss = 0.2471, validation loss = 0.8087. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 57: training loss = 0.2487, validation loss = 0.8039. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 58: training loss = 0.2363, validation loss = 0.8322. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 59: training loss = 0.2291, validation loss = 0.8261. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 60: training loss = 0.2382, validation loss = 0.8417. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 61: training loss = 0.2310, validation loss = 0.8290. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 62: training loss = 0.2423, validation loss = 0.8328. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 63: training loss = 0.2328, validation loss = 0.8230. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 64: training loss = 0.2350, validation loss = 0.8329. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 65: training loss = 0.2311, validation loss = 0.8448. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 66: training loss = 0.2376, validation loss = 0.8277. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 67: training loss = 0.2320, validation loss = 0.8145. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 68: training loss = 0.2424, validation loss = 0.8278. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 69: training loss = 0.2314, validation loss = 0.8432. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 69; restoring weights from epoch 19\n",
      "Epoch 1: training loss = 0.6557, validation loss = 0.6609. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4105, validation loss = 0.8394. Learning rate = 0.001. Patience = 1\n",
      "Epoch 3: training loss = 0.3134, validation loss = 0.5778. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3017, validation loss = 0.6946. Learning rate = 0.001. Patience = 1\n",
      "Epoch 5: training loss = 0.3001, validation loss = 0.3892. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2762, validation loss = 0.5939. Learning rate = 0.001. Patience = 1\n",
      "Epoch 7: training loss = 0.2644, validation loss = 0.3061. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.2616, validation loss = 0.3810. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.2613, validation loss = 0.2926. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2522, validation loss = 0.3585. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2411, validation loss = 0.3179. Learning rate = 0.001. Patience = 2\n",
      "Epoch 12: training loss = 0.2515, validation loss = 0.3081. Learning rate = 0.001. Patience = 3\n",
      "Epoch 13: training loss = 0.2525, validation loss = 0.3512. Learning rate = 0.001. Patience = 4\n",
      "Epoch 14: training loss = 0.2593, validation loss = 0.2775. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.2376, validation loss = 0.3452. Learning rate = 0.001. Patience = 1\n",
      "Epoch 16: training loss = 0.2427, validation loss = 0.2928. Learning rate = 0.001. Patience = 2\n",
      "Epoch 17: training loss = 0.2537, validation loss = 0.3043. Learning rate = 0.001. Patience = 3\n",
      "Epoch 18: training loss = 0.2419, validation loss = 0.3070. Learning rate = 0.001. Patience = 4\n",
      "Epoch 19: training loss = 0.2494, validation loss = 0.3783. Learning rate = 0.001. Patience = 5\n",
      "Epoch 20: training loss = 0.2401, validation loss = 0.2348. Learning rate = 0.001. Patience = 0\n",
      "Epoch 21: training loss = 0.2367, validation loss = 0.4281. Learning rate = 0.001. Patience = 1\n",
      "Epoch 22: training loss = 0.2344, validation loss = 0.2513. Learning rate = 0.001. Patience = 2\n",
      "Epoch 23: training loss = 0.2330, validation loss = 0.3237. Learning rate = 0.001. Patience = 3\n",
      "Epoch 24: training loss = 0.2212, validation loss = 0.2958. Learning rate = 0.001. Patience = 4\n",
      "Epoch 25: training loss = 0.2228, validation loss = 0.2976. Learning rate = 0.001. Patience = 5\n",
      "Epoch 26: training loss = 0.2179, validation loss = 0.3157. Learning rate = 0.001. Patience = 6\n",
      "Epoch 27: training loss = 0.2183, validation loss = 0.2633. Learning rate = 0.001. Patience = 7\n",
      "Epoch 28: training loss = 0.2219, validation loss = 0.3011. Learning rate = 0.001. Patience = 8\n",
      "Epoch 29: training loss = 0.2202, validation loss = 0.3247. Learning rate = 0.001. Patience = 9\n",
      "Epoch 30: training loss = 0.2629, validation loss = 0.3478. Learning rate = 0.001. Patience = 10\n",
      "Epoch 31: training loss = 0.2379, validation loss = 0.2614. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 32: training loss = 0.2232, validation loss = 0.2955. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 33: training loss = 0.2267, validation loss = 0.2949. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 34: training loss = 0.2266, validation loss = 0.3200. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 35: training loss = 0.2377, validation loss = 0.3351. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 36: training loss = 0.2145, validation loss = 0.2760. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 37: training loss = 0.2321, validation loss = 0.2966. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 38: training loss = 0.2233, validation loss = 0.3075. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 39: training loss = 0.2081, validation loss = 0.3514. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 40: training loss = 0.2478, validation loss = 0.2703. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 41: training loss = 0.2111, validation loss = 0.3434. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 42: training loss = 0.2507, validation loss = 0.3166. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 43: training loss = 0.2302, validation loss = 0.4167. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 44: training loss = 0.2319, validation loss = 0.2759. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 45: training loss = 0.2251, validation loss = 0.3437. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 46: training loss = 0.2201, validation loss = 0.3251. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 47: training loss = 0.2148, validation loss = 0.3504. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 48: training loss = 0.2168, validation loss = 0.3809. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 49: training loss = 0.2040, validation loss = 0.2713. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 50: training loss = 0.2383, validation loss = 0.3447. Learning rate = 0.00025. Patience = 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51: training loss = 0.2048, validation loss = 0.3304. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 52: training loss = 0.2080, validation loss = 0.3183. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 53: training loss = 0.2285, validation loss = 0.3386. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 54: training loss = 0.2124, validation loss = 0.3172. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 55: training loss = 0.2046, validation loss = 0.3281. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 56: training loss = 0.1984, validation loss = 0.3049. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 57: training loss = 0.2153, validation loss = 0.3225. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 58: training loss = 0.2156, validation loss = 0.3253. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 59: training loss = 0.2026, validation loss = 0.3152. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 60: training loss = 0.2181, validation loss = 0.3084. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 61: training loss = 0.2070, validation loss = 0.3064. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 62: training loss = 0.2166, validation loss = 0.3770. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 63: training loss = 0.2090, validation loss = 0.3502. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 64: training loss = 0.2055, validation loss = 0.3189. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 65: training loss = 0.2248, validation loss = 0.3164. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 66: training loss = 0.2166, validation loss = 0.3210. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 67: training loss = 0.2301, validation loss = 0.3240. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 68: training loss = 0.2166, validation loss = 0.3600. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 69: training loss = 0.2025, validation loss = 0.3428. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 70: training loss = 0.2162, validation loss = 0.3235. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 70; restoring weights from epoch 20\n",
      "Epoch 1: training loss = 0.5618, validation loss = 0.5179. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4345, validation loss = 0.7570. Learning rate = 0.001. Patience = 1\n",
      "Epoch 3: training loss = 0.3797, validation loss = 0.5137. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3676, validation loss = 0.4972. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.3635, validation loss = 0.5475. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.3249, validation loss = 0.4020. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.3477, validation loss = 0.4058. Learning rate = 0.001. Patience = 1\n",
      "Epoch 8: training loss = 0.3350, validation loss = 0.3900. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.3287, validation loss = 0.5133. Learning rate = 0.001. Patience = 1\n",
      "Epoch 10: training loss = 0.3848, validation loss = 0.3574. Learning rate = 0.001. Patience = 0\n",
      "Epoch 11: training loss = 0.3560, validation loss = 0.4171. Learning rate = 0.001. Patience = 1\n",
      "Epoch 12: training loss = 0.3043, validation loss = 0.4605. Learning rate = 0.001. Patience = 2\n",
      "Epoch 13: training loss = 0.3024, validation loss = 0.3539. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.3387, validation loss = 0.4149. Learning rate = 0.001. Patience = 1\n",
      "Epoch 15: training loss = 0.3020, validation loss = 0.4035. Learning rate = 0.001. Patience = 2\n",
      "Epoch 16: training loss = 0.2866, validation loss = 0.3698. Learning rate = 0.001. Patience = 3\n",
      "Epoch 17: training loss = 0.2982, validation loss = 0.3547. Learning rate = 0.001. Patience = 4\n",
      "Epoch 18: training loss = 0.2899, validation loss = 0.3756. Learning rate = 0.001. Patience = 5\n",
      "Epoch 19: training loss = 0.3251, validation loss = 0.3344. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.3126, validation loss = 0.3939. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.2887, validation loss = 0.3100. Learning rate = 0.001. Patience = 0\n",
      "Epoch 22: training loss = 0.2714, validation loss = 0.3770. Learning rate = 0.001. Patience = 1\n",
      "Epoch 23: training loss = 0.2656, validation loss = 0.3180. Learning rate = 0.001. Patience = 2\n",
      "Epoch 24: training loss = 0.2687, validation loss = 0.3499. Learning rate = 0.001. Patience = 3\n",
      "Epoch 25: training loss = 0.2807, validation loss = 0.3208. Learning rate = 0.001. Patience = 4\n",
      "Epoch 26: training loss = 0.2814, validation loss = 0.3660. Learning rate = 0.001. Patience = 5\n",
      "Epoch 27: training loss = 0.2678, validation loss = 0.3474. Learning rate = 0.001. Patience = 6\n",
      "Epoch 28: training loss = 0.2588, validation loss = 0.3972. Learning rate = 0.001. Patience = 7\n",
      "Epoch 29: training loss = 0.2869, validation loss = 0.2884. Learning rate = 0.001. Patience = 0\n",
      "Epoch 30: training loss = 0.2911, validation loss = 0.4096. Learning rate = 0.001. Patience = 1\n",
      "Epoch 31: training loss = 0.2560, validation loss = 0.2970. Learning rate = 0.001. Patience = 2\n",
      "Epoch 32: training loss = 0.2578, validation loss = 0.3649. Learning rate = 0.001. Patience = 3\n",
      "Epoch 33: training loss = 0.2789, validation loss = 0.2913. Learning rate = 0.001. Patience = 4\n",
      "Epoch 34: training loss = 0.3063, validation loss = 0.3412. Learning rate = 0.001. Patience = 5\n",
      "Epoch 35: training loss = 0.2949, validation loss = 0.3211. Learning rate = 0.001. Patience = 6\n",
      "Epoch 36: training loss = 0.2787, validation loss = 0.3309. Learning rate = 0.001. Patience = 7\n",
      "Epoch 37: training loss = 0.2488, validation loss = 0.3133. Learning rate = 0.001. Patience = 8\n",
      "Epoch 38: training loss = 0.2417, validation loss = 0.3387. Learning rate = 0.001. Patience = 9\n",
      "Epoch 39: training loss = 0.2649, validation loss = 0.2915. Learning rate = 0.001. Patience = 10\n",
      "Epoch 40: training loss = 0.2674, validation loss = 0.3478. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 41: training loss = 0.2428, validation loss = 0.2973. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 42: training loss = 0.2565, validation loss = 0.3031. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 43: training loss = 0.2660, validation loss = 0.3163. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 44: training loss = 0.2597, validation loss = 0.2986. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 45: training loss = 0.2807, validation loss = 0.3266. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 46: training loss = 0.2592, validation loss = 0.3023. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 47: training loss = 0.2376, validation loss = 0.3136. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 48: training loss = 0.2769, validation loss = 0.3336. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 49: training loss = 0.2477, validation loss = 0.3250. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 50: training loss = 0.2457, validation loss = 0.3007. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 51: training loss = 0.3189, validation loss = 0.3300. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 52: training loss = 0.2813, validation loss = 0.3186. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 53: training loss = 0.2562, validation loss = 0.3091. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 54: training loss = 0.2714, validation loss = 0.3182. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 55: training loss = 0.2917, validation loss = 0.3470. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 56: training loss = 0.2361, validation loss = 0.3136. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 57: training loss = 0.2955, validation loss = 0.3056. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 58: training loss = 0.2593, validation loss = 0.3171. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 59: training loss = 0.2602, validation loss = 0.3246. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 60: training loss = 0.2316, validation loss = 0.3071. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 61: training loss = 0.2387, validation loss = 0.3108. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 62: training loss = 0.2614, validation loss = 0.3143. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 63: training loss = 0.2700, validation loss = 0.3111. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 64: training loss = 0.2663, validation loss = 0.3090. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 65: training loss = 0.2564, validation loss = 0.3126. Learning rate = 0.000125. Patience = 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66: training loss = 0.2714, validation loss = 0.3193. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 67: training loss = 0.2489, validation loss = 0.3129. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 68: training loss = 0.2439, validation loss = 0.3122. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 69: training loss = 0.2427, validation loss = 0.3220. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 70: training loss = 0.2341, validation loss = 0.3196. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 71: training loss = 0.2427, validation loss = 0.3202. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 72: training loss = 0.2307, validation loss = 0.3116. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 73: training loss = 0.2684, validation loss = 0.3122. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 74: training loss = 0.2766, validation loss = 0.3136. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 75: training loss = 0.2475, validation loss = 0.3142. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 76: training loss = 0.2486, validation loss = 0.3142. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 77: training loss = 0.2374, validation loss = 0.3154. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 78: training loss = 0.2767, validation loss = 0.3122. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 79: training loss = 0.2786, validation loss = 0.3157. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 79; restoring weights from epoch 29\n",
      "Epoch 1: training loss = 0.6430, validation loss = 0.4991. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.3563, validation loss = 0.3078. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.2747, validation loss = 0.2877. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.2398, validation loss = 0.2696. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.2274, validation loss = 0.2736. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.2087, validation loss = 0.2577. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2161, validation loss = 0.2513. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.2114, validation loss = 0.2429. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.2002, validation loss = 0.2395. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.1985, validation loss = 0.2396. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.1960, validation loss = 0.2312. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.2049, validation loss = 0.2325. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.1976, validation loss = 0.2274. Learning rate = 0.001. Patience = 0\n",
      "Epoch 14: training loss = 0.1925, validation loss = 0.2306. Learning rate = 0.001. Patience = 1\n",
      "Epoch 15: training loss = 0.1992, validation loss = 0.2257. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.1841, validation loss = 0.2290. Learning rate = 0.001. Patience = 1\n",
      "Epoch 17: training loss = 0.1859, validation loss = 0.2266. Learning rate = 0.001. Patience = 2\n",
      "Epoch 18: training loss = 0.1812, validation loss = 0.2192. Learning rate = 0.001. Patience = 0\n",
      "Epoch 19: training loss = 0.1821, validation loss = 0.2198. Learning rate = 0.001. Patience = 1\n",
      "Epoch 20: training loss = 0.1869, validation loss = 0.2194. Learning rate = 0.001. Patience = 2\n",
      "Epoch 21: training loss = 0.1728, validation loss = 0.2185. Learning rate = 0.001. Patience = 0\n",
      "Epoch 22: training loss = 0.1713, validation loss = 0.2190. Learning rate = 0.001. Patience = 1\n",
      "Epoch 23: training loss = 0.1766, validation loss = 0.2253. Learning rate = 0.001. Patience = 2\n",
      "Epoch 24: training loss = 0.1796, validation loss = 0.2236. Learning rate = 0.001. Patience = 3\n",
      "Epoch 25: training loss = 0.1936, validation loss = 0.2207. Learning rate = 0.001. Patience = 4\n",
      "Epoch 26: training loss = 0.1755, validation loss = 0.2194. Learning rate = 0.001. Patience = 5\n",
      "Epoch 27: training loss = 0.1672, validation loss = 0.2238. Learning rate = 0.001. Patience = 6\n",
      "Epoch 28: training loss = 0.1667, validation loss = 0.2220. Learning rate = 0.001. Patience = 7\n",
      "Epoch 29: training loss = 0.1717, validation loss = 0.2153. Learning rate = 0.001. Patience = 0\n",
      "Epoch 30: training loss = 0.1717, validation loss = 0.2249. Learning rate = 0.001. Patience = 1\n",
      "Epoch 31: training loss = 0.1762, validation loss = 0.2258. Learning rate = 0.001. Patience = 2\n",
      "Epoch 32: training loss = 0.1728, validation loss = 0.2193. Learning rate = 0.001. Patience = 3\n",
      "Epoch 33: training loss = 0.1615, validation loss = 0.2299. Learning rate = 0.001. Patience = 4\n",
      "Epoch 34: training loss = 0.1663, validation loss = 0.2192. Learning rate = 0.001. Patience = 5\n",
      "Epoch 35: training loss = 0.1664, validation loss = 0.2265. Learning rate = 0.001. Patience = 6\n",
      "Epoch 36: training loss = 0.1661, validation loss = 0.2227. Learning rate = 0.001. Patience = 7\n",
      "Epoch 37: training loss = 0.1707, validation loss = 0.2226. Learning rate = 0.001. Patience = 8\n",
      "Epoch 38: training loss = 0.1688, validation loss = 0.2213. Learning rate = 0.001. Patience = 9\n",
      "Epoch 39: training loss = 0.1680, validation loss = 0.2229. Learning rate = 0.001. Patience = 10\n",
      "Epoch 40: training loss = 0.1605, validation loss = 0.2268. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 41: training loss = 0.1646, validation loss = 0.2240. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 42: training loss = 0.1587, validation loss = 0.2249. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 43: training loss = 0.1614, validation loss = 0.2272. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 44: training loss = 0.1597, validation loss = 0.2238. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 45: training loss = 0.1495, validation loss = 0.2193. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 46: training loss = 0.1661, validation loss = 0.2229. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 47: training loss = 0.1635, validation loss = 0.2188. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 48: training loss = 0.1540, validation loss = 0.2206. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 49: training loss = 0.1485, validation loss = 0.2208. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 50: training loss = 0.1527, validation loss = 0.2180. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 51: training loss = 0.1606, validation loss = 0.2192. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 52: training loss = 0.1535, validation loss = 0.2228. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 53: training loss = 0.1495, validation loss = 0.2225. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 54: training loss = 0.1515, validation loss = 0.2209. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 55: training loss = 0.1519, validation loss = 0.2194. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 56: training loss = 0.1476, validation loss = 0.2197. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 57: training loss = 0.1562, validation loss = 0.2201. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 58: training loss = 0.1580, validation loss = 0.2226. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 59: training loss = 0.1525, validation loss = 0.2217. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 60: training loss = 0.1628, validation loss = 0.2205. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 61: training loss = 0.1543, validation loss = 0.2190. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 62: training loss = 0.1661, validation loss = 0.2216. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 63: training loss = 0.1530, validation loss = 0.2254. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 64: training loss = 0.1491, validation loss = 0.2225. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 65: training loss = 0.1485, validation loss = 0.2201. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 66: training loss = 0.1435, validation loss = 0.2201. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 67: training loss = 0.1517, validation loss = 0.2210. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 68: training loss = 0.1468, validation loss = 0.2215. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 69: training loss = 0.1542, validation loss = 0.2217. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 70: training loss = 0.1536, validation loss = 0.2210. Learning rate = 0.000125. Patience = 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71: training loss = 0.1527, validation loss = 0.2219. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 72: training loss = 0.1482, validation loss = 0.2217. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 73: training loss = 0.1508, validation loss = 0.2205. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 74: training loss = 0.1542, validation loss = 0.2200. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 75: training loss = 0.1608, validation loss = 0.2198. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 76: training loss = 0.1446, validation loss = 0.2204. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 77: training loss = 0.1501, validation loss = 0.2206. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 78: training loss = 0.1426, validation loss = 0.2213. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 79: training loss = 0.1415, validation loss = 0.2208. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 79; restoring weights from epoch 29\n",
      "Epoch 1: training loss = 0.7767, validation loss = 1.0735. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.4544, validation loss = 0.7125. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3678, validation loss = 0.4564. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.3408, validation loss = 0.3811. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.3232, validation loss = 0.3713. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.3136, validation loss = 0.4767. Learning rate = 0.001. Patience = 1\n",
      "Epoch 7: training loss = 0.3359, validation loss = 0.4097. Learning rate = 0.001. Patience = 2\n",
      "Epoch 8: training loss = 0.3151, validation loss = 0.4342. Learning rate = 0.001. Patience = 3\n",
      "Epoch 9: training loss = 0.3013, validation loss = 0.3894. Learning rate = 0.001. Patience = 4\n",
      "Epoch 10: training loss = 0.3183, validation loss = 0.3947. Learning rate = 0.001. Patience = 5\n",
      "Epoch 11: training loss = 0.3106, validation loss = 0.4403. Learning rate = 0.001. Patience = 6\n",
      "Epoch 12: training loss = 0.2912, validation loss = 0.4051. Learning rate = 0.001. Patience = 7\n",
      "Epoch 13: training loss = 0.2881, validation loss = 0.3914. Learning rate = 0.001. Patience = 8\n",
      "Epoch 14: training loss = 0.3064, validation loss = 0.3810. Learning rate = 0.001. Patience = 9\n",
      "Epoch 15: training loss = 0.2889, validation loss = 0.4030. Learning rate = 0.001. Patience = 10\n",
      "Epoch 16: training loss = 0.2770, validation loss = 0.4352. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 17: training loss = 0.2965, validation loss = 0.3594. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 18: training loss = 0.2772, validation loss = 0.4046. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 19: training loss = 0.3039, validation loss = 0.3857. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 20: training loss = 0.2836, validation loss = 0.3866. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 21: training loss = 0.2784, validation loss = 0.3814. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 22: training loss = 0.2729, validation loss = 0.3840. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 23: training loss = 0.2841, validation loss = 0.3701. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 24: training loss = 0.2777, validation loss = 0.3528. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 25: training loss = 0.2689, validation loss = 0.3898. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 26: training loss = 0.2753, validation loss = 0.3677. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 27: training loss = 0.2757, validation loss = 0.3682. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 28: training loss = 0.2716, validation loss = 0.3809. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 29: training loss = 0.2824, validation loss = 0.3759. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 30: training loss = 0.2653, validation loss = 0.3901. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 31: training loss = 0.2875, validation loss = 0.3551. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 32: training loss = 0.2637, validation loss = 0.4230. Learning rate = 0.0005. Patience = 8\n",
      "Epoch 33: training loss = 0.2929, validation loss = 0.3579. Learning rate = 0.0005. Patience = 9\n",
      "Epoch 34: training loss = 0.2630, validation loss = 0.3580. Learning rate = 0.0005. Patience = 10\n",
      "Epoch 35: training loss = 0.2804, validation loss = 0.3753. Learning rate = 0.00025. Patience = 11\n",
      "Epoch 36: training loss = 0.2587, validation loss = 0.3473. Learning rate = 0.00025. Patience = 0\n",
      "Epoch 37: training loss = 0.2614, validation loss = 0.3687. Learning rate = 0.00025. Patience = 1\n",
      "Epoch 38: training loss = 0.2540, validation loss = 0.3859. Learning rate = 0.00025. Patience = 2\n",
      "Epoch 39: training loss = 0.2749, validation loss = 0.3595. Learning rate = 0.00025. Patience = 3\n",
      "Epoch 40: training loss = 0.2586, validation loss = 0.3751. Learning rate = 0.00025. Patience = 4\n",
      "Epoch 41: training loss = 0.2632, validation loss = 0.3657. Learning rate = 0.00025. Patience = 5\n",
      "Epoch 42: training loss = 0.2495, validation loss = 0.3504. Learning rate = 0.00025. Patience = 6\n",
      "Epoch 43: training loss = 0.2716, validation loss = 0.3764. Learning rate = 0.00025. Patience = 7\n",
      "Epoch 44: training loss = 0.2625, validation loss = 0.3461. Learning rate = 0.00025. Patience = 0\n",
      "Epoch 45: training loss = 0.2551, validation loss = 0.3655. Learning rate = 0.00025. Patience = 1\n",
      "Epoch 46: training loss = 0.2657, validation loss = 0.3455. Learning rate = 0.00025. Patience = 0\n",
      "Epoch 47: training loss = 0.2586, validation loss = 0.3882. Learning rate = 0.00025. Patience = 1\n",
      "Epoch 48: training loss = 0.2815, validation loss = 0.3776. Learning rate = 0.00025. Patience = 2\n",
      "Epoch 49: training loss = 0.2499, validation loss = 0.3573. Learning rate = 0.00025. Patience = 3\n",
      "Epoch 50: training loss = 0.2563, validation loss = 0.3540. Learning rate = 0.00025. Patience = 4\n",
      "Epoch 51: training loss = 0.2639, validation loss = 0.3623. Learning rate = 0.00025. Patience = 5\n",
      "Epoch 52: training loss = 0.2667, validation loss = 0.3495. Learning rate = 0.00025. Patience = 6\n",
      "Epoch 53: training loss = 0.2650, validation loss = 0.3596. Learning rate = 0.00025. Patience = 7\n",
      "Epoch 54: training loss = 0.2607, validation loss = 0.3626. Learning rate = 0.00025. Patience = 8\n",
      "Epoch 55: training loss = 0.2541, validation loss = 0.3555. Learning rate = 0.00025. Patience = 9\n",
      "Epoch 56: training loss = 0.2516, validation loss = 0.3536. Learning rate = 0.00025. Patience = 10\n",
      "Epoch 57: training loss = 0.2518, validation loss = 0.3541. Learning rate = 0.000125. Patience = 11\n",
      "Epoch 58: training loss = 0.2591, validation loss = 0.3624. Learning rate = 0.000125. Patience = 12\n",
      "Epoch 59: training loss = 0.2643, validation loss = 0.3508. Learning rate = 0.000125. Patience = 13\n",
      "Epoch 60: training loss = 0.2475, validation loss = 0.3529. Learning rate = 0.000125. Patience = 14\n",
      "Epoch 61: training loss = 0.2398, validation loss = 0.3611. Learning rate = 0.000125. Patience = 15\n",
      "Epoch 62: training loss = 0.2414, validation loss = 0.3573. Learning rate = 0.000125. Patience = 16\n",
      "Epoch 63: training loss = 0.2485, validation loss = 0.3521. Learning rate = 0.000125. Patience = 17\n",
      "Epoch 64: training loss = 0.2388, validation loss = 0.3602. Learning rate = 0.000125. Patience = 18\n",
      "Epoch 65: training loss = 0.2702, validation loss = 0.3515. Learning rate = 0.000125. Patience = 19\n",
      "Epoch 66: training loss = 0.2526, validation loss = 0.3531. Learning rate = 0.000125. Patience = 20\n",
      "Epoch 67: training loss = 0.2606, validation loss = 0.3699. Learning rate = 0.000125. Patience = 21\n",
      "Epoch 68: training loss = 0.2511, validation loss = 0.3604. Learning rate = 6.25e-05. Patience = 22\n",
      "Epoch 69: training loss = 0.2452, validation loss = 0.3612. Learning rate = 6.25e-05. Patience = 23\n",
      "Epoch 70: training loss = 0.2439, validation loss = 0.3572. Learning rate = 6.25e-05. Patience = 24\n",
      "Epoch 71: training loss = 0.2554, validation loss = 0.3641. Learning rate = 6.25e-05. Patience = 25\n",
      "Epoch 72: training loss = 0.2490, validation loss = 0.3536. Learning rate = 6.25e-05. Patience = 26\n",
      "Epoch 73: training loss = 0.2476, validation loss = 0.3485. Learning rate = 6.25e-05. Patience = 27\n",
      "Epoch 74: training loss = 0.2407, validation loss = 0.3588. Learning rate = 6.25e-05. Patience = 28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75: training loss = 0.2760, validation loss = 0.3592. Learning rate = 6.25e-05. Patience = 29\n",
      "Epoch 76: training loss = 0.2348, validation loss = 0.3630. Learning rate = 6.25e-05. Patience = 30\n",
      "Epoch 77: training loss = 0.2444, validation loss = 0.3549. Learning rate = 6.25e-05. Patience = 31\n",
      "Epoch 78: training loss = 0.2441, validation loss = 0.3568. Learning rate = 6.25e-05. Patience = 32\n",
      "Epoch 79: training loss = 0.2484, validation loss = 0.3574. Learning rate = 3.125e-05. Patience = 33\n",
      "Epoch 80: training loss = 0.2543, validation loss = 0.3588. Learning rate = 3.125e-05. Patience = 34\n",
      "Epoch 81: training loss = 0.2416, validation loss = 0.3557. Learning rate = 3.125e-05. Patience = 35\n",
      "Epoch 82: training loss = 0.2648, validation loss = 0.3540. Learning rate = 3.125e-05. Patience = 36\n",
      "Epoch 83: training loss = 0.2391, validation loss = 0.3546. Learning rate = 3.125e-05. Patience = 37\n",
      "Epoch 84: training loss = 0.2504, validation loss = 0.3554. Learning rate = 3.125e-05. Patience = 38\n",
      "Epoch 85: training loss = 0.2456, validation loss = 0.3510. Learning rate = 3.125e-05. Patience = 39\n",
      "Epoch 86: training loss = 0.2459, validation loss = 0.3561. Learning rate = 3.125e-05. Patience = 40\n",
      "Epoch 87: training loss = 0.2591, validation loss = 0.3560. Learning rate = 3.125e-05. Patience = 41\n",
      "Epoch 88: training loss = 0.2411, validation loss = 0.3604. Learning rate = 3.125e-05. Patience = 42\n",
      "Epoch 89: training loss = 0.2371, validation loss = 0.3584. Learning rate = 3.125e-05. Patience = 43\n",
      "Epoch 90: training loss = 0.2509, validation loss = 0.3569. Learning rate = 1.5625e-05. Patience = 44\n",
      "Epoch 91: training loss = 0.2488, validation loss = 0.3564. Learning rate = 1.5625e-05. Patience = 45\n",
      "Epoch 92: training loss = 0.2517, validation loss = 0.3552. Learning rate = 1.5625e-05. Patience = 46\n",
      "Epoch 93: training loss = 0.2428, validation loss = 0.3553. Learning rate = 1.5625e-05. Patience = 47\n",
      "Epoch 94: training loss = 0.2475, validation loss = 0.3573. Learning rate = 1.5625e-05. Patience = 48\n",
      "Epoch 95: training loss = 0.2506, validation loss = 0.3566. Learning rate = 1.5625e-05. Patience = 49\n",
      "Epoch 96: training loss = 0.2448, validation loss = 0.3571. Learning rate = 1.5625e-05. Patience = 50\n",
      "Training stopped at epoch 96; restoring weights from epoch 46\n",
      "Epoch 1: training loss = 0.6706, validation loss = 0.3040. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.3626, validation loss = 0.2697. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.3116, validation loss = 0.4453. Learning rate = 0.001. Patience = 1\n",
      "Epoch 4: training loss = 0.3604, validation loss = 0.2739. Learning rate = 0.001. Patience = 2\n",
      "Epoch 5: training loss = 0.3173, validation loss = 0.2639. Learning rate = 0.001. Patience = 0\n",
      "Epoch 6: training loss = 0.2786, validation loss = 0.2230. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.2942, validation loss = 0.1841. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.2818, validation loss = 0.1605. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.2701, validation loss = 0.1270. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.2813, validation loss = 0.1574. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.2547, validation loss = 0.1216. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.2717, validation loss = 0.1490. Learning rate = 0.001. Patience = 1\n",
      "Epoch 13: training loss = 0.2504, validation loss = 0.1353. Learning rate = 0.001. Patience = 2\n",
      "Epoch 14: training loss = 0.2461, validation loss = 0.1219. Learning rate = 0.001. Patience = 3\n",
      "Epoch 15: training loss = 0.2682, validation loss = 0.1417. Learning rate = 0.001. Patience = 4\n",
      "Epoch 16: training loss = 0.2452, validation loss = 0.1321. Learning rate = 0.001. Patience = 5\n",
      "Epoch 17: training loss = 0.2354, validation loss = 0.1342. Learning rate = 0.001. Patience = 6\n",
      "Epoch 18: training loss = 0.2333, validation loss = 0.1340. Learning rate = 0.001. Patience = 7\n",
      "Epoch 19: training loss = 0.2716, validation loss = 0.1197. Learning rate = 0.001. Patience = 0\n",
      "Epoch 20: training loss = 0.2492, validation loss = 0.1200. Learning rate = 0.001. Patience = 1\n",
      "Epoch 21: training loss = 0.2533, validation loss = 0.1587. Learning rate = 0.001. Patience = 2\n",
      "Epoch 22: training loss = 0.2308, validation loss = 0.1188. Learning rate = 0.001. Patience = 0\n",
      "Epoch 23: training loss = 0.2659, validation loss = 0.1372. Learning rate = 0.001. Patience = 1\n",
      "Epoch 24: training loss = 0.2363, validation loss = 0.1231. Learning rate = 0.001. Patience = 2\n",
      "Epoch 25: training loss = 0.2261, validation loss = 0.1339. Learning rate = 0.001. Patience = 3\n",
      "Epoch 26: training loss = 0.2262, validation loss = 0.1223. Learning rate = 0.001. Patience = 4\n",
      "Epoch 27: training loss = 0.2428, validation loss = 0.1388. Learning rate = 0.001. Patience = 5\n",
      "Epoch 28: training loss = 0.2283, validation loss = 0.1130. Learning rate = 0.001. Patience = 0\n",
      "Epoch 29: training loss = 0.2401, validation loss = 0.1491. Learning rate = 0.001. Patience = 1\n",
      "Epoch 30: training loss = 0.2377, validation loss = 0.1142. Learning rate = 0.001. Patience = 2\n",
      "Epoch 31: training loss = 0.2188, validation loss = 0.1386. Learning rate = 0.001. Patience = 3\n",
      "Epoch 32: training loss = 0.2345, validation loss = 0.1566. Learning rate = 0.001. Patience = 4\n",
      "Epoch 33: training loss = 0.2327, validation loss = 0.1166. Learning rate = 0.001. Patience = 5\n",
      "Epoch 34: training loss = 0.2268, validation loss = 0.1770. Learning rate = 0.001. Patience = 6\n",
      "Epoch 35: training loss = 0.2284, validation loss = 0.1102. Learning rate = 0.001. Patience = 0\n",
      "Epoch 36: training loss = 0.2350, validation loss = 0.2139. Learning rate = 0.001. Patience = 1\n",
      "Epoch 37: training loss = 0.2355, validation loss = 0.1059. Learning rate = 0.001. Patience = 0\n",
      "Epoch 38: training loss = 0.2207, validation loss = 0.1412. Learning rate = 0.001. Patience = 1\n",
      "Epoch 39: training loss = 0.2526, validation loss = 0.1368. Learning rate = 0.001. Patience = 2\n",
      "Epoch 40: training loss = 0.2438, validation loss = 0.1360. Learning rate = 0.001. Patience = 3\n",
      "Epoch 41: training loss = 0.2127, validation loss = 0.1144. Learning rate = 0.001. Patience = 4\n",
      "Epoch 42: training loss = 0.2330, validation loss = 0.1781. Learning rate = 0.001. Patience = 5\n",
      "Epoch 43: training loss = 0.2262, validation loss = 0.1140. Learning rate = 0.001. Patience = 6\n",
      "Epoch 44: training loss = 0.2208, validation loss = 0.1944. Learning rate = 0.001. Patience = 7\n",
      "Epoch 45: training loss = 0.2320, validation loss = 0.1203. Learning rate = 0.001. Patience = 8\n",
      "Epoch 46: training loss = 0.2170, validation loss = 0.1436. Learning rate = 0.001. Patience = 9\n",
      "Epoch 47: training loss = 0.2526, validation loss = 0.1378. Learning rate = 0.001. Patience = 10\n",
      "Epoch 48: training loss = 0.2245, validation loss = 0.1437. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 49: training loss = 0.2607, validation loss = 0.1359. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 50: training loss = 0.2224, validation loss = 0.1409. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 51: training loss = 0.2151, validation loss = 0.1335. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 52: training loss = 0.2152, validation loss = 0.1323. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 53: training loss = 0.2026, validation loss = 0.1375. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 54: training loss = 0.2335, validation loss = 0.1569. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 55: training loss = 0.2362, validation loss = 0.1393. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 56: training loss = 0.2202, validation loss = 0.1337. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 57: training loss = 0.2154, validation loss = 0.1568. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 58: training loss = 0.2123, validation loss = 0.1393. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 59: training loss = 0.2147, validation loss = 0.1387. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 60: training loss = 0.2046, validation loss = 0.1386. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 61: training loss = 0.2203, validation loss = 0.1497. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 62: training loss = 0.2056, validation loss = 0.1448. Learning rate = 0.00025. Patience = 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63: training loss = 0.2054, validation loss = 0.1339. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 64: training loss = 0.1983, validation loss = 0.1489. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 65: training loss = 0.2358, validation loss = 0.1428. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 66: training loss = 0.2231, validation loss = 0.1593. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 67: training loss = 0.2139, validation loss = 0.1404. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 68: training loss = 0.2413, validation loss = 0.1448. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 69: training loss = 0.2174, validation loss = 0.1653. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 70: training loss = 0.2025, validation loss = 0.1478. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 71: training loss = 0.1961, validation loss = 0.1447. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 72: training loss = 0.2155, validation loss = 0.1448. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 73: training loss = 0.2092, validation loss = 0.1555. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 74: training loss = 0.2231, validation loss = 0.1505. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 75: training loss = 0.2325, validation loss = 0.1475. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 76: training loss = 0.2076, validation loss = 0.1413. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 77: training loss = 0.2080, validation loss = 0.1472. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 78: training loss = 0.2219, validation loss = 0.1508. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 79: training loss = 0.1989, validation loss = 0.1557. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 80: training loss = 0.2105, validation loss = 0.1510. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 81: training loss = 0.2156, validation loss = 0.1562. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 82: training loss = 0.2072, validation loss = 0.1570. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 83: training loss = 0.2249, validation loss = 0.1559. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 84: training loss = 0.2133, validation loss = 0.1534. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 85: training loss = 0.2136, validation loss = 0.1500. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 86: training loss = 0.2038, validation loss = 0.1478. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 87: training loss = 0.2094, validation loss = 0.1496. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 87; restoring weights from epoch 37\n",
      "Epoch 1: training loss = 0.9691, validation loss = 11.9656. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.6986, validation loss = 11.7087. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.6798, validation loss = 11.3813. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.6335, validation loss = 11.5428. Learning rate = 0.001. Patience = 1\n",
      "Epoch 5: training loss = 0.8513, validation loss = 11.7726. Learning rate = 0.001. Patience = 2\n",
      "Epoch 6: training loss = 0.7158, validation loss = 10.9715. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.5514, validation loss = 10.7076. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.5205, validation loss = 11.2590. Learning rate = 0.001. Patience = 1\n",
      "Epoch 9: training loss = 0.4772, validation loss = 11.4602. Learning rate = 0.001. Patience = 2\n",
      "Epoch 10: training loss = 0.4416, validation loss = 11.5137. Learning rate = 0.001. Patience = 3\n",
      "Epoch 11: training loss = 0.4227, validation loss = 11.6490. Learning rate = 0.001. Patience = 4\n",
      "Epoch 12: training loss = 0.3997, validation loss = 12.0294. Learning rate = 0.001. Patience = 5\n",
      "Epoch 13: training loss = 0.3828, validation loss = 12.0232. Learning rate = 0.001. Patience = 6\n",
      "Epoch 14: training loss = 0.5626, validation loss = 11.8868. Learning rate = 0.001. Patience = 7\n",
      "Epoch 15: training loss = 0.3645, validation loss = 12.0967. Learning rate = 0.001. Patience = 8\n",
      "Epoch 16: training loss = 0.3624, validation loss = 12.2724. Learning rate = 0.001. Patience = 9\n",
      "Epoch 17: training loss = 0.4964, validation loss = 12.1297. Learning rate = 0.001. Patience = 10\n",
      "Epoch 18: training loss = 0.3693, validation loss = 12.0285. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 19: training loss = 0.3698, validation loss = 12.4090. Learning rate = 0.0005. Patience = 12\n",
      "Epoch 20: training loss = 0.3624, validation loss = 11.7912. Learning rate = 0.0005. Patience = 13\n",
      "Epoch 21: training loss = 0.3671, validation loss = 12.0311. Learning rate = 0.0005. Patience = 14\n",
      "Epoch 22: training loss = 0.3786, validation loss = 13.6450. Learning rate = 0.0005. Patience = 15\n",
      "Epoch 23: training loss = 0.3570, validation loss = 12.4501. Learning rate = 0.0005. Patience = 16\n",
      "Epoch 24: training loss = 0.3543, validation loss = 12.1189. Learning rate = 0.0005. Patience = 17\n",
      "Epoch 25: training loss = 0.3579, validation loss = 12.2068. Learning rate = 0.0005. Patience = 18\n",
      "Epoch 26: training loss = 0.3513, validation loss = 12.5949. Learning rate = 0.0005. Patience = 19\n",
      "Epoch 27: training loss = 0.3579, validation loss = 12.6006. Learning rate = 0.0005. Patience = 20\n",
      "Epoch 28: training loss = 0.3576, validation loss = 12.5471. Learning rate = 0.0005. Patience = 21\n",
      "Epoch 29: training loss = 0.3552, validation loss = 12.4070. Learning rate = 0.00025. Patience = 22\n",
      "Epoch 30: training loss = 0.3456, validation loss = 12.4339. Learning rate = 0.00025. Patience = 23\n",
      "Epoch 31: training loss = 0.3963, validation loss = 12.4978. Learning rate = 0.00025. Patience = 24\n",
      "Epoch 32: training loss = 0.3485, validation loss = 12.1573. Learning rate = 0.00025. Patience = 25\n",
      "Epoch 33: training loss = 0.3476, validation loss = 12.1804. Learning rate = 0.00025. Patience = 26\n",
      "Epoch 34: training loss = 0.3499, validation loss = 12.3712. Learning rate = 0.00025. Patience = 27\n",
      "Epoch 35: training loss = 0.3490, validation loss = 12.3093. Learning rate = 0.00025. Patience = 28\n",
      "Epoch 36: training loss = 0.3475, validation loss = 12.2317. Learning rate = 0.00025. Patience = 29\n",
      "Epoch 37: training loss = 0.3494, validation loss = 12.1441. Learning rate = 0.00025. Patience = 30\n",
      "Epoch 38: training loss = 0.3501, validation loss = 12.0780. Learning rate = 0.00025. Patience = 31\n",
      "Epoch 39: training loss = 0.3519, validation loss = 11.9326. Learning rate = 0.00025. Patience = 32\n",
      "Epoch 40: training loss = 0.5290, validation loss = 12.0817. Learning rate = 0.000125. Patience = 33\n",
      "Epoch 41: training loss = 0.3557, validation loss = 12.0382. Learning rate = 0.000125. Patience = 34\n",
      "Epoch 42: training loss = 0.3867, validation loss = 12.0291. Learning rate = 0.000125. Patience = 35\n",
      "Epoch 43: training loss = 0.3468, validation loss = 12.2356. Learning rate = 0.000125. Patience = 36\n",
      "Epoch 44: training loss = 0.3458, validation loss = 12.3402. Learning rate = 0.000125. Patience = 37\n",
      "Epoch 45: training loss = 0.3501, validation loss = 12.2368. Learning rate = 0.000125. Patience = 38\n",
      "Epoch 46: training loss = 0.3511, validation loss = 12.0971. Learning rate = 0.000125. Patience = 39\n",
      "Epoch 47: training loss = 0.3433, validation loss = 12.0645. Learning rate = 0.000125. Patience = 40\n",
      "Epoch 48: training loss = 0.5797, validation loss = 12.1369. Learning rate = 0.000125. Patience = 41\n",
      "Epoch 49: training loss = 0.3465, validation loss = 12.0139. Learning rate = 0.000125. Patience = 42\n",
      "Epoch 50: training loss = 0.3524, validation loss = 11.8843. Learning rate = 0.000125. Patience = 43\n",
      "Epoch 51: training loss = 0.3553, validation loss = 11.9052. Learning rate = 6.25e-05. Patience = 44\n",
      "Epoch 52: training loss = 0.5029, validation loss = 11.9551. Learning rate = 6.25e-05. Patience = 45\n",
      "Epoch 53: training loss = 0.5719, validation loss = 11.9869. Learning rate = 6.25e-05. Patience = 46\n",
      "Epoch 54: training loss = 0.4772, validation loss = 11.9899. Learning rate = 6.25e-05. Patience = 47\n",
      "Epoch 55: training loss = 0.3480, validation loss = 12.0300. Learning rate = 6.25e-05. Patience = 48\n",
      "Epoch 56: training loss = 0.3893, validation loss = 12.0673. Learning rate = 6.25e-05. Patience = 49\n",
      "Epoch 57: training loss = 0.5345, validation loss = 11.9874. Learning rate = 6.25e-05. Patience = 50\n",
      "Training stopped at epoch 57; restoring weights from epoch 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: training loss = 0.8930, validation loss = 0.8276. Learning rate = 0.001. Patience = 0\n",
      "Epoch 2: training loss = 0.6104, validation loss = 0.5341. Learning rate = 0.001. Patience = 0\n",
      "Epoch 3: training loss = 0.4816, validation loss = 0.4295. Learning rate = 0.001. Patience = 0\n",
      "Epoch 4: training loss = 0.4631, validation loss = 0.3891. Learning rate = 0.001. Patience = 0\n",
      "Epoch 5: training loss = 0.4234, validation loss = 0.3926. Learning rate = 0.001. Patience = 1\n",
      "Epoch 6: training loss = 0.4165, validation loss = 0.3687. Learning rate = 0.001. Patience = 0\n",
      "Epoch 7: training loss = 0.4043, validation loss = 0.3598. Learning rate = 0.001. Patience = 0\n",
      "Epoch 8: training loss = 0.3963, validation loss = 0.3486. Learning rate = 0.001. Patience = 0\n",
      "Epoch 9: training loss = 0.4025, validation loss = 0.3438. Learning rate = 0.001. Patience = 0\n",
      "Epoch 10: training loss = 0.3927, validation loss = 0.3465. Learning rate = 0.001. Patience = 1\n",
      "Epoch 11: training loss = 0.3928, validation loss = 0.3322. Learning rate = 0.001. Patience = 0\n",
      "Epoch 12: training loss = 0.3760, validation loss = 0.3228. Learning rate = 0.001. Patience = 0\n",
      "Epoch 13: training loss = 0.3703, validation loss = 0.3256. Learning rate = 0.001. Patience = 1\n",
      "Epoch 14: training loss = 0.3606, validation loss = 0.3189. Learning rate = 0.001. Patience = 0\n",
      "Epoch 15: training loss = 0.3677, validation loss = 0.3131. Learning rate = 0.001. Patience = 0\n",
      "Epoch 16: training loss = 0.3488, validation loss = 0.3124. Learning rate = 0.001. Patience = 0\n",
      "Epoch 17: training loss = 0.3463, validation loss = 0.3113. Learning rate = 0.001. Patience = 0\n",
      "Epoch 18: training loss = 0.3557, validation loss = 0.3189. Learning rate = 0.001. Patience = 1\n",
      "Epoch 19: training loss = 0.3457, validation loss = 0.3125. Learning rate = 0.001. Patience = 2\n",
      "Epoch 20: training loss = 0.3313, validation loss = 0.3133. Learning rate = 0.001. Patience = 3\n",
      "Epoch 21: training loss = 0.3463, validation loss = 0.3012. Learning rate = 0.001. Patience = 0\n",
      "Epoch 22: training loss = 0.3346, validation loss = 0.3151. Learning rate = 0.001. Patience = 1\n",
      "Epoch 23: training loss = 0.3423, validation loss = 0.3026. Learning rate = 0.001. Patience = 2\n",
      "Epoch 24: training loss = 0.3298, validation loss = 0.3080. Learning rate = 0.001. Patience = 3\n",
      "Epoch 25: training loss = 0.3313, validation loss = 0.3097. Learning rate = 0.001. Patience = 4\n",
      "Epoch 26: training loss = 0.3173, validation loss = 0.3204. Learning rate = 0.001. Patience = 5\n",
      "Epoch 27: training loss = 0.3241, validation loss = 0.3007. Learning rate = 0.001. Patience = 0\n",
      "Epoch 28: training loss = 0.3189, validation loss = 0.3008. Learning rate = 0.001. Patience = 1\n",
      "Epoch 29: training loss = 0.3104, validation loss = 0.3085. Learning rate = 0.001. Patience = 2\n",
      "Epoch 30: training loss = 0.3087, validation loss = 0.3079. Learning rate = 0.001. Patience = 3\n",
      "Epoch 31: training loss = 0.3119, validation loss = 0.3040. Learning rate = 0.001. Patience = 4\n",
      "Epoch 32: training loss = 0.3063, validation loss = 0.2974. Learning rate = 0.001. Patience = 0\n",
      "Epoch 33: training loss = 0.2979, validation loss = 0.3011. Learning rate = 0.001. Patience = 1\n",
      "Epoch 34: training loss = 0.2978, validation loss = 0.3065. Learning rate = 0.001. Patience = 2\n",
      "Epoch 35: training loss = 0.3020, validation loss = 0.2979. Learning rate = 0.001. Patience = 3\n",
      "Epoch 36: training loss = 0.3073, validation loss = 0.3048. Learning rate = 0.001. Patience = 4\n",
      "Epoch 37: training loss = 0.2995, validation loss = 0.3019. Learning rate = 0.001. Patience = 5\n",
      "Epoch 38: training loss = 0.2988, validation loss = 0.3147. Learning rate = 0.001. Patience = 6\n",
      "Epoch 39: training loss = 0.2953, validation loss = 0.3030. Learning rate = 0.001. Patience = 7\n",
      "Epoch 40: training loss = 0.2963, validation loss = 0.3050. Learning rate = 0.001. Patience = 8\n",
      "Epoch 41: training loss = 0.2854, validation loss = 0.3196. Learning rate = 0.001. Patience = 9\n",
      "Epoch 42: training loss = 0.2873, validation loss = 0.3004. Learning rate = 0.001. Patience = 10\n",
      "Epoch 43: training loss = 0.2787, validation loss = 0.3100. Learning rate = 0.0005. Patience = 11\n",
      "Epoch 44: training loss = 0.2729, validation loss = 0.2960. Learning rate = 0.0005. Patience = 0\n",
      "Epoch 45: training loss = 0.2798, validation loss = 0.3055. Learning rate = 0.0005. Patience = 1\n",
      "Epoch 46: training loss = 0.2791, validation loss = 0.3188. Learning rate = 0.0005. Patience = 2\n",
      "Epoch 47: training loss = 0.2685, validation loss = 0.3042. Learning rate = 0.0005. Patience = 3\n",
      "Epoch 48: training loss = 0.2704, validation loss = 0.3104. Learning rate = 0.0005. Patience = 4\n",
      "Epoch 49: training loss = 0.2667, validation loss = 0.3097. Learning rate = 0.0005. Patience = 5\n",
      "Epoch 50: training loss = 0.2606, validation loss = 0.3133. Learning rate = 0.0005. Patience = 6\n",
      "Epoch 51: training loss = 0.2684, validation loss = 0.3097. Learning rate = 0.0005. Patience = 7\n",
      "Epoch 52: training loss = 0.2738, validation loss = 0.3142. Learning rate = 0.0005. Patience = 8\n",
      "Epoch 53: training loss = 0.2689, validation loss = 0.3185. Learning rate = 0.0005. Patience = 9\n",
      "Epoch 54: training loss = 0.2710, validation loss = 0.3158. Learning rate = 0.0005. Patience = 10\n",
      "Epoch 55: training loss = 0.2751, validation loss = 0.3148. Learning rate = 0.00025. Patience = 11\n",
      "Epoch 56: training loss = 0.2600, validation loss = 0.3082. Learning rate = 0.00025. Patience = 12\n",
      "Epoch 57: training loss = 0.2613, validation loss = 0.3074. Learning rate = 0.00025. Patience = 13\n",
      "Epoch 58: training loss = 0.2678, validation loss = 0.3139. Learning rate = 0.00025. Patience = 14\n",
      "Epoch 59: training loss = 0.2598, validation loss = 0.3154. Learning rate = 0.00025. Patience = 15\n",
      "Epoch 60: training loss = 0.2562, validation loss = 0.3129. Learning rate = 0.00025. Patience = 16\n",
      "Epoch 61: training loss = 0.2602, validation loss = 0.3089. Learning rate = 0.00025. Patience = 17\n",
      "Epoch 62: training loss = 0.2524, validation loss = 0.3075. Learning rate = 0.00025. Patience = 18\n",
      "Epoch 63: training loss = 0.2605, validation loss = 0.3102. Learning rate = 0.00025. Patience = 19\n",
      "Epoch 64: training loss = 0.2554, validation loss = 0.3098. Learning rate = 0.00025. Patience = 20\n",
      "Epoch 65: training loss = 0.2592, validation loss = 0.3102. Learning rate = 0.00025. Patience = 21\n",
      "Epoch 66: training loss = 0.2614, validation loss = 0.3138. Learning rate = 0.000125. Patience = 22\n",
      "Epoch 67: training loss = 0.2585, validation loss = 0.3128. Learning rate = 0.000125. Patience = 23\n",
      "Epoch 68: training loss = 0.2523, validation loss = 0.3106. Learning rate = 0.000125. Patience = 24\n",
      "Epoch 69: training loss = 0.2569, validation loss = 0.3111. Learning rate = 0.000125. Patience = 25\n",
      "Epoch 70: training loss = 0.2504, validation loss = 0.3112. Learning rate = 0.000125. Patience = 26\n",
      "Epoch 71: training loss = 0.2481, validation loss = 0.3113. Learning rate = 0.000125. Patience = 27\n",
      "Epoch 72: training loss = 0.2519, validation loss = 0.3107. Learning rate = 0.000125. Patience = 28\n",
      "Epoch 73: training loss = 0.2603, validation loss = 0.3125. Learning rate = 0.000125. Patience = 29\n",
      "Epoch 74: training loss = 0.2554, validation loss = 0.3137. Learning rate = 0.000125. Patience = 30\n",
      "Epoch 75: training loss = 0.2424, validation loss = 0.3143. Learning rate = 0.000125. Patience = 31\n",
      "Epoch 76: training loss = 0.2585, validation loss = 0.3137. Learning rate = 0.000125. Patience = 32\n",
      "Epoch 77: training loss = 0.2545, validation loss = 0.3136. Learning rate = 6.25e-05. Patience = 33\n",
      "Epoch 78: training loss = 0.2505, validation loss = 0.3124. Learning rate = 6.25e-05. Patience = 34\n",
      "Epoch 79: training loss = 0.2485, validation loss = 0.3118. Learning rate = 6.25e-05. Patience = 35\n",
      "Epoch 80: training loss = 0.2483, validation loss = 0.3116. Learning rate = 6.25e-05. Patience = 36\n",
      "Epoch 81: training loss = 0.2476, validation loss = 0.3121. Learning rate = 6.25e-05. Patience = 37\n",
      "Epoch 82: training loss = 0.2470, validation loss = 0.3125. Learning rate = 6.25e-05. Patience = 38\n",
      "Epoch 83: training loss = 0.2425, validation loss = 0.3130. Learning rate = 6.25e-05. Patience = 39\n",
      "Epoch 84: training loss = 0.2584, validation loss = 0.3141. Learning rate = 6.25e-05. Patience = 40\n",
      "Epoch 85: training loss = 0.2515, validation loss = 0.3133. Learning rate = 6.25e-05. Patience = 41\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86: training loss = 0.2492, validation loss = 0.3135. Learning rate = 6.25e-05. Patience = 42\n",
      "Epoch 87: training loss = 0.2514, validation loss = 0.3155. Learning rate = 6.25e-05. Patience = 43\n",
      "Epoch 88: training loss = 0.2466, validation loss = 0.3168. Learning rate = 3.125e-05. Patience = 44\n",
      "Epoch 89: training loss = 0.2527, validation loss = 0.3166. Learning rate = 3.125e-05. Patience = 45\n",
      "Epoch 90: training loss = 0.2452, validation loss = 0.3167. Learning rate = 3.125e-05. Patience = 46\n",
      "Epoch 91: training loss = 0.2560, validation loss = 0.3167. Learning rate = 3.125e-05. Patience = 47\n",
      "Epoch 92: training loss = 0.2510, validation loss = 0.3167. Learning rate = 3.125e-05. Patience = 48\n",
      "Epoch 93: training loss = 0.2478, validation loss = 0.3164. Learning rate = 3.125e-05. Patience = 49\n",
      "Epoch 94: training loss = 0.2494, validation loss = 0.3159. Learning rate = 3.125e-05. Patience = 50\n",
      "Training stopped at epoch 94; restoring weights from epoch 44\n"
     ]
    }
   ],
   "source": [
    "df_result = pd.DataFrame()\n",
    "#\n",
    "for family in df['family'].unique():\n",
    "    # perform train-test splitting\n",
    "    df_train, df_valid, df_test, scaler = train_test_splitting(df = df[df['family'] == family].reset_index(drop = True).drop('family', axis = 1),\n",
    "                                                               dict_params = dict_params)\n",
    "    #\n",
    "    horizon_forecast = dict_params['data']['horizon_forecast']\n",
    "    # training set data\n",
    "    x_train, y_train, date_x_train, date_y_train = get_x_y(df = df_train, df_future = df_valid, dict_params = dict_params,\n",
    "                                                           test_set = False, horizon_forecast = horizon_forecast)\n",
    "    # validation set data\n",
    "    x_valid, y_valid, date_x_valid, date_y_valid = get_x_y(df = df_valid, df_future = df_test, dict_params = dict_params,\n",
    "                                                           test_set = False, horizon_forecast = horizon_forecast)\n",
    "    # test set data\n",
    "    x_test, y_test, date_x_test, date_y_test = get_x_y(df = df_test, df_future = None, dict_params = dict_params, test_set = True,\n",
    "                                                       horizon_forecast = horizon_forecast)\n",
    "    # create datasets and dataloader\n",
    "    dataset_train = CreateDataset(x = x_train, y = y_train)\n",
    "    dataset_valid = CreateDataset(x = x_valid, y = y_valid)\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size = dict_params['training']['batch_size'], shuffle = True)\n",
    "    dataloader_valid = DataLoader(dataset_valid, batch_size = dict_params['training']['batch_size'], shuffle = False)\n",
    "    # define the model\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "    len_series = dataloader_train.dataset.x.shape[2]\n",
    "    num_feat = dataloader_train.dataset.x.shape[1]\n",
    "    len_output = dataloader_train.dataset.y.shape[2]\n",
    "    # model = TCN(len_series = len_series, num_chan = num_chan, dict_params = dict_params, len_input=100, len_output = 7)\n",
    "    model = TCN(len_series = len_series, num_feat = num_feat, len_output = len_output, dict_params = dict_params,\n",
    "                gated_activation = False)\n",
    "    # perform training\n",
    "    model, list_loss_train, list_loss_valid = TrainTCN(model = model, dict_params = dict_params,\n",
    "                                                       dataloader_train = dataloader_train,\n",
    "                                                       dataloader_valid = dataloader_valid).train_model()\n",
    "    # load best parameters\n",
    "    if 'model' in locals():\n",
    "        del model\n",
    "    len_series = dataloader_train.dataset.x.shape[2]\n",
    "    num_feat = dataloader_train.dataset.x.shape[1]\n",
    "    len_output = dataloader_train.dataset.y.shape[2]\n",
    "    # model = TCN(len_series = len_series, num_chan = num_chan, dict_params = dict_params, len_input=100, len_output = 7)\n",
    "    model = TCN(len_series = len_series, num_feat = num_feat, len_output = len_output, dict_params = dict_params,\n",
    "                gated_activation = False)\n",
    "    #\n",
    "    model.load_state_dict(torch.load('../data/artifacts/weights.p'))\n",
    "    model.eval()\n",
    "    # get time series and the corresponding predictions\n",
    "    y_true_train, y_hat_train = get_y_true_y_hat(model = model, x = x_train, y = y_train, date_y = date_y_train, scaler = scaler)\n",
    "    y_true_valid, y_hat_valid = get_y_true_y_hat(model = model, x = x_valid, y = y_valid, date_y = date_y_valid, scaler = scaler)\n",
    "    y_true_test, y_hat_test = get_y_true_y_hat(model = model, x = x_test, y = y_test, date_y = date_y_test, scaler = scaler)\n",
    "    # compute mape on training, validation and test set\n",
    "    mape_train = compute_mape(y_true = y_true_train, y_hat = y_hat_train)\n",
    "    mape_valid = compute_mape(y_true = y_true_valid, y_hat = y_hat_valid)\n",
    "    mape_test = compute_mape(y_true = y_true_test, y_hat = y_hat_test)\n",
    "    #\n",
    "    df_result = pd.concat((df_result, pd.DataFrame({'family': [family], 'mape_train': [mape_train], 'mape_valid': [mape_valid],\n",
    "                                                    'mape_test': [mape_test]})))\n",
    "#\n",
    "df_result = df_result.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "8d7c9f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7999706.5"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result['mape_test'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "23e9c2b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13a52f19d50>]"
      ]
     },
     "execution_count": 459,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(df[df['family'] == 'AUTOMOTIVE']['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "26bab4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_date = []\n",
    "list_y_true = []\n",
    "list_y_hat = []\n",
    "preds = model(x_test)\n",
    "for i in range(np.unique(date_y_test).shape[0]):\n",
    "    date = np.unique(date_y_test)[i]\n",
    "    list_date.append(date)\n",
    "    idx = np.where(date_y_test == date)\n",
    "    list_y_true.append(y_test.numpy()[idx].mean())\n",
    "    list_y_hat.append(preds.detach().numpy()[idx].mean())\n",
    "list_y_true = np.array(list_y_true)\n",
    "list_y_hat = np.array(list_y_hat)\n",
    "# scale back\n",
    "list_y_true = scaler.inverse_transform(list_y_true.reshape(-1, 1)).ravel()\n",
    "list_y_hat = scaler.inverse_transform(list_y_hat.reshape(-1, 1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "9359ffff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15152872"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(abs(list_y_true[list_y_true > 0] - list_y_hat[list_y_true > 0])/list_y_hat[list_y_true > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "85dfc68b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13a26c903a0>]"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = [12, 6])\n",
    "plt.plot(list_y_true)\n",
    "plt.plot(np.arange(len(list_y_hat)) - 0*x_test.shape[2], list_y_hat)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading",
   "language": "python",
   "name": "trading"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
